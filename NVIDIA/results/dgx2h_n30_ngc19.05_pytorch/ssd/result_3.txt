Beginning trial 4 of 5
Gathering sys log on circe-n001
:::MLL 1558651657.543 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558651657.543 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558651657.544 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558651657.544 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558651657.544 submission_platform: {"value": "30xNVIDIA DGX-2H", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558651657.545 submission_entry: {"value": "{'hardware': 'NVIDIA DGX-2H', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.1 LTS / NVIDIA DGX Server 4.0.4 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) Platinum 8174 CPU @ 3.10GHz', 'num_cores': '48', 'num_vcpus': '96', 'accelerator': 'Tesla V100-SXM3-32GB-H', 'num_accelerators': '8', 'sys_mem_size': '1510 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '2x 894.3G + 8x 3.5T', 'cpu_accel_interconnect': 'UPI', 'network_card': 'Mellanox Technologies MT27800 Family [ConnectX-5]', 'num_network_cards': '10', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558651657.545 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558651657.545 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558651660.162 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.155 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.183 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.182 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.184 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.192 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.223 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.174 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.179 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.205 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.195 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.211 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.197 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.199 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.209 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.250 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.238 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.240 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.250 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.235 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.265 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.223 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.264 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.273 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.275 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.266 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.309 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.254 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.297 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651660.279 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node circe-n001
+ pids+=($!)
+ set +x
Launching on node circe-n002
+ pids+=($!)
+ set +x
Launching on node circe-n003
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n001
Launching on node circe-n004
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n002
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n003
+ srun --mem=0 -N 1 -n 1 -w circe-n001 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n005
+ srun --mem=0 -N 1 -n 1 -w circe-n002 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n003 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
Launching on node circe-n006
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n004
+ srun --mem=0 -N 1 -n 1 -w circe-n004 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n005
+ set +x
Launching on node circe-n007
+ srun --mem=0 -N 1 -n 1 -w circe-n005 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n006
+ set +x
Launching on node circe-n008
+ srun --mem=0 -N 1 -n 1 -w circe-n006 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n007
Launching on node circe-n009
+ pids+=($!)
+ set +x
Launching on node circe-n010
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n008
+ srun --mem=0 -N 1 -n 1 -w circe-n007 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n011
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n009
+ srun --mem=0 -N 1 -n 1 -w circe-n008 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n012
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n009 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n010
+ pids+=($!)
+ set +x
Launching on node circe-n013
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n011
+ srun --mem=0 -N 1 -n 1 -w circe-n010 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n014
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n012
+ srun --mem=0 -N 1 -n 1 -w circe-n011 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n015
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n013
+ srun --mem=0 -N 1 -n 1 -w circe-n012 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n016
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n013 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n014
+ pids+=($!)
+ set +x
Launching on node circe-n017
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n015
+ srun --mem=0 -N 1 -n 1 -w circe-n014 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n018
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n016
+ srun --mem=0 -N 1 -n 1 -w circe-n015 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n016 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n019
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n017
+ pids+=($!)
+ set +x
Launching on node circe-n020
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n017 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n018
+ pids+=($!)
+ set +x
Launching on node circe-n021
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n019
+ srun --mem=0 -N 1 -n 1 -w circe-n018 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n022
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n020
+ srun --mem=0 -N 1 -n 1 -w circe-n019 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n023
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n021
+ srun --mem=0 -N 1 -n 1 -w circe-n020 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n022
Launching on node circe-n024
+ srun --mem=0 -N 1 -n 1 -w circe-n021 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w circe-n022 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n023
+ set +x
Launching on node circe-n025
+ pids+=($!)
+ set +x
Launching on node circe-n026
+ srun --mem=0 -N 1 -n 1 -w circe-n023 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n024
+ pids+=($!)
+ set +x
Launching on node circe-n027
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n025
+ srun --mem=0 -N 1 -n 1 -w circe-n024 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n028
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n026
+ srun --mem=0 -N 1 -n 1 -w circe-n025 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n029
+ srun --mem=0 -N 1 -n 1 -w circe-n026 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n027
+ pids+=($!)
+ set +x
Launching on node circe-n030
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n028
+ srun --mem=0 -N 1 -n 1 -w circe-n027 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n029
+ srun --mem=0 -N 1 -n 1 -w circe-n028 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n030
+ srun --mem=0 -N 1 -n 1 -w circe-n029 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n030 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:47:40 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558651663.622 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.622 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.622 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.622 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.622 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.622 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.622 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.629 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.879 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.879 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.879 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.879 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.880 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.880 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.916 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.916 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.916 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.905 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.905 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.905 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.905 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.905 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.905 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558651663.906 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.906 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.908 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.895 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.895 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.895 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.895 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.895 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.895 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.895 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.896 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.896 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.897 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.897 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.897 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.897 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.898 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.898 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651663.898 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.914 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.914 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.914 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.914 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.914 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.915 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.915 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.915 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.899 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.899 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.899 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.912 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.912 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.912 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.912 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.913 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.913 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.913 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.913 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.940 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.940 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.940 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.940 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.940 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.940 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.940 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.940 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.907 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.954 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.954 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.954 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.919 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651663.920 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.920 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.920 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.953 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.954 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.954 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.954 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.944 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.944 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.944 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.944 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.944 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.944 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.944 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.944 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.938 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.938 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.939 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.939 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.939 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.939 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.939 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.939 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.932 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.932 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.932 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.932 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.932 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.932 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.932 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.932 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.941 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.941 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.941 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.941 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.941 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.941 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.941 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.981 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.981 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.981 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.982 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.982 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.982 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.982 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.982 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.942 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.961 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.961 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.961 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.961 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651663.934 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.934 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.934 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.934 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.962 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.962 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.962 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.962 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.935 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.935 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.935 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.935 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.936 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.937 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.937 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.937 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.937 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.937 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.937 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.938 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.952 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.952 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.952 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.952 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.952 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.952 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.952 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.952 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.994 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.994 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.994 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.994 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.994 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.994 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.994 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.994 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.972 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.972 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.972 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.972 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.972 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.972 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.972 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.972 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.976 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.976 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.976 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.976 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.977 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.977 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.977 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.977 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651663.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651663.993 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
0 Using seed = 2389432267
2 Using seed = 2389432269
1 Using seed = 2389432268
:::MLL 1558651677.516 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
4 Using seed = 2389432271
3 Using seed = 2389432270
10 Using seed = 2389432277
9 Using seed = 2389432276
13 Using seed = 2389432280
8 Using seed = 2389432275
14 Using seed = 2389432281
15 Using seed = 2389432282
11 Using seed = 2389432278
12 Using seed = 2389432279
23 Using seed = 2389432290
21 Using seed = 2389432288
22 Using seed = 2389432289
18 Using seed = 2389432285
17 Using seed = 2389432284
16 Using seed = 2389432283
20 Using seed = 2389432287
19 Using seed = 2389432286
31 Using seed = 2389432298
29 Using seed = 2389432296
24 Using seed = 2389432291
30 Using seed = 2389432297
25 Using seed = 2389432292
26 Using seed = 2389432293
28 Using seed = 2389432295
27 Using seed = 2389432294
35 Using seed = 2389432302
32 Using seed = 2389432299
33 Using seed = 2389432300
37 Using seed = 2389432304
34 Using seed = 2389432301
38 Using seed = 2389432305
39 Using seed = 2389432306
36 Using seed = 2389432303
43 Using seed = 2389432310
44 Using seed = 2389432311
42 Using seed = 2389432309
45 Using seed = 2389432312
46 Using seed = 2389432313
40 Using seed = 2389432307
41 Using seed = 2389432308
47 Using seed = 2389432314
54 Using seed = 2389432321
49 Using seed = 2389432316
53 Using seed = 2389432320
55 Using seed = 2389432322
50 Using seed = 2389432317
48 Using seed = 2389432315
51 Using seed = 2389432318
52 Using seed = 2389432319
63 Using seed = 2389432330
60 Using seed = 2389432327
62 Using seed = 2389432329
57 Using seed = 2389432324
59 Using seed = 2389432326
61 Using seed = 2389432328
56 Using seed = 2389432323
58 Using seed = 2389432325
69 Using seed = 2389432336
70 Using seed = 2389432337
67 Using seed = 2389432334
64 Using seed = 2389432331
66 Using seed = 2389432333
71 Using seed = 2389432338
68 Using seed = 2389432335
65 Using seed = 2389432332
72 Using seed = 2389432339
75 Using seed = 2389432342
73 Using seed = 2389432340
79 Using seed = 2389432346
74 Using seed = 2389432341
77 Using seed = 2389432344
78 Using seed = 2389432345
76 Using seed = 2389432343
81 Using seed = 2389432348
80 Using seed = 2389432347
82 Using seed = 2389432349
85 Using seed = 2389432352
86 Using seed = 2389432353
87 Using seed = 2389432354
84 Using seed = 2389432351
83 Using seed = 2389432350
88 Using seed = 2389432355
89 Using seed = 2389432356
95 Using seed = 2389432362
93 Using seed = 2389432360
90 Using seed = 2389432357
94 Using seed = 2389432361
92 Using seed = 2389432359
91 Using seed = 2389432358
96 Using seed = 2389432363
98 Using seed = 2389432365
102 Using seed = 2389432369
97 Using seed = 2389432364
99 Using seed = 2389432366
101 Using seed = 2389432368
103 Using seed = 2389432370
100 Using seed = 2389432367
110 Using seed = 2389432377
109 Using seed = 2389432376
111 Using seed = 2389432378
107 Using seed = 2389432374
106 Using seed = 2389432373
105 Using seed = 2389432372
104 Using seed = 2389432371
108 Using seed = 2389432375
112 Using seed = 2389432379
113 Using seed = 2389432380
118 Using seed = 2389432385
119 Using seed = 2389432386
114 Using seed = 2389432381
117 Using seed = 2389432384
115 Using seed = 2389432382
116 Using seed = 2389432383
127 Using seed = 2389432394
124 Using seed = 2389432391
126 Using seed = 2389432393
125 Using seed = 2389432392
121 Using seed = 2389432388
123 Using seed = 2389432390
120 Using seed = 2389432387
122 Using seed = 2389432389
128 Using seed = 2389432395
133 Using seed = 2389432400
131 Using seed = 2389432398
129 Using seed = 2389432396
130 Using seed = 2389432397
134 Using seed = 2389432401
135 Using seed = 2389432402
132 Using seed = 2389432399
139 Using seed = 2389432406
141 Using seed = 2389432408
138 Using seed = 2389432405
143 Using seed = 2389432410
142 Using seed = 2389432409
136 Using seed = 2389432403
137 Using seed = 2389432404
140 Using seed = 2389432407
146 Using seed = 2389432413
147 Using seed = 2389432414
145 Using seed = 2389432412
151 Using seed = 2389432418
144 Using seed = 2389432411
148 Using seed = 2389432415
150 Using seed = 2389432417
149 Using seed = 2389432416
155 Using seed = 2389432422
153 Using seed = 2389432420
159 Using seed = 2389432426
157 Using seed = 2389432424
158 Using seed = 2389432425
152 Using seed = 2389432419
156 Using seed = 2389432423
154 Using seed = 2389432421
166 Using seed = 2389432433
160 Using seed = 2389432427
165 Using seed = 2389432432
167 Using seed = 2389432434
163 Using seed = 2389432430
161 Using seed = 2389432428
162 Using seed = 2389432429
164 Using seed = 2389432431
173 Using seed = 2389432440
172 Using seed = 2389432439
175 Using seed = 2389432442
168 Using seed = 2389432435
171 Using seed = 2389432438
169 Using seed = 2389432436
170 Using seed = 2389432437
174 Using seed = 2389432441
177 Using seed = 2389432444
182 Using seed = 2389432449
176 Using seed = 2389432443
178 Using seed = 2389432445
179 Using seed = 2389432446
183 Using seed = 2389432450
181 Using seed = 2389432448
180 Using seed = 2389432447
189 Using seed = 2389432456
190 Using seed = 2389432457
191 Using seed = 2389432458
188 Using seed = 2389432455
187 Using seed = 2389432454
184 Using seed = 2389432451
185 Using seed = 2389432452
186 Using seed = 2389432453
195 Using seed = 2389432462
194 Using seed = 2389432461
192 Using seed = 2389432459
193 Using seed = 2389432460
198 Using seed = 2389432465
197 Using seed = 2389432464
199 Using seed = 2389432466
196 Using seed = 2389432463
201 Using seed = 2389432468
207 Using seed = 2389432474
205 Using seed = 2389432472
206 Using seed = 2389432473
200 Using seed = 2389432467
204 Using seed = 2389432471
202 Using seed = 2389432469
203 Using seed = 2389432470
210 Using seed = 2389432477
209 Using seed = 2389432476
214 Using seed = 2389432481
211 Using seed = 2389432478
215 Using seed = 2389432482
213 Using seed = 2389432480
208 Using seed = 2389432475
212 Using seed = 2389432479
223 Using seed = 2389432490
217 Using seed = 2389432484
222 Using seed = 2389432489
221 Using seed = 2389432488
216 Using seed = 2389432483
219 Using seed = 2389432486
218 Using seed = 2389432485
220 Using seed = 2389432487
230 Using seed = 2389432497
229 Using seed = 2389432496
226 Using seed = 2389432493
224 Using seed = 2389432491
231 Using seed = 2389432498
225 Using seed = 2389432492
227 Using seed = 2389432494
228 Using seed = 2389432495
233 Using seed = 2389432500
239 Using seed = 2389432506
234 Using seed = 2389432501
235 Using seed = 2389432502
232 Using seed = 2389432499
237 Using seed = 2389432504
238 Using seed = 2389432505
236 Using seed = 2389432503
5 Using seed = 2389432272
7 Using seed = 2389432274
6 Using seed = 2389432273
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1558651679.599 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558651679.600 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651679.615 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1558651679.615 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
Delaying allreduces to the end of backward()
:::MLL 1558651679.615 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558651679.616 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558651683.449 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558651683.449 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.45s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
time_check a: 1558651685.092967749
time_check a: 1558651685.100638628
time_check a: 1558651685.087631941
time_check a: 1558651685.107001781
time_check a: 1558651685.088064194
time_check a: 1558651685.086940050
time_check a: 1558651685.112599850
time_check a: 1558651685.085252047
time_check a: 1558651685.108692408
time_check a: 1558651685.110217571
time_check a: 1558651685.107868671
time_check a: 1558651685.096761703
time_check a: 1558651685.129131794
time_check a: 1558651685.114828110
time_check a: 1558651685.095022917
time_check a: 1558651685.141417265
time_check a: 1558651685.102193832
time_check a: 1558651685.093332529
time_check a: 1558651685.108744144
time_check a: 1558651685.099566221
time_check a: 1558651685.145584583
time_check a: 1558651685.089929581
time_check a: 1558651685.136737347
time_check a: 1558651685.129415512
time_check a: 1558651685.128848076
time_check a: 1558651685.129388094
time_check a: 1558651685.122035742
time_check a: 1558651685.131638050
time_check a: 1558651685.115625620
time_check a: 1558651685.123389721
time_check b: 1558651688.897006989
time_check b: 1558651688.910580158
time_check b: 1558651688.942258835
time_check b: 1558651688.907007933
time_check b: 1558651688.906843185
time_check b: 1558651688.951863766
time_check b: 1558651688.931662560
time_check b: 1558651688.982474327
time_check b: 1558651688.974709034
time_check b: 1558651688.941985607
time_check b: 1558651688.980278254
time_check b: 1558651688.951428652
time_check b: 1558651688.972574472
time_check b: 1558651688.953266621
time_check b: 1558651688.967228174
time_check b: 1558651688.973278284
time_check b: 1558651689.006951332
time_check b: 1558651688.980107546
time_check b: 1558651688.991456032
time_check b: 1558651689.017806292
time_check b: 1558651689.036513329
time_check b: 1558651689.002345562
time_check b: 1558651689.038982153
time_check b: 1558651689.028536558
time_check b: 1558651689.034037828
time_check b: 1558651689.038546085
time_check b: 1558651689.043522596
time_check b: 1558651689.049025774
time_check b: 1558651689.051493645
time_check b: 1558651689.108343840
:::MLL 1558651689.731 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558651689.732 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 23.429, Average Loss: 0.023, avg. samples / sec: 179.59
Iteration:      0, Loss function: 23.710, Average Loss: 0.024, avg. samples / sec: 176.52
Iteration:      0, Loss function: 23.467, Average Loss: 0.023, avg. samples / sec: 178.16
Iteration:      0, Loss function: 23.253, Average Loss: 0.023, avg. samples / sec: 178.37
Iteration:      0, Loss function: 23.137, Average Loss: 0.023, avg. samples / sec: 178.14
Iteration:      0, Loss function: 23.017, Average Loss: 0.023, avg. samples / sec: 176.65
Iteration:      0, Loss function: 23.370, Average Loss: 0.023, avg. samples / sec: 179.42
Iteration:      0, Loss function: 23.375, Average Loss: 0.023, avg. samples / sec: 176.82
Iteration:      0, Loss function: 23.384, Average Loss: 0.023, avg. samples / sec: 178.75
Iteration:      0, Loss function: 23.209, Average Loss: 0.023, avg. samples / sec: 178.47
Iteration:      0, Loss function: 22.672, Average Loss: 0.023, avg. samples / sec: 174.05
Iteration:      0, Loss function: 23.032, Average Loss: 0.023, avg. samples / sec: 175.91
Iteration:      0, Loss function: 23.137, Average Loss: 0.023, avg. samples / sec: 177.04
Iteration:      0, Loss function: 23.021, Average Loss: 0.023, avg. samples / sec: 177.08
Iteration:      0, Loss function: 24.122, Average Loss: 0.024, avg. samples / sec: 178.97
Iteration:      0, Loss function: 22.921, Average Loss: 0.023, avg. samples / sec: 178.15
Iteration:      0, Loss function: 22.971, Average Loss: 0.023, avg. samples / sec: 177.75
Iteration:      0, Loss function: 23.904, Average Loss: 0.024, avg. samples / sec: 178.67
Iteration:      0, Loss function: 23.421, Average Loss: 0.023, avg. samples / sec: 178.73
Iteration:      0, Loss function: 22.989, Average Loss: 0.023, avg. samples / sec: 178.49
Iteration:      0, Loss function: 23.066, Average Loss: 0.023, avg. samples / sec: 177.98
Iteration:      0, Loss function: 23.015, Average Loss: 0.023, avg. samples / sec: 175.74
Iteration:      0, Loss function: 22.920, Average Loss: 0.023, avg. samples / sec: 178.24
Iteration:      0, Loss function: 23.703, Average Loss: 0.024, avg. samples / sec: 176.83
Iteration:      0, Loss function: 23.333, Average Loss: 0.023, avg. samples / sec: 163.60
Iteration:      0, Loss function: 23.517, Average Loss: 0.024, avg. samples / sec: 177.65
Iteration:      0, Loss function: 23.166, Average Loss: 0.023, avg. samples / sec: 175.07
Iteration:      0, Loss function: 22.842, Average Loss: 0.023, avg. samples / sec: 178.87
Iteration:      0, Loss function: 23.857, Average Loss: 0.024, avg. samples / sec: 178.77
Iteration:      0, Loss function: 23.346, Average Loss: 0.023, avg. samples / sec: 176.35
Iteration:     20, Loss function: 20.422, Average Loss: 0.450, avg. samples / sec: 42717.65
Iteration:     20, Loss function: 21.597, Average Loss: 0.452, avg. samples / sec: 42760.50
Iteration:     20, Loss function: 20.194, Average Loss: 0.447, avg. samples / sec: 43374.41
Iteration:     20, Loss function: 20.676, Average Loss: 0.449, avg. samples / sec: 42949.99
Iteration:     20, Loss function: 20.220, Average Loss: 0.445, avg. samples / sec: 42898.53
Iteration:     20, Loss function: 20.608, Average Loss: 0.447, avg. samples / sec: 43124.60
Iteration:     20, Loss function: 21.126, Average Loss: 0.449, avg. samples / sec: 44304.91
Iteration:     20, Loss function: 21.037, Average Loss: 0.449, avg. samples / sec: 43165.99
Iteration:     20, Loss function: 21.375, Average Loss: 0.455, avg. samples / sec: 44685.17
Iteration:     20, Loss function: 20.490, Average Loss: 0.448, avg. samples / sec: 43061.34
Iteration:     20, Loss function: 20.989, Average Loss: 0.447, avg. samples / sec: 43269.28
Iteration:     20, Loss function: 20.541, Average Loss: 0.449, avg. samples / sec: 43272.66
Iteration:     20, Loss function: 20.898, Average Loss: 0.448, avg. samples / sec: 42860.80
Iteration:     20, Loss function: 20.264, Average Loss: 0.447, avg. samples / sec: 43168.30
Iteration:     20, Loss function: 21.187, Average Loss: 0.452, avg. samples / sec: 44329.47
Iteration:     20, Loss function: 20.454, Average Loss: 0.449, avg. samples / sec: 43118.86
Iteration:     20, Loss function: 20.604, Average Loss: 0.448, avg. samples / sec: 42991.44
Iteration:     20, Loss function: 20.393, Average Loss: 0.449, avg. samples / sec: 42844.81
Iteration:     20, Loss function: 21.129, Average Loss: 0.448, avg. samples / sec: 42962.65
Iteration:     20, Loss function: 20.451, Average Loss: 0.446, avg. samples / sec: 42914.54
Iteration:     20, Loss function: 21.121, Average Loss: 0.447, avg. samples / sec: 42837.35
Iteration:     20, Loss function: 20.250, Average Loss: 0.446, avg. samples / sec: 43133.67
Iteration:     20, Loss function: 20.624, Average Loss: 0.450, avg. samples / sec: 42987.35
Iteration:     20, Loss function: 20.266, Average Loss: 0.450, avg. samples / sec: 43022.42
Iteration:     20, Loss function: 20.884, Average Loss: 0.446, avg. samples / sec: 43253.48
Iteration:     20, Loss function: 20.760, Average Loss: 0.446, avg. samples / sec: 42192.00
Iteration:     20, Loss function: 20.711, Average Loss: 0.445, avg. samples / sec: 43020.07
Iteration:     20, Loss function: 22.490, Average Loss: 0.448, avg. samples / sec: 43330.77
Iteration:     20, Loss function: 20.477, Average Loss: 0.447, avg. samples / sec: 42710.31
Iteration:     20, Loss function: 20.541, Average Loss: 0.447, avg. samples / sec: 42447.50
Iteration:     40, Loss function: 18.348, Average Loss: 0.836, avg. samples / sec: 64052.90
Iteration:     40, Loss function: 18.384, Average Loss: 0.833, avg. samples / sec: 63904.28
Iteration:     40, Loss function: 18.162, Average Loss: 0.831, avg. samples / sec: 64289.35
Iteration:     40, Loss function: 18.854, Average Loss: 0.836, avg. samples / sec: 63897.44
Iteration:     40, Loss function: 19.013, Average Loss: 0.839, avg. samples / sec: 63628.62
Iteration:     40, Loss function: 20.351, Average Loss: 0.843, avg. samples / sec: 63960.78
Iteration:     40, Loss function: 18.643, Average Loss: 0.835, avg. samples / sec: 63767.33
Iteration:     40, Loss function: 18.172, Average Loss: 0.838, avg. samples / sec: 63867.90
Iteration:     40, Loss function: 18.610, Average Loss: 0.839, avg. samples / sec: 63794.29
Iteration:     40, Loss function: 19.359, Average Loss: 0.838, avg. samples / sec: 64628.54
Iteration:     40, Loss function: 18.403, Average Loss: 0.846, avg. samples / sec: 63784.10
Iteration:     40, Loss function: 18.568, Average Loss: 0.837, avg. samples / sec: 63729.99
Iteration:     40, Loss function: 18.767, Average Loss: 0.835, avg. samples / sec: 63961.18
Iteration:     40, Loss function: 19.087, Average Loss: 0.844, avg. samples / sec: 63753.23
Iteration:     40, Loss function: 18.267, Average Loss: 0.839, avg. samples / sec: 64045.36
Iteration:     40, Loss function: 19.164, Average Loss: 0.838, avg. samples / sec: 63676.17
Iteration:     40, Loss function: 19.409, Average Loss: 0.835, avg. samples / sec: 63804.00
Iteration:     40, Loss function: 18.698, Average Loss: 0.835, avg. samples / sec: 63656.47
Iteration:     40, Loss function: 19.851, Average Loss: 0.842, avg. samples / sec: 64121.59
Iteration:     40, Loss function: 18.901, Average Loss: 0.840, avg. samples / sec: 63419.51
Iteration:     40, Loss function: 18.243, Average Loss: 0.838, avg. samples / sec: 63680.09
Iteration:     40, Loss function: 18.043, Average Loss: 0.838, avg. samples / sec: 63918.51
Iteration:     40, Loss function: 18.302, Average Loss: 0.837, avg. samples / sec: 63435.75
Iteration:     40, Loss function: 18.889, Average Loss: 0.837, avg. samples / sec: 63735.73
Iteration:     40, Loss function: 18.611, Average Loss: 0.840, avg. samples / sec: 63790.95
Iteration:     40, Loss function: 18.921, Average Loss: 0.840, avg. samples / sec: 63637.93
Iteration:     40, Loss function: 19.452, Average Loss: 0.845, avg. samples / sec: 63562.36
Iteration:     40, Loss function: 19.163, Average Loss: 0.841, avg. samples / sec: 63748.30
Iteration:     40, Loss function: 18.262, Average Loss: 0.833, avg. samples / sec: 63828.76
Iteration:     40, Loss function: 18.816, Average Loss: 0.839, avg. samples / sec: 63155.14
Iteration:     60, Loss function: 12.997, Average Loss: 1.114, avg. samples / sec: 63272.08
Iteration:     60, Loss function: 15.100, Average Loss: 1.108, avg. samples / sec: 63036.52
Iteration:     60, Loss function: 12.459, Average Loss: 1.095, avg. samples / sec: 63348.44
Iteration:     60, Loss function: 12.131, Average Loss: 1.097, avg. samples / sec: 62849.30
Iteration:     60, Loss function: 13.567, Average Loss: 1.104, avg. samples / sec: 62825.90
Iteration:     60, Loss function: 11.706, Average Loss: 1.105, avg. samples / sec: 63101.30
Iteration:     60, Loss function: 12.485, Average Loss: 1.105, avg. samples / sec: 63128.27
Iteration:     60, Loss function: 14.701, Average Loss: 1.106, avg. samples / sec: 62968.39
Iteration:     60, Loss function: 12.649, Average Loss: 1.102, avg. samples / sec: 63201.25
Iteration:     60, Loss function: 14.162, Average Loss: 1.105, avg. samples / sec: 62950.36
Iteration:     60, Loss function: 14.571, Average Loss: 1.102, avg. samples / sec: 63141.33
Iteration:     60, Loss function: 14.089, Average Loss: 1.108, avg. samples / sec: 63518.15
Iteration:     60, Loss function: 13.608, Average Loss: 1.101, avg. samples / sec: 62910.80
Iteration:     60, Loss function: 14.430, Average Loss: 1.105, avg. samples / sec: 63099.29
Iteration:     60, Loss function: 14.512, Average Loss: 1.107, avg. samples / sec: 62917.90
Iteration:     60, Loss function: 12.312, Average Loss: 1.100, avg. samples / sec: 63203.72
Iteration:     60, Loss function: 14.575, Average Loss: 1.103, avg. samples / sec: 62848.63
Iteration:     60, Loss function: 13.613, Average Loss: 1.106, avg. samples / sec: 63052.80
Iteration:     60, Loss function: 13.297, Average Loss: 1.097, avg. samples / sec: 62978.64
Iteration:     60, Loss function: 12.304, Average Loss: 1.107, avg. samples / sec: 62825.37
Iteration:     60, Loss function: 14.985, Average Loss: 1.108, avg. samples / sec: 62837.08
Iteration:     60, Loss function: 10.947, Average Loss: 1.099, avg. samples / sec: 63017.08
Iteration:     60, Loss function: 13.506, Average Loss: 1.106, avg. samples / sec: 63046.51
Iteration:     60, Loss function: 16.050, Average Loss: 1.100, avg. samples / sec: 62924.98
Iteration:     60, Loss function: 12.593, Average Loss: 1.106, avg. samples / sec: 63040.53
Iteration:     60, Loss function: 13.531, Average Loss: 1.099, avg. samples / sec: 62803.78
Iteration:     60, Loss function: 13.529, Average Loss: 1.110, avg. samples / sec: 62924.64
Iteration:     60, Loss function: 15.091, Average Loss: 1.094, avg. samples / sec: 62506.23
Iteration:     60, Loss function: 12.918, Average Loss: 1.100, avg. samples / sec: 62542.85
Iteration:     60, Loss function: 15.765, Average Loss: 1.098, avg. samples / sec: 62178.22
:::MLL 1558651692.505 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558651692.506 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 10.654, Average Loss: 1.300, avg. samples / sec: 64575.27
Iteration:     80, Loss function: 10.812, Average Loss: 1.301, avg. samples / sec: 65115.82
Iteration:     80, Loss function: 10.196, Average Loss: 1.308, avg. samples / sec: 64722.48
Iteration:     80, Loss function: 10.333, Average Loss: 1.297, avg. samples / sec: 64733.96
Iteration:     80, Loss function: 9.992, Average Loss: 1.298, avg. samples / sec: 64724.18
Iteration:     80, Loss function: 10.572, Average Loss: 1.306, avg. samples / sec: 64662.05
Iteration:     80, Loss function: 10.497, Average Loss: 1.318, avg. samples / sec: 64779.81
Iteration:     80, Loss function: 10.023, Average Loss: 1.306, avg. samples / sec: 64329.08
Iteration:     80, Loss function: 9.858, Average Loss: 1.300, avg. samples / sec: 64458.66
Iteration:     80, Loss function: 11.076, Average Loss: 1.301, avg. samples / sec: 64417.82
Iteration:     80, Loss function: 9.232, Average Loss: 1.295, avg. samples / sec: 64576.57
Iteration:     80, Loss function: 10.441, Average Loss: 1.299, avg. samples / sec: 64385.30
Iteration:     80, Loss function: 10.637, Average Loss: 1.296, avg. samples / sec: 65416.99
Iteration:     80, Loss function: 10.537, Average Loss: 1.307, avg. samples / sec: 64476.33
Iteration:     80, Loss function: 9.895, Average Loss: 1.295, avg. samples / sec: 64339.33
Iteration:     80, Loss function: 9.907, Average Loss: 1.289, avg. samples / sec: 64752.85
Iteration:     80, Loss function: 10.614, Average Loss: 1.296, avg. samples / sec: 64540.19
Iteration:     80, Loss function: 9.966, Average Loss: 1.299, avg. samples / sec: 64336.48
Iteration:     80, Loss function: 10.134, Average Loss: 1.300, avg. samples / sec: 64375.86
Iteration:     80, Loss function: 10.447, Average Loss: 1.297, avg. samples / sec: 64416.68
Iteration:     80, Loss function: 10.088, Average Loss: 1.303, avg. samples / sec: 64347.15
Iteration:     80, Loss function: 11.041, Average Loss: 1.293, avg. samples / sec: 64253.24
Iteration:     80, Loss function: 10.631, Average Loss: 1.309, avg. samples / sec: 64209.41
Iteration:     80, Loss function: 12.086, Average Loss: 1.307, avg. samples / sec: 64433.70
Iteration:     80, Loss function: 9.978, Average Loss: 1.301, avg. samples / sec: 64332.28
Iteration:     80, Loss function: 10.426, Average Loss: 1.298, avg. samples / sec: 64522.11
Iteration:     80, Loss function: 10.569, Average Loss: 1.311, avg. samples / sec: 64486.33
Iteration:     80, Loss function: 10.248, Average Loss: 1.302, avg. samples / sec: 64273.81
Iteration:     80, Loss function: 11.022, Average Loss: 1.305, avg. samples / sec: 64198.06
Iteration:     80, Loss function: 10.011, Average Loss: 1.306, avg. samples / sec: 63977.56
Iteration:    100, Loss function: 8.856, Average Loss: 1.470, avg. samples / sec: 65736.84
Iteration:    100, Loss function: 9.157, Average Loss: 1.464, avg. samples / sec: 65912.95
Iteration:    100, Loss function: 9.844, Average Loss: 1.467, avg. samples / sec: 65901.27
Iteration:    100, Loss function: 9.415, Average Loss: 1.468, avg. samples / sec: 65782.44
Iteration:    100, Loss function: 9.916, Average Loss: 1.478, avg. samples / sec: 65919.33
Iteration:    100, Loss function: 9.821, Average Loss: 1.470, avg. samples / sec: 65897.85
Iteration:    100, Loss function: 10.100, Average Loss: 1.468, avg. samples / sec: 65806.52
Iteration:    100, Loss function: 9.807, Average Loss: 1.477, avg. samples / sec: 66038.29
Iteration:    100, Loss function: 9.049, Average Loss: 1.470, avg. samples / sec: 65701.78
Iteration:    100, Loss function: 9.718, Average Loss: 1.466, avg. samples / sec: 65521.83
Iteration:    100, Loss function: 9.462, Average Loss: 1.469, avg. samples / sec: 65667.34
Iteration:    100, Loss function: 8.984, Average Loss: 1.472, avg. samples / sec: 65760.86
Iteration:    100, Loss function: 9.933, Average Loss: 1.469, avg. samples / sec: 65538.71
Iteration:    100, Loss function: 9.093, Average Loss: 1.467, avg. samples / sec: 65643.64
Iteration:    100, Loss function: 10.487, Average Loss: 1.476, avg. samples / sec: 65759.69
Iteration:    100, Loss function: 10.432, Average Loss: 1.486, avg. samples / sec: 65522.44
Iteration:    100, Loss function: 9.500, Average Loss: 1.469, avg. samples / sec: 65639.42
Iteration:    100, Loss function: 9.679, Average Loss: 1.479, avg. samples / sec: 65721.94
Iteration:    100, Loss function: 8.918, Average Loss: 1.461, avg. samples / sec: 65437.10
Iteration:    100, Loss function: 9.440, Average Loss: 1.475, avg. samples / sec: 65580.13
Iteration:    100, Loss function: 8.821, Average Loss: 1.459, avg. samples / sec: 65600.37
Iteration:    100, Loss function: 9.796, Average Loss: 1.468, avg. samples / sec: 65602.72
Iteration:    100, Loss function: 9.193, Average Loss: 1.457, avg. samples / sec: 65456.58
Iteration:    100, Loss function: 9.049, Average Loss: 1.476, avg. samples / sec: 65925.84
Iteration:    100, Loss function: 10.355, Average Loss: 1.464, avg. samples / sec: 65405.30
Iteration:    100, Loss function: 9.225, Average Loss: 1.475, avg. samples / sec: 65247.36
Iteration:    100, Loss function: 9.996, Average Loss: 1.472, avg. samples / sec: 65247.42
Iteration:    100, Loss function: 8.930, Average Loss: 1.473, avg. samples / sec: 65048.38
Iteration:    100, Loss function: 8.842, Average Loss: 1.471, avg. samples / sec: 65252.61
Iteration:    100, Loss function: 9.531, Average Loss: 1.472, avg. samples / sec: 64827.79
Iteration:    120, Loss function: 10.166, Average Loss: 1.621, avg. samples / sec: 65076.07
Iteration:    120, Loss function: 8.985, Average Loss: 1.633, avg. samples / sec: 64928.98
Iteration:    120, Loss function: 9.219, Average Loss: 1.611, avg. samples / sec: 65228.42
Iteration:    120, Loss function: 9.337, Average Loss: 1.628, avg. samples / sec: 65307.10
Iteration:    120, Loss function: 9.264, Average Loss: 1.619, avg. samples / sec: 65035.14
Iteration:    120, Loss function: 9.119, Average Loss: 1.625, avg. samples / sec: 64769.10
Iteration:    120, Loss function: 9.169, Average Loss: 1.639, avg. samples / sec: 64980.18
Iteration:    120, Loss function: 9.252, Average Loss: 1.620, avg. samples / sec: 64930.27
Iteration:    120, Loss function: 9.214, Average Loss: 1.620, avg. samples / sec: 64762.79
Iteration:    120, Loss function: 9.289, Average Loss: 1.620, avg. samples / sec: 64744.58
Iteration:    120, Loss function: 8.731, Average Loss: 1.618, avg. samples / sec: 64729.71
Iteration:    120, Loss function: 9.500, Average Loss: 1.623, avg. samples / sec: 64967.56
Iteration:    120, Loss function: 9.621, Average Loss: 1.631, avg. samples / sec: 64879.15
Iteration:    120, Loss function: 9.677, Average Loss: 1.621, avg. samples / sec: 65036.97
Iteration:    120, Loss function: 9.478, Average Loss: 1.632, avg. samples / sec: 64723.20
Iteration:    120, Loss function: 8.222, Average Loss: 1.608, avg. samples / sec: 65021.70
Iteration:    120, Loss function: 10.272, Average Loss: 1.620, avg. samples / sec: 64744.07
Iteration:    120, Loss function: 9.195, Average Loss: 1.623, avg. samples / sec: 65486.36
Iteration:    120, Loss function: 9.992, Average Loss: 1.622, avg. samples / sec: 64706.91
Iteration:    120, Loss function: 9.687, Average Loss: 1.625, avg. samples / sec: 65342.05
Iteration:    120, Loss function: 10.178, Average Loss: 1.619, avg. samples / sec: 65083.38
Iteration:    120, Loss function: 9.171, Average Loss: 1.629, avg. samples / sec: 64876.91
Iteration:    120, Loss function: 9.239, Average Loss: 1.618, avg. samples / sec: 64793.87
Iteration:    120, Loss function: 9.135, Average Loss: 1.622, avg. samples / sec: 65152.04
Iteration:    120, Loss function: 9.083, Average Loss: 1.633, avg. samples / sec: 64819.29
Iteration:    120, Loss function: 8.656, Average Loss: 1.627, avg. samples / sec: 65001.34
Iteration:    120, Loss function: 8.309, Average Loss: 1.627, avg. samples / sec: 64593.09
Iteration:    120, Loss function: 8.694, Average Loss: 1.626, avg. samples / sec: 65013.93
Iteration:    120, Loss function: 9.479, Average Loss: 1.626, avg. samples / sec: 64439.21
Iteration:    120, Loss function: 9.963, Average Loss: 1.619, avg. samples / sec: 64096.60
:::MLL 1558651694.313 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558651694.314 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 8.796, Average Loss: 1.765, avg. samples / sec: 64604.63
Iteration:    140, Loss function: 8.871, Average Loss: 1.775, avg. samples / sec: 64635.03
Iteration:    140, Loss function: 8.997, Average Loss: 1.775, avg. samples / sec: 64903.71
Iteration:    140, Loss function: 8.588, Average Loss: 1.770, avg. samples / sec: 64643.04
Iteration:    140, Loss function: 8.782, Average Loss: 1.782, avg. samples / sec: 64447.93
Iteration:    140, Loss function: 9.299, Average Loss: 1.778, avg. samples / sec: 64509.09
Iteration:    140, Loss function: 8.492, Average Loss: 1.766, avg. samples / sec: 65291.73
Iteration:    140, Loss function: 8.866, Average Loss: 1.769, avg. samples / sec: 64454.92
Iteration:    140, Loss function: 7.751, Average Loss: 1.774, avg. samples / sec: 64427.07
Iteration:    140, Loss function: 8.278, Average Loss: 1.791, avg. samples / sec: 64445.31
Iteration:    140, Loss function: 8.292, Average Loss: 1.771, avg. samples / sec: 64576.84
Iteration:    140, Loss function: 8.824, Average Loss: 1.753, avg. samples / sec: 64357.46
Iteration:    140, Loss function: 8.874, Average Loss: 1.773, avg. samples / sec: 64714.10
Iteration:    140, Loss function: 8.619, Average Loss: 1.769, avg. samples / sec: 64544.10
Iteration:    140, Loss function: 9.240, Average Loss: 1.766, avg. samples / sec: 64576.30
Iteration:    140, Loss function: 9.179, Average Loss: 1.770, avg. samples / sec: 64490.87
Iteration:    140, Loss function: 9.445, Average Loss: 1.773, avg. samples / sec: 64581.84
Iteration:    140, Loss function: 8.442, Average Loss: 1.777, avg. samples / sec: 64444.42
Iteration:    140, Loss function: 9.374, Average Loss: 1.771, avg. samples / sec: 64537.62
Iteration:    140, Loss function: 10.026, Average Loss: 1.756, avg. samples / sec: 64418.74
Iteration:    140, Loss function: 8.446, Average Loss: 1.772, avg. samples / sec: 64821.86
Iteration:    140, Loss function: 9.620, Average Loss: 1.779, avg. samples / sec: 64515.91
Iteration:    140, Loss function: 8.796, Average Loss: 1.768, avg. samples / sec: 64328.52
Iteration:    140, Loss function: 8.826, Average Loss: 1.768, avg. samples / sec: 64249.16
Iteration:    140, Loss function: 9.566, Average Loss: 1.773, avg. samples / sec: 64318.04
Iteration:    140, Loss function: 8.392, Average Loss: 1.772, avg. samples / sec: 64232.21
Iteration:    140, Loss function: 9.031, Average Loss: 1.770, avg. samples / sec: 64161.50
Iteration:    140, Loss function: 9.333, Average Loss: 1.770, avg. samples / sec: 63961.82
Iteration:    140, Loss function: 8.727, Average Loss: 1.774, avg. samples / sec: 64231.39
Iteration:    140, Loss function: 9.130, Average Loss: 1.779, avg. samples / sec: 64105.37
Iteration:    160, Loss function: 8.216, Average Loss: 1.905, avg. samples / sec: 65636.30
Iteration:    160, Loss function: 8.826, Average Loss: 1.911, avg. samples / sec: 65441.39
Iteration:    160, Loss function: 8.161, Average Loss: 1.909, avg. samples / sec: 65527.07
Iteration:    160, Loss function: 9.616, Average Loss: 1.913, avg. samples / sec: 65396.17
Iteration:    160, Loss function: 7.905, Average Loss: 1.908, avg. samples / sec: 65274.25
Iteration:    160, Loss function: 8.448, Average Loss: 1.915, avg. samples / sec: 65717.84
Iteration:    160, Loss function: 9.658, Average Loss: 1.899, avg. samples / sec: 65449.26
Iteration:    160, Loss function: 8.674, Average Loss: 1.913, avg. samples / sec: 65412.92
Iteration:    160, Loss function: 8.863, Average Loss: 1.914, avg. samples / sec: 65530.61
Iteration:    160, Loss function: 8.756, Average Loss: 1.893, avg. samples / sec: 65370.23
Iteration:    160, Loss function: 8.964, Average Loss: 1.911, avg. samples / sec: 65381.42
Iteration:    160, Loss function: 9.019, Average Loss: 1.909, avg. samples / sec: 65437.62
Iteration:    160, Loss function: 8.949, Average Loss: 1.927, avg. samples / sec: 65227.97
Iteration:    160, Loss function: 8.854, Average Loss: 1.912, avg. samples / sec: 65577.69
Iteration:    160, Loss function: 8.292, Average Loss: 1.912, avg. samples / sec: 65215.47
Iteration:    160, Loss function: 8.740, Average Loss: 1.912, avg. samples / sec: 65306.56
Iteration:    160, Loss function: 8.393, Average Loss: 1.914, avg. samples / sec: 65287.35
Iteration:    160, Loss function: 8.513, Average Loss: 1.910, avg. samples / sec: 65595.30
Iteration:    160, Loss function: 9.606, Average Loss: 1.912, avg. samples / sec: 65173.01
Iteration:    160, Loss function: 8.484, Average Loss: 1.908, avg. samples / sec: 65317.12
Iteration:    160, Loss function: 8.751, Average Loss: 1.905, avg. samples / sec: 65288.38
Iteration:    160, Loss function: 8.948, Average Loss: 1.934, avg. samples / sec: 65232.65
Iteration:    160, Loss function: 9.260, Average Loss: 1.920, avg. samples / sec: 65648.47
Iteration:    160, Loss function: 8.874, Average Loss: 1.915, avg. samples / sec: 65324.84
Iteration:    160, Loss function: 7.970, Average Loss: 1.913, avg. samples / sec: 65264.49
Iteration:    160, Loss function: 8.797, Average Loss: 1.918, avg. samples / sec: 65075.05
Iteration:    160, Loss function: 8.176, Average Loss: 1.912, avg. samples / sec: 65475.44
Iteration:    160, Loss function: 9.045, Average Loss: 1.914, avg. samples / sec: 65174.67
Iteration:    160, Loss function: 8.513, Average Loss: 1.918, avg. samples / sec: 65056.28
Iteration:    160, Loss function: 7.588, Average Loss: 1.904, avg. samples / sec: 65086.65
Iteration:    180, Loss function: 8.514, Average Loss: 2.044, avg. samples / sec: 65849.20
Iteration:    180, Loss function: 8.231, Average Loss: 2.048, avg. samples / sec: 65844.25
Iteration:    180, Loss function: 8.562, Average Loss: 2.036, avg. samples / sec: 66016.17
Iteration:    180, Loss function: 8.938, Average Loss: 2.044, avg. samples / sec: 65843.57
Iteration:    180, Loss function: 8.944, Average Loss: 2.047, avg. samples / sec: 65929.39
Iteration:    180, Loss function: 8.394, Average Loss: 2.048, avg. samples / sec: 65823.86
Iteration:    180, Loss function: 7.924, Average Loss: 2.046, avg. samples / sec: 65913.97
Iteration:    180, Loss function: 8.863, Average Loss: 2.037, avg. samples / sec: 65843.08
Iteration:    180, Loss function: 8.302, Average Loss: 2.051, avg. samples / sec: 65943.92
Iteration:    180, Loss function: 8.416, Average Loss: 2.038, avg. samples / sec: 65626.03
Iteration:    180, Loss function: 8.936, Average Loss: 2.058, avg. samples / sec: 65835.63
Iteration:    180, Loss function: 9.902, Average Loss: 2.049, avg. samples / sec: 65761.41
Iteration:    180, Loss function: 8.226, Average Loss: 2.049, avg. samples / sec: 65663.52
Iteration:    180, Loss function: 8.546, Average Loss: 2.047, avg. samples / sec: 65736.81
Iteration:    180, Loss function: 7.825, Average Loss: 2.029, avg. samples / sec: 65715.29
Iteration:    180, Loss function: 9.523, Average Loss: 2.035, avg. samples / sec: 65694.83
Iteration:    180, Loss function: 9.443, Average Loss: 2.050, avg. samples / sec: 65916.40
Iteration:    180, Loss function: 8.847, Average Loss: 2.042, avg. samples / sec: 65659.20
Iteration:    180, Loss function: 8.237, Average Loss: 2.047, avg. samples / sec: 65723.41
Iteration:    180, Loss function: 8.459, Average Loss: 2.046, avg. samples / sec: 65526.34
Iteration:    180, Loss function: 9.205, Average Loss: 2.053, avg. samples / sec: 65760.49
Iteration:    180, Loss function: 8.377, Average Loss: 2.046, avg. samples / sec: 65656.57
Iteration:    180, Loss function: 8.130, Average Loss: 2.048, avg. samples / sec: 65603.60
Iteration:    180, Loss function: 8.203, Average Loss: 2.043, avg. samples / sec: 65512.72
Iteration:    180, Loss function: 9.194, Average Loss: 2.047, avg. samples / sec: 65563.32
Iteration:    180, Loss function: 8.577, Average Loss: 2.043, avg. samples / sec: 65540.24
Iteration:    180, Loss function: 8.084, Average Loss: 2.052, avg. samples / sec: 65647.30
Iteration:    180, Loss function: 9.584, Average Loss: 2.063, avg. samples / sec: 65513.36
Iteration:    180, Loss function: 8.796, Average Loss: 2.067, avg. samples / sec: 65596.49
Iteration:    180, Loss function: 8.666, Average Loss: 2.036, avg. samples / sec: 65562.40
Iteration:    200, Loss function: 7.705, Average Loss: 2.174, avg. samples / sec: 65873.18
Iteration:    200, Loss function: 7.652, Average Loss: 2.183, avg. samples / sec: 65828.99
Iteration:    200, Loss function: 8.290, Average Loss: 2.167, avg. samples / sec: 65849.29
Iteration:    200, Loss function: 7.618, Average Loss: 2.166, avg. samples / sec: 65843.48
Iteration:    200, Loss function: 8.342, Average Loss: 2.163, avg. samples / sec: 65769.85
Iteration:    200, Loss function: 8.354, Average Loss: 2.171, avg. samples / sec: 65977.48
Iteration:    200, Loss function: 9.051, Average Loss: 2.168, avg. samples / sec: 65727.37
Iteration:    200, Loss function: 9.391, Average Loss: 2.173, avg. samples / sec: 65731.69
Iteration:    200, Loss function: 8.838, Average Loss: 2.175, avg. samples / sec: 65753.31
Iteration:    200, Loss function: 8.690, Average Loss: 2.173, avg. samples / sec: 65714.40
Iteration:    200, Loss function: 8.587, Average Loss: 2.175, avg. samples / sec: 65741.17
Iteration:    200, Loss function: 9.109, Average Loss: 2.173, avg. samples / sec: 65683.47
Iteration:    200, Loss function: 7.613, Average Loss: 2.165, avg. samples / sec: 65825.33
Iteration:    200, Loss function: 7.416, Average Loss: 2.173, avg. samples / sec: 65906.54
Iteration:    200, Loss function: 7.715, Average Loss: 2.193, avg. samples / sec: 65922.79
Iteration:    200, Loss function: 8.585, Average Loss: 2.171, avg. samples / sec: 65840.56
Iteration:    200, Loss function: 8.514, Average Loss: 2.170, avg. samples / sec: 65538.77
Iteration:    200, Loss function: 8.172, Average Loss: 2.186, avg. samples / sec: 65881.74
Iteration:    200, Loss function: 9.592, Average Loss: 2.154, avg. samples / sec: 65637.25
Iteration:    200, Loss function: 7.735, Average Loss: 2.159, avg. samples / sec: 65590.45
Iteration:    200, Loss function: 7.603, Average Loss: 2.165, avg. samples / sec: 65462.67
Iteration:    200, Loss function: 7.369, Average Loss: 2.169, avg. samples / sec: 65614.05
Iteration:    200, Loss function: 7.800, Average Loss: 2.175, avg. samples / sec: 65725.41
Iteration:    200, Loss function: 8.160, Average Loss: 2.167, avg. samples / sec: 65819.31
Iteration:    200, Loss function: 7.934, Average Loss: 2.174, avg. samples / sec: 65651.56
Iteration:    200, Loss function: 8.097, Average Loss: 2.173, avg. samples / sec: 65554.63
Iteration:    200, Loss function: 7.631, Average Loss: 2.158, avg. samples / sec: 65823.24
Iteration:    200, Loss function: 9.373, Average Loss: 2.169, avg. samples / sec: 65674.01
Iteration:    200, Loss function: 7.647, Average Loss: 2.161, avg. samples / sec: 65515.77
Iteration:    200, Loss function: 8.241, Average Loss: 2.171, avg. samples / sec: 65567.38
:::MLL 1558651696.106 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558651696.106 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 8.752, Average Loss: 2.305, avg. samples / sec: 65731.26
Iteration:    220, Loss function: 7.877, Average Loss: 2.291, avg. samples / sec: 65588.95
Iteration:    220, Loss function: 7.840, Average Loss: 2.295, avg. samples / sec: 65488.10
Iteration:    220, Loss function: 8.418, Average Loss: 2.284, avg. samples / sec: 65546.18
Iteration:    220, Loss function: 7.797, Average Loss: 2.286, avg. samples / sec: 65660.49
Iteration:    220, Loss function: 8.487, Average Loss: 2.290, avg. samples / sec: 65541.76
Iteration:    220, Loss function: 7.364, Average Loss: 2.276, avg. samples / sec: 65761.78
Iteration:    220, Loss function: 8.469, Average Loss: 2.291, avg. samples / sec: 65517.54
Iteration:    220, Loss function: 8.206, Average Loss: 2.285, avg. samples / sec: 65446.43
Iteration:    220, Loss function: 8.726, Average Loss: 2.292, avg. samples / sec: 65698.26
Iteration:    220, Loss function: 8.384, Average Loss: 2.284, avg. samples / sec: 65561.95
Iteration:    220, Loss function: 8.657, Average Loss: 2.291, avg. samples / sec: 65572.07
Iteration:    220, Loss function: 7.852, Average Loss: 2.273, avg. samples / sec: 65661.80
Iteration:    220, Loss function: 7.995, Average Loss: 2.282, avg. samples / sec: 65407.64
Iteration:    220, Loss function: 8.419, Average Loss: 2.293, avg. samples / sec: 65438.65
Iteration:    220, Loss function: 8.031, Average Loss: 2.284, avg. samples / sec: 65782.69
Iteration:    220, Loss function: 6.968, Average Loss: 2.285, avg. samples / sec: 65541.70
Iteration:    220, Loss function: 7.830, Average Loss: 2.282, avg. samples / sec: 65648.65
Iteration:    220, Loss function: 8.107, Average Loss: 2.292, avg. samples / sec: 65593.16
Iteration:    220, Loss function: 7.462, Average Loss: 2.288, avg. samples / sec: 65407.13
Iteration:    220, Loss function: 8.758, Average Loss: 2.283, avg. samples / sec: 65563.50
Iteration:    220, Loss function: 8.295, Average Loss: 2.276, avg. samples / sec: 65552.98
Iteration:    220, Loss function: 8.043, Average Loss: 2.302, avg. samples / sec: 65339.47
Iteration:    220, Loss function: 9.390, Average Loss: 2.291, avg. samples / sec: 65505.75
Iteration:    220, Loss function: 7.728, Average Loss: 2.281, avg. samples / sec: 65500.94
Iteration:    220, Loss function: 8.109, Average Loss: 2.282, avg. samples / sec: 65506.03
Iteration:    220, Loss function: 8.383, Average Loss: 2.278, avg. samples / sec: 65261.98
Iteration:    220, Loss function: 7.515, Average Loss: 2.307, avg. samples / sec: 65379.15
Iteration:    220, Loss function: 8.063, Average Loss: 2.287, avg. samples / sec: 65294.30
Iteration:    220, Loss function: 8.482, Average Loss: 2.274, avg. samples / sec: 65185.01
Iteration:    240, Loss function: 7.638, Average Loss: 2.416, avg. samples / sec: 64493.56
Iteration:    240, Loss function: 7.868, Average Loss: 2.416, avg. samples / sec: 64625.49
Iteration:    240, Loss function: 9.032, Average Loss: 2.393, avg. samples / sec: 64503.92
Iteration:    240, Loss function: 8.389, Average Loss: 2.407, avg. samples / sec: 64476.15
Iteration:    240, Loss function: 8.452, Average Loss: 2.401, avg. samples / sec: 64472.02
Iteration:    240, Loss function: 7.145, Average Loss: 2.404, avg. samples / sec: 64421.77
Iteration:    240, Loss function: 8.266, Average Loss: 2.403, avg. samples / sec: 64624.07
Iteration:    240, Loss function: 9.813, Average Loss: 2.404, avg. samples / sec: 64393.16
Iteration:    240, Loss function: 8.337, Average Loss: 2.402, avg. samples / sec: 64518.66
Iteration:    240, Loss function: 9.556, Average Loss: 2.412, avg. samples / sec: 64428.90
Iteration:    240, Loss function: 8.681, Average Loss: 2.391, avg. samples / sec: 64619.83
Iteration:    240, Loss function: 7.603, Average Loss: 2.394, avg. samples / sec: 64502.86
Iteration:    240, Loss function: 8.310, Average Loss: 2.398, avg. samples / sec: 64435.73
Iteration:    240, Loss function: 7.797, Average Loss: 2.409, avg. samples / sec: 64438.18
Iteration:    240, Loss function: 7.746, Average Loss: 2.405, avg. samples / sec: 64341.06
Iteration:    240, Loss function: 8.836, Average Loss: 2.403, avg. samples / sec: 64427.04
Iteration:    240, Loss function: 8.987, Average Loss: 2.395, avg. samples / sec: 64542.03
Iteration:    240, Loss function: 8.251, Average Loss: 2.405, avg. samples / sec: 64639.51
Iteration:    240, Loss function: 9.202, Average Loss: 2.397, avg. samples / sec: 64549.21
Iteration:    240, Loss function: 8.208, Average Loss: 2.396, avg. samples / sec: 64449.91
Iteration:    240, Loss function: 9.232, Average Loss: 2.412, avg. samples / sec: 64378.48
Iteration:    240, Loss function: 8.705, Average Loss: 2.425, avg. samples / sec: 64525.33
Iteration:    240, Loss function: 7.306, Average Loss: 2.402, avg. samples / sec: 64354.20
Iteration:    240, Loss function: 9.166, Average Loss: 2.390, avg. samples / sec: 64745.26
Iteration:    240, Loss function: 9.134, Average Loss: 2.392, avg. samples / sec: 64301.73
Iteration:    240, Loss function: 9.052, Average Loss: 2.400, avg. samples / sec: 64292.16
Iteration:    240, Loss function: 9.338, Average Loss: 2.387, avg. samples / sec: 64354.61
Iteration:    240, Loss function: 7.502, Average Loss: 2.404, avg. samples / sec: 64191.86
Iteration:    240, Loss function: 8.046, Average Loss: 2.402, avg. samples / sec: 64230.42
Iteration:    240, Loss function: 8.985, Average Loss: 2.407, avg. samples / sec: 64254.38
Iteration:    260, Loss function: 7.609, Average Loss: 2.512, avg. samples / sec: 65603.21
Iteration:    260, Loss function: 7.516, Average Loss: 2.502, avg. samples / sec: 65740.09
Iteration:    260, Loss function: 8.721, Average Loss: 2.523, avg. samples / sec: 65584.10
Iteration:    260, Loss function: 8.607, Average Loss: 2.509, avg. samples / sec: 65468.50
Iteration:    260, Loss function: 7.810, Average Loss: 2.521, avg. samples / sec: 65579.92
Iteration:    260, Loss function: 7.308, Average Loss: 2.503, avg. samples / sec: 65533.65
Iteration:    260, Loss function: 7.396, Average Loss: 2.527, avg. samples / sec: 65386.67
Iteration:    260, Loss function: 8.053, Average Loss: 2.526, avg. samples / sec: 65426.96
Iteration:    260, Loss function: 8.048, Average Loss: 2.516, avg. samples / sec: 65522.35
Iteration:    260, Loss function: 7.449, Average Loss: 2.517, avg. samples / sec: 65490.65
Iteration:    260, Loss function: 7.413, Average Loss: 2.515, avg. samples / sec: 65475.26
Iteration:    260, Loss function: 8.482, Average Loss: 2.517, avg. samples / sec: 65514.16
Iteration:    260, Loss function: 7.440, Average Loss: 2.513, avg. samples / sec: 65454.52
Iteration:    260, Loss function: 7.250, Average Loss: 2.513, avg. samples / sec: 65414.59
Iteration:    260, Loss function: 7.114, Average Loss: 2.518, avg. samples / sec: 65657.34
Iteration:    260, Loss function: 7.871, Average Loss: 2.516, avg. samples / sec: 65577.75
Iteration:    260, Loss function: 8.336, Average Loss: 2.520, avg. samples / sec: 65437.22
Iteration:    260, Loss function: 8.524, Average Loss: 2.520, avg. samples / sec: 65704.81
Iteration:    260, Loss function: 6.547, Average Loss: 2.501, avg. samples / sec: 65568.47
Iteration:    260, Loss function: 7.441, Average Loss: 2.510, avg. samples / sec: 65489.59
Iteration:    260, Loss function: 7.416, Average Loss: 2.533, avg. samples / sec: 65537.07
Iteration:    260, Loss function: 9.054, Average Loss: 2.508, avg. samples / sec: 65411.22
Iteration:    260, Loss function: 8.112, Average Loss: 2.512, avg. samples / sec: 65351.80
Iteration:    260, Loss function: 8.657, Average Loss: 2.507, avg. samples / sec: 65493.73
Iteration:    260, Loss function: 7.769, Average Loss: 2.522, avg. samples / sec: 65280.88
Iteration:    260, Loss function: 7.792, Average Loss: 2.506, avg. samples / sec: 65315.00
Iteration:    260, Loss function: 8.050, Average Loss: 2.525, avg. samples / sec: 65359.53
Iteration:    260, Loss function: 7.813, Average Loss: 2.522, avg. samples / sec: 65186.94
Iteration:    260, Loss function: 8.055, Average Loss: 2.511, avg. samples / sec: 65397.17
Iteration:    260, Loss function: 7.666, Average Loss: 2.515, avg. samples / sec: 65293.22
:::MLL 1558651697.914 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558651697.914 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 8.138, Average Loss: 2.620, avg. samples / sec: 65482.71
Iteration:    280, Loss function: 8.117, Average Loss: 2.629, avg. samples / sec: 65116.15
Iteration:    280, Loss function: 7.654, Average Loss: 2.600, avg. samples / sec: 65081.87
Iteration:    280, Loss function: 8.565, Average Loss: 2.617, avg. samples / sec: 65113.93
Iteration:    280, Loss function: 7.324, Average Loss: 2.602, avg. samples / sec: 65062.58
Iteration:    280, Loss function: 6.707, Average Loss: 2.607, avg. samples / sec: 65005.44
Iteration:    280, Loss function: 6.956, Average Loss: 2.625, avg. samples / sec: 65029.23
Iteration:    280, Loss function: 7.375, Average Loss: 2.601, avg. samples / sec: 65263.49
Iteration:    280, Loss function: 7.615, Average Loss: 2.616, avg. samples / sec: 65080.25
Iteration:    280, Loss function: 7.371, Average Loss: 2.604, avg. samples / sec: 65208.17
Iteration:    280, Loss function: 7.124, Average Loss: 2.632, avg. samples / sec: 65100.36
Iteration:    280, Loss function: 7.637, Average Loss: 2.602, avg. samples / sec: 65098.68
Iteration:    280, Loss function: 8.006, Average Loss: 2.622, avg. samples / sec: 65077.94
Iteration:    280, Loss function: 7.404, Average Loss: 2.618, avg. samples / sec: 65479.03
Iteration:    280, Loss function: 9.155, Average Loss: 2.617, avg. samples / sec: 65012.28
Iteration:    280, Loss function: 8.092, Average Loss: 2.613, avg. samples / sec: 64911.19
Iteration:    280, Loss function: 8.079, Average Loss: 2.609, avg. samples / sec: 65114.41
Iteration:    280, Loss function: 7.544, Average Loss: 2.611, avg. samples / sec: 65060.33
Iteration:    280, Loss function: 7.678, Average Loss: 2.626, avg. samples / sec: 65190.80
Iteration:    280, Loss function: 7.448, Average Loss: 2.611, avg. samples / sec: 64943.52
Iteration:    280, Loss function: 7.752, Average Loss: 2.621, avg. samples / sec: 64882.05
Iteration:    280, Loss function: 9.392, Average Loss: 2.619, avg. samples / sec: 64972.96
Iteration:    280, Loss function: 6.969, Average Loss: 2.613, avg. samples / sec: 65038.86
Iteration:    280, Loss function: 7.650, Average Loss: 2.613, avg. samples / sec: 64842.41
Iteration:    280, Loss function: 6.754, Average Loss: 2.610, avg. samples / sec: 65180.66
Iteration:    280, Loss function: 7.804, Average Loss: 2.625, avg. samples / sec: 64822.63
Iteration:    280, Loss function: 7.903, Average Loss: 2.618, avg. samples / sec: 64931.11
Iteration:    280, Loss function: 8.106, Average Loss: 2.626, avg. samples / sec: 65014.08
Iteration:    280, Loss function: 8.274, Average Loss: 2.613, avg. samples / sec: 64843.18
Iteration:    280, Loss function: 7.996, Average Loss: 2.613, avg. samples / sec: 64583.76
Iteration:    300, Loss function: 7.853, Average Loss: 2.717, avg. samples / sec: 65365.35
Iteration:    300, Loss function: 7.644, Average Loss: 2.704, avg. samples / sec: 65201.35
Iteration:    300, Loss function: 7.803, Average Loss: 2.721, avg. samples / sec: 65285.96
Iteration:    300, Loss function: 7.946, Average Loss: 2.709, avg. samples / sec: 65115.46
Iteration:    300, Loss function: 8.114, Average Loss: 2.723, avg. samples / sec: 65354.38
Iteration:    300, Loss function: 7.004, Average Loss: 2.709, avg. samples / sec: 65213.03
Iteration:    300, Loss function: 7.677, Average Loss: 2.697, avg. samples / sec: 65094.11
Iteration:    300, Loss function: 7.542, Average Loss: 2.718, avg. samples / sec: 65153.75
Iteration:    300, Loss function: 7.638, Average Loss: 2.701, avg. samples / sec: 65237.54
Iteration:    300, Loss function: 8.278, Average Loss: 2.710, avg. samples / sec: 65401.12
Iteration:    300, Loss function: 6.397, Average Loss: 2.698, avg. samples / sec: 65096.78
Iteration:    300, Loss function: 7.041, Average Loss: 2.702, avg. samples / sec: 65322.72
Iteration:    300, Loss function: 7.925, Average Loss: 2.710, avg. samples / sec: 65160.65
Iteration:    300, Loss function: 5.605, Average Loss: 2.708, avg. samples / sec: 65163.82
Iteration:    300, Loss function: 7.129, Average Loss: 2.698, avg. samples / sec: 65128.46
Iteration:    300, Loss function: 7.060, Average Loss: 2.718, avg. samples / sec: 65333.38
Iteration:    300, Loss function: 6.709, Average Loss: 2.716, avg. samples / sec: 65222.02
Iteration:    300, Loss function: 7.682, Average Loss: 2.714, avg. samples / sec: 64969.48
Iteration:    300, Loss function: 7.481, Average Loss: 2.723, avg. samples / sec: 64989.14
Iteration:    300, Loss function: 8.504, Average Loss: 2.710, avg. samples / sec: 65118.74
Iteration:    300, Loss function: 7.478, Average Loss: 2.706, avg. samples / sec: 65229.15
Iteration:    300, Loss function: 7.516, Average Loss: 2.707, avg. samples / sec: 65139.48
Iteration:    300, Loss function: 6.926, Average Loss: 2.704, avg. samples / sec: 65210.40
Iteration:    300, Loss function: 6.412, Average Loss: 2.695, avg. samples / sec: 65082.32
Iteration:    300, Loss function: 7.256, Average Loss: 2.712, avg. samples / sec: 65226.07
Iteration:    300, Loss function: 8.298, Average Loss: 2.709, avg. samples / sec: 65496.65
Iteration:    300, Loss function: 7.985, Average Loss: 2.725, avg. samples / sec: 65011.08
Iteration:    300, Loss function: 7.470, Average Loss: 2.709, avg. samples / sec: 65017.32
Iteration:    300, Loss function: 7.733, Average Loss: 2.707, avg. samples / sec: 65028.75
Iteration:    300, Loss function: 6.710, Average Loss: 2.693, avg. samples / sec: 64700.85
Iteration:    320, Loss function: 7.601, Average Loss: 2.811, avg. samples / sec: 66167.43
Iteration:    320, Loss function: 6.585, Average Loss: 2.793, avg. samples / sec: 66130.36
Iteration:    320, Loss function: 6.629, Average Loss: 2.798, avg. samples / sec: 66125.48
Iteration:    320, Loss function: 7.723, Average Loss: 2.804, avg. samples / sec: 66379.04
Iteration:    320, Loss function: 6.777, Average Loss: 2.802, avg. samples / sec: 66053.86
Iteration:    320, Loss function: 7.972, Average Loss: 2.811, avg. samples / sec: 66163.45
Iteration:    320, Loss function: 8.073, Average Loss: 2.817, avg. samples / sec: 66041.20
Iteration:    320, Loss function: 6.256, Average Loss: 2.810, avg. samples / sec: 66001.70
Iteration:    320, Loss function: 6.929, Average Loss: 2.802, avg. samples / sec: 66065.16
Iteration:    320, Loss function: 6.771, Average Loss: 2.806, avg. samples / sec: 66097.01
Iteration:    320, Loss function: 7.517, Average Loss: 2.808, avg. samples / sec: 66139.36
Iteration:    320, Loss function: 9.943, Average Loss: 2.820, avg. samples / sec: 66036.90
Iteration:    320, Loss function: 7.235, Average Loss: 2.789, avg. samples / sec: 66539.88
Iteration:    320, Loss function: 8.253, Average Loss: 2.807, avg. samples / sec: 66174.57
Iteration:    320, Loss function: 8.068, Average Loss: 2.814, avg. samples / sec: 66047.05
Iteration:    320, Loss function: 7.732, Average Loss: 2.799, avg. samples / sec: 66133.64
Iteration:    320, Loss function: 7.243, Average Loss: 2.803, avg. samples / sec: 66125.55
Iteration:    320, Loss function: 7.990, Average Loss: 2.792, avg. samples / sec: 66077.18
Iteration:    320, Loss function: 7.932, Average Loss: 2.801, avg. samples / sec: 66128.83
Iteration:    320, Loss function: 7.073, Average Loss: 2.793, avg. samples / sec: 66025.17
Iteration:    320, Loss function: 7.695, Average Loss: 2.820, avg. samples / sec: 66102.47
Iteration:    320, Loss function: 7.137, Average Loss: 2.803, avg. samples / sec: 66138.46
Iteration:    320, Loss function: 7.875, Average Loss: 2.809, avg. samples / sec: 65961.94
Iteration:    320, Loss function: 7.304, Average Loss: 2.801, avg. samples / sec: 66001.08
Iteration:    320, Loss function: 7.438, Average Loss: 2.823, avg. samples / sec: 66126.76
Iteration:    320, Loss function: 7.674, Average Loss: 2.791, avg. samples / sec: 65919.49
Iteration:    320, Loss function: 8.275, Average Loss: 2.791, avg. samples / sec: 66043.98
Iteration:    320, Loss function: 8.390, Average Loss: 2.804, avg. samples / sec: 65929.88
Iteration:    320, Loss function: 6.776, Average Loss: 2.805, avg. samples / sec: 66092.27
Iteration:    320, Loss function: 8.195, Average Loss: 2.803, avg. samples / sec: 65878.75
Iteration:    340, Loss function: 7.010, Average Loss: 2.901, avg. samples / sec: 65816.79
Iteration:    340, Loss function: 8.391, Average Loss: 2.914, avg. samples / sec: 65905.52
Iteration:    340, Loss function: 7.290, Average Loss: 2.893, avg. samples / sec: 65846.77
Iteration:    340, Loss function: 7.572, Average Loss: 2.908, avg. samples / sec: 65780.90
Iteration:    340, Loss function: 6.654, Average Loss: 2.890, avg. samples / sec: 65854.95
Iteration:    340, Loss function: 7.462, Average Loss: 2.893, avg. samples / sec: 65668.84
Iteration:    340, Loss function: 7.303, Average Loss: 2.901, avg. samples / sec: 65726.23
Iteration:    340, Loss function: 6.372, Average Loss: 2.888, avg. samples / sec: 65645.84
Iteration:    340, Loss function: 7.929, Average Loss: 2.894, avg. samples / sec: 65674.23
Iteration:    340, Loss function: 6.629, Average Loss: 2.900, avg. samples / sec: 65648.25
Iteration:    340, Loss function: 8.464, Average Loss: 2.889, avg. samples / sec: 65618.60
Iteration:    340, Loss function: 6.551, Average Loss: 2.876, avg. samples / sec: 65799.95
Iteration:    340, Loss function: 7.098, Average Loss: 2.894, avg. samples / sec: 65656.02
Iteration:    340, Loss function: 7.287, Average Loss: 2.887, avg. samples / sec: 65672.30
Iteration:    340, Loss function: 8.532, Average Loss: 2.883, avg. samples / sec: 65760.61
Iteration:    340, Loss function: 7.551, Average Loss: 2.898, avg. samples / sec: 65677.16
Iteration:    340, Loss function: 5.839, Average Loss: 2.889, avg. samples / sec: 65652.38
Iteration:    340, Loss function: 6.881, Average Loss: 2.884, avg. samples / sec: 65557.74
Iteration:    340, Loss function: 7.447, Average Loss: 2.901, avg. samples / sec: 65540.05
Iteration:    340, Loss function: 6.668, Average Loss: 2.909, avg. samples / sec: 65589.32
Iteration:    340, Loss function: 6.564, Average Loss: 2.893, avg. samples / sec: 65573.51
Iteration:    340, Loss function: 6.864, Average Loss: 2.887, avg. samples / sec: 65673.89
Iteration:    340, Loss function: 5.382, Average Loss: 2.890, avg. samples / sec: 65720.81
Iteration:    340, Loss function: 7.585, Average Loss: 2.882, avg. samples / sec: 65604.73
Iteration:    340, Loss function: 7.974, Average Loss: 2.894, avg. samples / sec: 65838.74
Iteration:    340, Loss function: 6.605, Average Loss: 2.893, avg. samples / sec: 65576.96
Iteration:    340, Loss function: 7.522, Average Loss: 2.885, avg. samples / sec: 65590.87
Iteration:    340, Loss function: 6.956, Average Loss: 2.889, avg. samples / sec: 65520.06
Iteration:    340, Loss function: 6.270, Average Loss: 2.878, avg. samples / sec: 65548.83
Iteration:    340, Loss function: 6.451, Average Loss: 2.883, avg. samples / sec: 65558.93
:::MLL 1558651699.708 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558651699.708 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 8.232, Average Loss: 2.985, avg. samples / sec: 65637.89
Iteration:    360, Loss function: 6.692, Average Loss: 2.981, avg. samples / sec: 65413.74
Iteration:    360, Loss function: 7.038, Average Loss: 2.971, avg. samples / sec: 65537.16
Iteration:    360, Loss function: 6.065, Average Loss: 2.970, avg. samples / sec: 65566.61
Iteration:    360, Loss function: 8.153, Average Loss: 2.976, avg. samples / sec: 65456.31
Iteration:    360, Loss function: 6.767, Average Loss: 2.997, avg. samples / sec: 65365.66
Iteration:    360, Loss function: 5.801, Average Loss: 2.963, avg. samples / sec: 65613.07
Iteration:    360, Loss function: 7.617, Average Loss: 2.979, avg. samples / sec: 65467.14
Iteration:    360, Loss function: 7.031, Average Loss: 2.977, avg. samples / sec: 65344.62
Iteration:    360, Loss function: 7.943, Average Loss: 2.978, avg. samples / sec: 65562.86
Iteration:    360, Loss function: 6.523, Average Loss: 2.984, avg. samples / sec: 65531.28
Iteration:    360, Loss function: 6.148, Average Loss: 2.975, avg. samples / sec: 65563.90
Iteration:    360, Loss function: 6.006, Average Loss: 2.988, avg. samples / sec: 65519.30
Iteration:    360, Loss function: 6.876, Average Loss: 2.964, avg. samples / sec: 65403.79
Iteration:    360, Loss function: 6.447, Average Loss: 2.967, avg. samples / sec: 65558.68
Iteration:    360, Loss function: 6.390, Average Loss: 2.972, avg. samples / sec: 65368.60
Iteration:    360, Loss function: 7.912, Average Loss: 2.962, avg. samples / sec: 65412.77
Iteration:    360, Loss function: 7.002, Average Loss: 2.970, avg. samples / sec: 65457.37
Iteration:    360, Loss function: 7.409, Average Loss: 2.970, avg. samples / sec: 65502.22
Iteration:    360, Loss function: 7.841, Average Loss: 2.978, avg. samples / sec: 65496.89
Iteration:    360, Loss function: 6.804, Average Loss: 2.981, avg. samples / sec: 65367.69
Iteration:    360, Loss function: 7.323, Average Loss: 2.996, avg. samples / sec: 65302.56
Iteration:    360, Loss function: 6.917, Average Loss: 2.974, avg. samples / sec: 65472.88
Iteration:    360, Loss function: 6.698, Average Loss: 2.966, avg. samples / sec: 65415.41
Iteration:    360, Loss function: 7.104, Average Loss: 2.972, avg. samples / sec: 65471.06
Iteration:    360, Loss function: 9.674, Average Loss: 2.979, avg. samples / sec: 65346.56
Iteration:    360, Loss function: 8.352, Average Loss: 2.984, avg. samples / sec: 65347.14
Iteration:    360, Loss function: 7.339, Average Loss: 2.961, avg. samples / sec: 65464.03
Iteration:    360, Loss function: 7.016, Average Loss: 2.976, avg. samples / sec: 65430.21
Iteration:    360, Loss function: 7.587, Average Loss: 2.972, avg. samples / sec: 65324.57
Iteration:    380, Loss function: 6.025, Average Loss: 3.063, avg. samples / sec: 66174.95
Iteration:    380, Loss function: 8.158, Average Loss: 3.046, avg. samples / sec: 66092.67
Iteration:    380, Loss function: 6.281, Average Loss: 3.053, avg. samples / sec: 66040.42
Iteration:    380, Loss function: 6.550, Average Loss: 3.059, avg. samples / sec: 66146.03
Iteration:    380, Loss function: 6.121, Average Loss: 3.057, avg. samples / sec: 65994.28
Iteration:    380, Loss function: 6.590, Average Loss: 3.061, avg. samples / sec: 65893.14
Iteration:    380, Loss function: 6.897, Average Loss: 3.061, avg. samples / sec: 66101.57
Iteration:    380, Loss function: 6.308, Average Loss: 3.043, avg. samples / sec: 65907.77
Iteration:    380, Loss function: 6.935, Average Loss: 3.058, avg. samples / sec: 65873.89
Iteration:    380, Loss function: 6.111, Average Loss: 3.075, avg. samples / sec: 66042.13
Iteration:    380, Loss function: 6.086, Average Loss: 3.051, avg. samples / sec: 65892.86
Iteration:    380, Loss function: 6.743, Average Loss: 3.046, avg. samples / sec: 66022.63
Iteration:    380, Loss function: 6.644, Average Loss: 3.056, avg. samples / sec: 65939.63
Iteration:    380, Loss function: 6.823, Average Loss: 3.056, avg. samples / sec: 65863.20
Iteration:    380, Loss function: 7.029, Average Loss: 3.047, avg. samples / sec: 65937.31
Iteration:    380, Loss function: 6.136, Average Loss: 3.078, avg. samples / sec: 65862.62
Iteration:    380, Loss function: 7.534, Average Loss: 3.057, avg. samples / sec: 65963.21
Iteration:    380, Loss function: 7.259, Average Loss: 3.049, avg. samples / sec: 66068.75
Iteration:    380, Loss function: 6.494, Average Loss: 3.056, avg. samples / sec: 66025.54
Iteration:    380, Loss function: 7.152, Average Loss: 3.057, avg. samples / sec: 65948.55
Iteration:    380, Loss function: 6.961, Average Loss: 3.052, avg. samples / sec: 65955.74
Iteration:    380, Loss function: 6.617, Average Loss: 3.064, avg. samples / sec: 65741.01
Iteration:    380, Loss function: 7.381, Average Loss: 3.044, avg. samples / sec: 65901.09
Iteration:    380, Loss function: 6.738, Average Loss: 3.054, avg. samples / sec: 65851.82
Iteration:    380, Loss function: 7.143, Average Loss: 3.061, avg. samples / sec: 65840.96
Iteration:    380, Loss function: 5.943, Average Loss: 3.041, avg. samples / sec: 65888.14
Iteration:    380, Loss function: 7.472, Average Loss: 3.046, avg. samples / sec: 65873.79
Iteration:    380, Loss function: 6.900, Average Loss: 3.044, avg. samples / sec: 65955.37
Iteration:    380, Loss function: 6.706, Average Loss: 3.050, avg. samples / sec: 65809.99
Iteration:    380, Loss function: 6.651, Average Loss: 3.069, avg. samples / sec: 65651.98
Iteration:    400, Loss function: 6.961, Average Loss: 3.140, avg. samples / sec: 65599.88
Iteration:    400, Loss function: 7.970, Average Loss: 3.134, avg. samples / sec: 65780.38
Iteration:    400, Loss function: 6.096, Average Loss: 3.124, avg. samples / sec: 65642.38
Iteration:    400, Loss function: 7.351, Average Loss: 3.148, avg. samples / sec: 65809.90
Iteration:    400, Loss function: 6.496, Average Loss: 3.132, avg. samples / sec: 65709.10
Iteration:    400, Loss function: 6.620, Average Loss: 3.134, avg. samples / sec: 65735.52
Iteration:    400, Loss function: 6.836, Average Loss: 3.135, avg. samples / sec: 65614.48
Iteration:    400, Loss function: 6.978, Average Loss: 3.127, avg. samples / sec: 65670.89
Iteration:    400, Loss function: 6.630, Average Loss: 3.150, avg. samples / sec: 65987.73
Iteration:    400, Loss function: 5.736, Average Loss: 3.131, avg. samples / sec: 65746.47
Iteration:    400, Loss function: 6.765, Average Loss: 3.158, avg. samples / sec: 65716.30
Iteration:    400, Loss function: 7.477, Average Loss: 3.137, avg. samples / sec: 65747.70
Iteration:    400, Loss function: 6.639, Average Loss: 3.157, avg. samples / sec: 65645.50
Iteration:    400, Loss function: 6.496, Average Loss: 3.126, avg. samples / sec: 65729.24
Iteration:    400, Loss function: 6.620, Average Loss: 3.122, avg. samples / sec: 65739.82
Iteration:    400, Loss function: 6.969, Average Loss: 3.136, avg. samples / sec: 65568.60
Iteration:    400, Loss function: 6.847, Average Loss: 3.117, avg. samples / sec: 65739.54
Iteration:    400, Loss function: 7.041, Average Loss: 3.126, avg. samples / sec: 65700.28
Iteration:    400, Loss function: 6.390, Average Loss: 3.129, avg. samples / sec: 65516.14
Iteration:    400, Loss function: 6.616, Average Loss: 3.126, avg. samples / sec: 65652.05
Iteration:    400, Loss function: 6.592, Average Loss: 3.125, avg. samples / sec: 65753.77
Iteration:    400, Loss function: 7.142, Average Loss: 3.135, avg. samples / sec: 65678.76
Iteration:    400, Loss function: 7.360, Average Loss: 3.120, avg. samples / sec: 65596.00
Iteration:    400, Loss function: 7.478, Average Loss: 3.140, avg. samples / sec: 65539.93
Iteration:    400, Loss function: 7.600, Average Loss: 3.139, avg. samples / sec: 65667.52
Iteration:    400, Loss function: 7.040, Average Loss: 3.132, avg. samples / sec: 65663.58
Iteration:    400, Loss function: 5.723, Average Loss: 3.125, avg. samples / sec: 65661.86
Iteration:    400, Loss function: 6.576, Average Loss: 3.135, avg. samples / sec: 65480.88
Iteration:    400, Loss function: 7.280, Average Loss: 3.134, avg. samples / sec: 65696.24
Iteration:    400, Loss function: 7.192, Average Loss: 3.125, avg. samples / sec: 65542.89
:::MLL 1558651701.499 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558651701.500 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 6.025, Average Loss: 3.210, avg. samples / sec: 65611.36
Iteration:    420, Loss function: 6.478, Average Loss: 3.218, avg. samples / sec: 65379.79
Iteration:    420, Loss function: 8.044, Average Loss: 3.198, avg. samples / sec: 65362.41
Iteration:    420, Loss function: 7.205, Average Loss: 3.191, avg. samples / sec: 65482.01
Iteration:    420, Loss function: 6.224, Average Loss: 3.206, avg. samples / sec: 65432.36
Iteration:    420, Loss function: 6.250, Average Loss: 3.200, avg. samples / sec: 65425.74
Iteration:    420, Loss function: 6.513, Average Loss: 3.206, avg. samples / sec: 65421.40
Iteration:    420, Loss function: 6.520, Average Loss: 3.201, avg. samples / sec: 65316.21
Iteration:    420, Loss function: 8.072, Average Loss: 3.194, avg. samples / sec: 65447.71
Iteration:    420, Loss function: 6.658, Average Loss: 3.214, avg. samples / sec: 65229.06
Iteration:    420, Loss function: 5.592, Average Loss: 3.234, avg. samples / sec: 65339.23
Iteration:    420, Loss function: 6.612, Average Loss: 3.203, avg. samples / sec: 65225.52
Iteration:    420, Loss function: 5.954, Average Loss: 3.206, avg. samples / sec: 65283.02
Iteration:    420, Loss function: 7.759, Average Loss: 3.195, avg. samples / sec: 65322.48
Iteration:    420, Loss function: 6.067, Average Loss: 3.211, avg. samples / sec: 65368.02
Iteration:    420, Loss function: 7.126, Average Loss: 3.191, avg. samples / sec: 65315.03
Iteration:    420, Loss function: 7.150, Average Loss: 3.198, avg. samples / sec: 65338.83
Iteration:    420, Loss function: 6.145, Average Loss: 3.208, avg. samples / sec: 65332.75
Iteration:    420, Loss function: 7.107, Average Loss: 3.206, avg. samples / sec: 65274.40
Iteration:    420, Loss function: 6.329, Average Loss: 3.195, avg. samples / sec: 65418.27
Iteration:    420, Loss function: 5.645, Average Loss: 3.198, avg. samples / sec: 65242.64
Iteration:    420, Loss function: 7.308, Average Loss: 3.207, avg. samples / sec: 65367.44
Iteration:    420, Loss function: 7.220, Average Loss: 3.231, avg. samples / sec: 65238.42
Iteration:    420, Loss function: 6.230, Average Loss: 3.221, avg. samples / sec: 65201.93
Iteration:    420, Loss function: 7.327, Average Loss: 3.195, avg. samples / sec: 65247.18
Iteration:    420, Loss function: 6.986, Average Loss: 3.200, avg. samples / sec: 65253.76
Iteration:    420, Loss function: 7.054, Average Loss: 3.199, avg. samples / sec: 65219.52
Iteration:    420, Loss function: 8.050, Average Loss: 3.206, avg. samples / sec: 65156.01
Iteration:    420, Loss function: 6.123, Average Loss: 3.206, avg. samples / sec: 65138.25
Iteration:    420, Loss function: 7.015, Average Loss: 3.208, avg. samples / sec: 64583.05
Iteration:    440, Loss function: 6.503, Average Loss: 3.266, avg. samples / sec: 65684.05
Iteration:    440, Loss function: 6.163, Average Loss: 3.270, avg. samples / sec: 65729.21
Iteration:    440, Loss function: 7.134, Average Loss: 3.277, avg. samples / sec: 65697.28
Iteration:    440, Loss function: 5.576, Average Loss: 3.264, avg. samples / sec: 65681.14
Iteration:    440, Loss function: 6.909, Average Loss: 3.287, avg. samples / sec: 65863.08
Iteration:    440, Loss function: 6.742, Average Loss: 3.266, avg. samples / sec: 65824.75
Iteration:    440, Loss function: 8.714, Average Loss: 3.277, avg. samples / sec: 65941.02
Iteration:    440, Loss function: 5.854, Average Loss: 3.284, avg. samples / sec: 65613.75
Iteration:    440, Loss function: 7.252, Average Loss: 3.267, avg. samples / sec: 65722.68
Iteration:    440, Loss function: 6.705, Average Loss: 3.299, avg. samples / sec: 65820.35
Iteration:    440, Loss function: 5.809, Average Loss: 3.269, avg. samples / sec: 65764.24
Iteration:    440, Loss function: 6.830, Average Loss: 3.262, avg. samples / sec: 65618.60
Iteration:    440, Loss function: 7.435, Average Loss: 3.252, avg. samples / sec: 65727.80
Iteration:    440, Loss function: 5.810, Average Loss: 3.263, avg. samples / sec: 65800.16
Iteration:    440, Loss function: 6.177, Average Loss: 3.280, avg. samples / sec: 65513.00
Iteration:    440, Loss function: 5.641, Average Loss: 3.305, avg. samples / sec: 65655.44
Iteration:    440, Loss function: 5.883, Average Loss: 3.268, avg. samples / sec: 65760.49
Iteration:    440, Loss function: 6.566, Average Loss: 3.265, avg. samples / sec: 65908.88
Iteration:    440, Loss function: 6.306, Average Loss: 3.272, avg. samples / sec: 66392.80
Iteration:    440, Loss function: 6.391, Average Loss: 3.278, avg. samples / sec: 65669.18
Iteration:    440, Loss function: 6.682, Average Loss: 3.284, avg. samples / sec: 65631.50
Iteration:    440, Loss function: 6.521, Average Loss: 3.280, avg. samples / sec: 65677.65
Iteration:    440, Loss function: 6.122, Average Loss: 3.271, avg. samples / sec: 65626.06
Iteration:    440, Loss function: 6.806, Average Loss: 3.273, avg. samples / sec: 65748.50
Iteration:    440, Loss function: 5.745, Average Loss: 3.259, avg. samples / sec: 65652.87
Iteration:    440, Loss function: 5.354, Average Loss: 3.260, avg. samples / sec: 65582.78
Iteration:    440, Loss function: 5.589, Average Loss: 3.271, avg. samples / sec: 65510.20
Iteration:    440, Loss function: 6.910, Average Loss: 3.278, avg. samples / sec: 65605.77
Iteration:    440, Loss function: 6.835, Average Loss: 3.269, avg. samples / sec: 65623.95
Iteration:    440, Loss function: 5.809, Average Loss: 3.273, avg. samples / sec: 65556.91
Iteration:    460, Loss function: 7.055, Average Loss: 3.355, avg. samples / sec: 66054.66
Iteration:    460, Loss function: 7.106, Average Loss: 3.326, avg. samples / sec: 66177.37
Iteration:    460, Loss function: 6.557, Average Loss: 3.337, avg. samples / sec: 65981.49
Iteration:    460, Loss function: 6.119, Average Loss: 3.357, avg. samples / sec: 66003.96
Iteration:    460, Loss function: 6.448, Average Loss: 3.342, avg. samples / sec: 65983.84
Iteration:    460, Loss function: 6.728, Average Loss: 3.330, avg. samples / sec: 65933.67
Iteration:    460, Loss function: 6.479, Average Loss: 3.334, avg. samples / sec: 65992.21
Iteration:    460, Loss function: 6.083, Average Loss: 3.344, avg. samples / sec: 66086.66
Iteration:    460, Loss function: 5.226, Average Loss: 3.367, avg. samples / sec: 65984.80
Iteration:    460, Loss function: 6.598, Average Loss: 3.343, avg. samples / sec: 66171.19
Iteration:    460, Loss function: 6.189, Average Loss: 3.344, avg. samples / sec: 66067.33
Iteration:    460, Loss function: 6.451, Average Loss: 3.329, avg. samples / sec: 66036.49
Iteration:    460, Loss function: 6.880, Average Loss: 3.335, avg. samples / sec: 66035.16
Iteration:    460, Loss function: 6.818, Average Loss: 3.342, avg. samples / sec: 66185.23
Iteration:    460, Loss function: 9.052, Average Loss: 3.334, avg. samples / sec: 66112.11
Iteration:    460, Loss function: 6.936, Average Loss: 3.332, avg. samples / sec: 65928.74
Iteration:    460, Loss function: 6.939, Average Loss: 3.341, avg. samples / sec: 65987.98
Iteration:    460, Loss function: 6.069, Average Loss: 3.330, avg. samples / sec: 65882.66
Iteration:    460, Loss function: 6.417, Average Loss: 3.330, avg. samples / sec: 65911.44
Iteration:    460, Loss function: 6.267, Average Loss: 3.344, avg. samples / sec: 65850.62
Iteration:    460, Loss function: 6.834, Average Loss: 3.334, avg. samples / sec: 66096.24
Iteration:    460, Loss function: 6.626, Average Loss: 3.352, avg. samples / sec: 65906.85
Iteration:    460, Loss function: 6.877, Average Loss: 3.315, avg. samples / sec: 65879.92
Iteration:    460, Loss function: 6.087, Average Loss: 3.347, avg. samples / sec: 65944.23
Iteration:    460, Loss function: 5.468, Average Loss: 3.326, avg. samples / sec: 65869.91
Iteration:    460, Loss function: 6.332, Average Loss: 3.340, avg. samples / sec: 65953.82
Iteration:    460, Loss function: 6.299, Average Loss: 3.369, avg. samples / sec: 65903.58
Iteration:    460, Loss function: 6.956, Average Loss: 3.336, avg. samples / sec: 65995.64
Iteration:    460, Loss function: 5.584, Average Loss: 3.328, avg. samples / sec: 65795.43
Iteration:    460, Loss function: 7.124, Average Loss: 3.339, avg. samples / sec: 65825.89
Iteration:    480, Loss function: 7.223, Average Loss: 3.392, avg. samples / sec: 66154.79
Iteration:    480, Loss function: 7.560, Average Loss: 3.397, avg. samples / sec: 66246.46
Iteration:    480, Loss function: 7.387, Average Loss: 3.406, avg. samples / sec: 66299.07
Iteration:    480, Loss function: 7.202, Average Loss: 3.405, avg. samples / sec: 66130.08
Iteration:    480, Loss function: 7.182, Average Loss: 3.411, avg. samples / sec: 66223.24
Iteration:    480, Loss function: 6.307, Average Loss: 3.409, avg. samples / sec: 66246.21
Iteration:    480, Loss function: 7.317, Average Loss: 3.398, avg. samples / sec: 66081.70
Iteration:    480, Loss function: 6.710, Average Loss: 3.422, avg. samples / sec: 66025.57
Iteration:    480, Loss function: 7.327, Average Loss: 3.409, avg. samples / sec: 66084.49
Iteration:    480, Loss function: 6.540, Average Loss: 3.403, avg. samples / sec: 66134.14
Iteration:    480, Loss function: 7.812, Average Loss: 3.409, avg. samples / sec: 66004.33
Iteration:    480, Loss function: 6.702, Average Loss: 3.395, avg. samples / sec: 66127.87
Iteration:    480, Loss function: 6.824, Average Loss: 3.431, avg. samples / sec: 66044.79
Iteration:    480, Loss function: 6.851, Average Loss: 3.416, avg. samples / sec: 66166.40
Iteration:    480, Loss function: 6.770, Average Loss: 3.403, avg. samples / sec: 65980.47
Iteration:    480, Loss function: 6.010, Average Loss: 3.388, avg. samples / sec: 66173.86
Iteration:    480, Loss function: 7.804, Average Loss: 3.393, avg. samples / sec: 66034.89
Iteration:    480, Loss function: 6.400, Average Loss: 3.387, avg. samples / sec: 65944.04
Iteration:    480, Loss function: 5.831, Average Loss: 3.405, avg. samples / sec: 66079.13
Iteration:    480, Loss function: 6.770, Average Loss: 3.396, avg. samples / sec: 66023.50
Iteration:    480, Loss function: 7.022, Average Loss: 3.412, avg. samples / sec: 65982.14
Iteration:    480, Loss function: 6.111, Average Loss: 3.380, avg. samples / sec: 66079.29
Iteration:    480, Loss function: 5.486, Average Loss: 3.403, avg. samples / sec: 66242.72
Iteration:    480, Loss function: 6.636, Average Loss: 3.404, avg. samples / sec: 66046.27
Iteration:    480, Loss function: 7.175, Average Loss: 3.436, avg. samples / sec: 66078.20
Iteration:    480, Loss function: 6.351, Average Loss: 3.404, avg. samples / sec: 65962.59
Iteration:    480, Loss function: 6.405, Average Loss: 3.398, avg. samples / sec: 66072.93
Iteration:    480, Loss function: 5.865, Average Loss: 3.405, avg. samples / sec: 65898.47
Iteration:    480, Loss function: 7.153, Average Loss: 3.424, avg. samples / sec: 65837.97
Iteration:    480, Loss function: 6.300, Average Loss: 3.391, avg. samples / sec: 66013.54
:::MLL 1558651703.285 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558651703.286 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 5.810, Average Loss: 3.446, avg. samples / sec: 64998.37
Iteration:    500, Loss function: 6.071, Average Loss: 3.482, avg. samples / sec: 65047.57
Iteration:    500, Loss function: 5.823, Average Loss: 3.464, avg. samples / sec: 64959.96
Iteration:    500, Loss function: 5.858, Average Loss: 3.439, avg. samples / sec: 65153.69
Iteration:    500, Loss function: 6.076, Average Loss: 3.490, avg. samples / sec: 65041.98
Iteration:    500, Loss function: 7.062, Average Loss: 3.446, avg. samples / sec: 65032.50
Iteration:    500, Loss function: 6.402, Average Loss: 3.470, avg. samples / sec: 65026.41
Iteration:    500, Loss function: 6.439, Average Loss: 3.469, avg. samples / sec: 64973.79
Iteration:    500, Loss function: 6.651, Average Loss: 3.465, avg. samples / sec: 64973.02
Iteration:    500, Loss function: 6.292, Average Loss: 3.462, avg. samples / sec: 65018.19
Iteration:    500, Loss function: 6.463, Average Loss: 3.460, avg. samples / sec: 65109.21
Iteration:    500, Loss function: 5.970, Average Loss: 3.452, avg. samples / sec: 65056.37
Iteration:    500, Loss function: 6.808, Average Loss: 3.469, avg. samples / sec: 65041.68
Iteration:    500, Loss function: 7.536, Average Loss: 3.447, avg. samples / sec: 65020.95
Iteration:    500, Loss function: 6.442, Average Loss: 3.454, avg. samples / sec: 64963.43
Iteration:    500, Loss function: 6.361, Average Loss: 3.452, avg. samples / sec: 65090.50
Iteration:    500, Loss function: 5.381, Average Loss: 3.497, avg. samples / sec: 65056.49
Iteration:    500, Loss function: 6.098, Average Loss: 3.468, avg. samples / sec: 65100.66
Iteration:    500, Loss function: 5.676, Average Loss: 3.466, avg. samples / sec: 64984.31
Iteration:    500, Loss function: 6.092, Average Loss: 3.485, avg. samples / sec: 65104.09
Iteration:    500, Loss function: 7.346, Average Loss: 3.460, avg. samples / sec: 65027.94
Iteration:    500, Loss function: 6.022, Average Loss: 3.458, avg. samples / sec: 64824.60
Iteration:    500, Loss function: 6.666, Average Loss: 3.462, avg. samples / sec: 64862.46
Iteration:    500, Loss function: 6.411, Average Loss: 3.451, avg. samples / sec: 64957.20
Iteration:    500, Loss function: 5.722, Average Loss: 3.461, avg. samples / sec: 64811.27
Iteration:    500, Loss function: 5.653, Average Loss: 3.472, avg. samples / sec: 64866.58
Iteration:    500, Loss function: 6.035, Average Loss: 3.466, avg. samples / sec: 64866.94
Iteration:    500, Loss function: 5.980, Average Loss: 3.456, avg. samples / sec: 65177.38
Iteration:    500, Loss function: 6.443, Average Loss: 3.477, avg. samples / sec: 64911.94
Iteration:    500, Loss function: 5.656, Average Loss: 3.461, avg. samples / sec: 65013.99
Iteration:    520, Loss function: 7.490, Average Loss: 3.541, avg. samples / sec: 65718.30
Iteration:    520, Loss function: 5.744, Average Loss: 3.501, avg. samples / sec: 65657.89
Iteration:    520, Loss function: 6.064, Average Loss: 3.491, avg. samples / sec: 65736.78
Iteration:    520, Loss function: 5.896, Average Loss: 3.508, avg. samples / sec: 65859.63
Iteration:    520, Loss function: 6.453, Average Loss: 3.525, avg. samples / sec: 65715.45
Iteration:    520, Loss function: 6.863, Average Loss: 3.505, avg. samples / sec: 65813.71
Iteration:    520, Loss function: 5.842, Average Loss: 3.523, avg. samples / sec: 65810.15
Iteration:    520, Loss function: 6.186, Average Loss: 3.545, avg. samples / sec: 65818.75
Iteration:    520, Loss function: 6.990, Average Loss: 3.521, avg. samples / sec: 65833.79
Iteration:    520, Loss function: 6.124, Average Loss: 3.519, avg. samples / sec: 65854.49
Iteration:    520, Loss function: 6.376, Average Loss: 3.501, avg. samples / sec: 65721.82
Iteration:    520, Loss function: 6.330, Average Loss: 3.513, avg. samples / sec: 65818.14
Iteration:    520, Loss function: 6.352, Average Loss: 3.521, avg. samples / sec: 65792.33
Iteration:    520, Loss function: 6.439, Average Loss: 3.528, avg. samples / sec: 65831.24
Iteration:    520, Loss function: 6.171, Average Loss: 3.518, avg. samples / sec: 65742.39
Iteration:    520, Loss function: 6.419, Average Loss: 3.544, avg. samples / sec: 65683.87
Iteration:    520, Loss function: 5.749, Average Loss: 3.541, avg. samples / sec: 65777.96
Iteration:    520, Loss function: 8.133, Average Loss: 3.530, avg. samples / sec: 65694.98
Iteration:    520, Loss function: 7.170, Average Loss: 3.519, avg. samples / sec: 65789.01
Iteration:    520, Loss function: 7.352, Average Loss: 3.517, avg. samples / sec: 65795.92
Iteration:    520, Loss function: 6.786, Average Loss: 3.529, avg. samples / sec: 65762.92
Iteration:    520, Loss function: 5.898, Average Loss: 3.504, avg. samples / sec: 65714.80
Iteration:    520, Loss function: 6.670, Average Loss: 3.513, avg. samples / sec: 65765.37
Iteration:    520, Loss function: 7.259, Average Loss: 3.515, avg. samples / sec: 65668.14
Iteration:    520, Loss function: 7.340, Average Loss: 3.524, avg. samples / sec: 65629.27
Iteration:    520, Loss function: 6.024, Average Loss: 3.523, avg. samples / sec: 65721.79
Iteration:    520, Loss function: 5.668, Average Loss: 3.520, avg. samples / sec: 65623.61
Iteration:    520, Loss function: 6.463, Average Loss: 3.512, avg. samples / sec: 65587.18
Iteration:    520, Loss function: 6.251, Average Loss: 3.507, avg. samples / sec: 65601.22
Iteration:    520, Loss function: 6.807, Average Loss: 3.519, avg. samples / sec: 65493.21
Iteration:    540, Loss function: 6.850, Average Loss: 3.593, avg. samples / sec: 66193.60
Iteration:    540, Loss function: 7.123, Average Loss: 3.588, avg. samples / sec: 66088.80
Iteration:    540, Loss function: 6.222, Average Loss: 3.565, avg. samples / sec: 66051.72
Iteration:    540, Loss function: 5.628, Average Loss: 3.600, avg. samples / sec: 66100.58
Iteration:    540, Loss function: 6.083, Average Loss: 3.559, avg. samples / sec: 66055.13
Iteration:    540, Loss function: 5.987, Average Loss: 3.572, avg. samples / sec: 66054.88
Iteration:    540, Loss function: 6.638, Average Loss: 3.577, avg. samples / sec: 66055.00
Iteration:    540, Loss function: 6.327, Average Loss: 3.545, avg. samples / sec: 65967.69
Iteration:    540, Loss function: 7.005, Average Loss: 3.574, avg. samples / sec: 66192.91
Iteration:    540, Loss function: 7.355, Average Loss: 3.601, avg. samples / sec: 65935.31
Iteration:    540, Loss function: 6.056, Average Loss: 3.593, avg. samples / sec: 66014.04
Iteration:    540, Loss function: 5.438, Average Loss: 3.578, avg. samples / sec: 65940.80
Iteration:    540, Loss function: 6.285, Average Loss: 3.604, avg. samples / sec: 65993.97
Iteration:    540, Loss function: 6.885, Average Loss: 3.568, avg. samples / sec: 66035.35
Iteration:    540, Loss function: 7.158, Average Loss: 3.585, avg. samples / sec: 65933.61
Iteration:    540, Loss function: 5.495, Average Loss: 3.565, avg. samples / sec: 65927.41
Iteration:    540, Loss function: 6.666, Average Loss: 3.588, avg. samples / sec: 66025.45
Iteration:    540, Loss function: 6.247, Average Loss: 3.601, avg. samples / sec: 65935.68
Iteration:    540, Loss function: 5.514, Average Loss: 3.581, avg. samples / sec: 65972.97
Iteration:    540, Loss function: 6.605, Average Loss: 3.580, avg. samples / sec: 65925.22
Iteration:    540, Loss function: 5.962, Average Loss: 3.576, avg. samples / sec: 65995.83
Iteration:    540, Loss function: 5.666, Average Loss: 3.579, avg. samples / sec: 66070.64
Iteration:    540, Loss function: 6.523, Average Loss: 3.569, avg. samples / sec: 65907.37
Iteration:    540, Loss function: 5.872, Average Loss: 3.569, avg. samples / sec: 66071.79
Iteration:    540, Loss function: 5.751, Average Loss: 3.579, avg. samples / sec: 66016.76
Iteration:    540, Loss function: 7.399, Average Loss: 3.575, avg. samples / sec: 65893.44
Iteration:    540, Loss function: 6.103, Average Loss: 3.567, avg. samples / sec: 66103.99
Iteration:    540, Loss function: 5.284, Average Loss: 3.587, avg. samples / sec: 65980.44
Iteration:    540, Loss function: 6.412, Average Loss: 3.575, avg. samples / sec: 66135.23
Iteration:    540, Loss function: 7.174, Average Loss: 3.574, avg. samples / sec: 65847.48
:::MLL 1558651705.085 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558651705.086 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 5.613, Average Loss: 3.617, avg. samples / sec: 64863.86
Iteration:    560, Loss function: 5.385, Average Loss: 3.612, avg. samples / sec: 64746.51
Iteration:    560, Loss function: 6.543, Average Loss: 3.616, avg. samples / sec: 64703.08
Iteration:    560, Loss function: 4.521, Average Loss: 3.629, avg. samples / sec: 64768.86
Iteration:    560, Loss function: 7.178, Average Loss: 3.620, avg. samples / sec: 64724.48
Iteration:    560, Loss function: 5.037, Average Loss: 3.621, avg. samples / sec: 64797.00
Iteration:    560, Loss function: 6.453, Average Loss: 3.611, avg. samples / sec: 64788.81
Iteration:    560, Loss function: 6.028, Average Loss: 3.624, avg. samples / sec: 64687.96
Iteration:    560, Loss function: 6.776, Average Loss: 3.634, avg. samples / sec: 64768.11
Iteration:    560, Loss function: 5.585, Average Loss: 3.633, avg. samples / sec: 64833.04
Iteration:    560, Loss function: 5.515, Average Loss: 3.627, avg. samples / sec: 64736.22
Iteration:    560, Loss function: 5.415, Average Loss: 3.650, avg. samples / sec: 64672.14
Iteration:    560, Loss function: 7.298, Average Loss: 3.600, avg. samples / sec: 64659.56
Iteration:    560, Loss function: 5.433, Average Loss: 3.630, avg. samples / sec: 64652.59
Iteration:    560, Loss function: 5.825, Average Loss: 3.620, avg. samples / sec: 64713.87
Iteration:    560, Loss function: 5.274, Average Loss: 3.647, avg. samples / sec: 64722.78
Iteration:    560, Loss function: 6.269, Average Loss: 3.643, avg. samples / sec: 64504.78
Iteration:    560, Loss function: 6.288, Average Loss: 3.655, avg. samples / sec: 64688.65
Iteration:    560, Loss function: 4.513, Average Loss: 3.623, avg. samples / sec: 64749.66
Iteration:    560, Loss function: 5.474, Average Loss: 3.624, avg. samples / sec: 64693.37
Iteration:    560, Loss function: 4.021, Average Loss: 3.632, avg. samples / sec: 64697.61
Iteration:    560, Loss function: 5.600, Average Loss: 3.631, avg. samples / sec: 64666.95
Iteration:    560, Loss function: 5.679, Average Loss: 3.638, avg. samples / sec: 64622.97
Iteration:    560, Loss function: 4.887, Average Loss: 3.619, avg. samples / sec: 64838.97
Iteration:    560, Loss function: 5.632, Average Loss: 3.627, avg. samples / sec: 64767.79
Iteration:    560, Loss function: 5.835, Average Loss: 3.649, avg. samples / sec: 64537.09
Iteration:    560, Loss function: 4.695, Average Loss: 3.640, avg. samples / sec: 64489.01
Iteration:    560, Loss function: 6.463, Average Loss: 3.630, avg. samples / sec: 64591.16
Iteration:    560, Loss function: 5.140, Average Loss: 3.640, avg. samples / sec: 64534.11
Iteration:    560, Loss function: 6.640, Average Loss: 3.614, avg. samples / sec: 64532.36
Iteration:    580, Loss function: 5.942, Average Loss: 3.696, avg. samples / sec: 66125.55
Iteration:    580, Loss function: 6.489, Average Loss: 3.685, avg. samples / sec: 66137.06
Iteration:    580, Loss function: 6.090, Average Loss: 3.668, avg. samples / sec: 66113.29
Iteration:    580, Loss function: 5.813, Average Loss: 3.685, avg. samples / sec: 66164.69
Iteration:    580, Loss function: 5.734, Average Loss: 3.662, avg. samples / sec: 65927.26
Iteration:    580, Loss function: 5.286, Average Loss: 3.664, avg. samples / sec: 65984.70
Iteration:    580, Loss function: 5.535, Average Loss: 3.684, avg. samples / sec: 66092.49
Iteration:    580, Loss function: 5.567, Average Loss: 3.682, avg. samples / sec: 66068.88
Iteration:    580, Loss function: 5.558, Average Loss: 3.654, avg. samples / sec: 65947.59
Iteration:    580, Loss function: 6.712, Average Loss: 3.663, avg. samples / sec: 65872.47
Iteration:    580, Loss function: 6.669, Average Loss: 3.670, avg. samples / sec: 65923.56
Iteration:    580, Loss function: 5.454, Average Loss: 3.676, avg. samples / sec: 65942.62
Iteration:    580, Loss function: 5.190, Average Loss: 3.677, avg. samples / sec: 65977.07
Iteration:    580, Loss function: 5.788, Average Loss: 3.673, avg. samples / sec: 65910.79
Iteration:    580, Loss function: 5.944, Average Loss: 3.674, avg. samples / sec: 66109.94
Iteration:    580, Loss function: 5.525, Average Loss: 3.660, avg. samples / sec: 65827.30
Iteration:    580, Loss function: 5.734, Average Loss: 3.668, avg. samples / sec: 65869.27
Iteration:    580, Loss function: 6.254, Average Loss: 3.693, avg. samples / sec: 65933.00
Iteration:    580, Loss function: 5.795, Average Loss: 3.675, avg. samples / sec: 66001.89
Iteration:    580, Loss function: 6.238, Average Loss: 3.696, avg. samples / sec: 65938.36
Iteration:    580, Loss function: 6.345, Average Loss: 3.643, avg. samples / sec: 65913.78
Iteration:    580, Loss function: 6.809, Average Loss: 3.667, avg. samples / sec: 65955.95
Iteration:    580, Loss function: 6.197, Average Loss: 3.675, avg. samples / sec: 65886.30
Iteration:    580, Loss function: 6.494, Average Loss: 3.672, avg. samples / sec: 65961.26
Iteration:    580, Loss function: 6.729, Average Loss: 3.679, avg. samples / sec: 65863.79
Iteration:    580, Loss function: 6.715, Average Loss: 3.671, avg. samples / sec: 65936.14
Iteration:    580, Loss function: 5.836, Average Loss: 3.671, avg. samples / sec: 65877.46
Iteration:    580, Loss function: 6.179, Average Loss: 3.666, avg. samples / sec: 66137.06
Iteration:    580, Loss function: 4.921, Average Loss: 3.686, avg. samples / sec: 66043.52
Iteration:    580, Loss function: 5.864, Average Loss: 3.696, avg. samples / sec: 65900.84
Iteration:    600, Loss function: 6.678, Average Loss: 3.742, avg. samples / sec: 66183.28
Iteration:    600, Loss function: 5.954, Average Loss: 3.696, avg. samples / sec: 66316.70
Iteration:    600, Loss function: 5.877, Average Loss: 3.735, avg. samples / sec: 66362.38
Iteration:    600, Loss function: 6.433, Average Loss: 3.719, avg. samples / sec: 66148.36
Iteration:    600, Loss function: 5.455, Average Loss: 3.731, avg. samples / sec: 66181.91
Iteration:    600, Loss function: 5.535, Average Loss: 3.737, avg. samples / sec: 66066.55
Iteration:    600, Loss function: 5.272, Average Loss: 3.748, avg. samples / sec: 66353.16
Iteration:    600, Loss function: 6.928, Average Loss: 3.726, avg. samples / sec: 66205.41
Iteration:    600, Loss function: 6.010, Average Loss: 3.728, avg. samples / sec: 66174.64
Iteration:    600, Loss function: 5.687, Average Loss: 3.729, avg. samples / sec: 66268.98
Iteration:    600, Loss function: 5.861, Average Loss: 3.710, avg. samples / sec: 66197.14
Iteration:    600, Loss function: 7.304, Average Loss: 3.717, avg. samples / sec: 66094.87
Iteration:    600, Loss function: 6.037, Average Loss: 3.726, avg. samples / sec: 66238.33
Iteration:    600, Loss function: 5.497, Average Loss: 3.719, avg. samples / sec: 66172.52
Iteration:    600, Loss function: 5.628, Average Loss: 3.712, avg. samples / sec: 66102.19
Iteration:    600, Loss function: 5.504, Average Loss: 3.722, avg. samples / sec: 66142.15
Iteration:    600, Loss function: 7.725, Average Loss: 3.717, avg. samples / sec: 66035.72
Iteration:    600, Loss function: 7.268, Average Loss: 3.725, avg. samples / sec: 66110.75
Iteration:    600, Loss function: 6.535, Average Loss: 3.717, avg. samples / sec: 66152.77
Iteration:    600, Loss function: 5.932, Average Loss: 3.741, avg. samples / sec: 66043.43
Iteration:    600, Loss function: 6.556, Average Loss: 3.732, avg. samples / sec: 66069.22
Iteration:    600, Loss function: 5.741, Average Loss: 3.723, avg. samples / sec: 66207.47
Iteration:    600, Loss function: 6.130, Average Loss: 3.714, avg. samples / sec: 66072.78
Iteration:    600, Loss function: 6.013, Average Loss: 3.724, avg. samples / sec: 66121.95
Iteration:    600, Loss function: 6.507, Average Loss: 3.722, avg. samples / sec: 66149.17
Iteration:    600, Loss function: 7.135, Average Loss: 3.725, avg. samples / sec: 66138.58
Iteration:    600, Loss function: 6.643, Average Loss: 3.745, avg. samples / sec: 66091.93
Iteration:    600, Loss function: 6.521, Average Loss: 3.746, avg. samples / sec: 66061.66
Iteration:    600, Loss function: 5.214, Average Loss: 3.717, avg. samples / sec: 66103.71
Iteration:    600, Loss function: 5.108, Average Loss: 3.716, avg. samples / sec: 66025.05
Iteration:    620, Loss function: 4.265, Average Loss: 3.765, avg. samples / sec: 66298.35
Iteration:    620, Loss function: 6.169, Average Loss: 3.785, avg. samples / sec: 66140.75
Iteration:    620, Loss function: 5.805, Average Loss: 3.776, avg. samples / sec: 66278.93
Iteration:    620, Loss function: 6.438, Average Loss: 3.773, avg. samples / sec: 66345.61
Iteration:    620, Loss function: 5.259, Average Loss: 3.766, avg. samples / sec: 66327.03
Iteration:    620, Loss function: 5.251, Average Loss: 3.759, avg. samples / sec: 66462.16
Iteration:    620, Loss function: 6.599, Average Loss: 3.791, avg. samples / sec: 66332.30
Iteration:    620, Loss function: 5.437, Average Loss: 3.769, avg. samples / sec: 66263.22
Iteration:    620, Loss function: 6.301, Average Loss: 3.787, avg. samples / sec: 66229.00
Iteration:    620, Loss function: 6.687, Average Loss: 3.761, avg. samples / sec: 66286.41
Iteration:    620, Loss function: 6.635, Average Loss: 3.761, avg. samples / sec: 66297.38
Iteration:    620, Loss function: 5.594, Average Loss: 3.771, avg. samples / sec: 66187.91
Iteration:    620, Loss function: 6.489, Average Loss: 3.738, avg. samples / sec: 66148.82
Iteration:    620, Loss function: 5.974, Average Loss: 3.766, avg. samples / sec: 66255.87
Iteration:    620, Loss function: 6.112, Average Loss: 3.769, avg. samples / sec: 66271.26
Iteration:    620, Loss function: 5.413, Average Loss: 3.766, avg. samples / sec: 66303.93
Iteration:    620, Loss function: 4.815, Average Loss: 3.759, avg. samples / sec: 66468.49
Iteration:    620, Loss function: 5.371, Average Loss: 3.756, avg. samples / sec: 66227.22
Iteration:    620, Loss function: 4.940, Average Loss: 3.793, avg. samples / sec: 66352.29
Iteration:    620, Loss function: 6.956, Average Loss: 3.773, avg. samples / sec: 66301.10
Iteration:    620, Loss function: 8.615, Average Loss: 3.793, avg. samples / sec: 66351.60
Iteration:    620, Loss function: 5.850, Average Loss: 3.767, avg. samples / sec: 66270.11
Iteration:    620, Loss function: 6.224, Average Loss: 3.775, avg. samples / sec: 66168.33
Iteration:    620, Loss function: 6.984, Average Loss: 3.756, avg. samples / sec: 66174.70
Iteration:    620, Loss function: 6.239, Average Loss: 3.756, avg. samples / sec: 66202.05
Iteration:    620, Loss function: 5.361, Average Loss: 3.769, avg. samples / sec: 66131.01
Iteration:    620, Loss function: 4.928, Average Loss: 3.762, avg. samples / sec: 66189.99
Iteration:    620, Loss function: 6.832, Average Loss: 3.772, avg. samples / sec: 66162.55
Iteration:    620, Loss function: 6.670, Average Loss: 3.781, avg. samples / sec: 66067.95
Iteration:    620, Loss function: 5.731, Average Loss: 3.758, avg. samples / sec: 66073.80
:::MLL 1558651706.866 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558651706.866 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 5.866, Average Loss: 3.795, avg. samples / sec: 65446.83
Iteration:    640, Loss function: 5.656, Average Loss: 3.804, avg. samples / sec: 65266.94
Iteration:    640, Loss function: 5.011, Average Loss: 3.819, avg. samples / sec: 65304.47
Iteration:    640, Loss function: 5.554, Average Loss: 3.829, avg. samples / sec: 65291.79
Iteration:    640, Loss function: 5.547, Average Loss: 3.823, avg. samples / sec: 65274.95
Iteration:    640, Loss function: 6.164, Average Loss: 3.790, avg. samples / sec: 65379.39
Iteration:    640, Loss function: 6.269, Average Loss: 3.802, avg. samples / sec: 65351.68
Iteration:    640, Loss function: 7.132, Average Loss: 3.829, avg. samples / sec: 65298.15
Iteration:    640, Loss function: 6.409, Average Loss: 3.810, avg. samples / sec: 65402.69
Iteration:    640, Loss function: 5.565, Average Loss: 3.827, avg. samples / sec: 65343.71
Iteration:    640, Loss function: 6.025, Average Loss: 3.799, avg. samples / sec: 65326.66
Iteration:    640, Loss function: 5.183, Average Loss: 3.804, avg. samples / sec: 65214.42
Iteration:    640, Loss function: 5.207, Average Loss: 3.779, avg. samples / sec: 65277.37
Iteration:    640, Loss function: 5.830, Average Loss: 3.807, avg. samples / sec: 65327.78
Iteration:    640, Loss function: 5.139, Average Loss: 3.808, avg. samples / sec: 65347.83
Iteration:    640, Loss function: 5.415, Average Loss: 3.828, avg. samples / sec: 65271.26
Iteration:    640, Loss function: 4.875, Average Loss: 3.806, avg. samples / sec: 65237.87
Iteration:    640, Loss function: 5.098, Average Loss: 3.800, avg. samples / sec: 65196.01
Iteration:    640, Loss function: 6.819, Average Loss: 3.807, avg. samples / sec: 65270.35
Iteration:    640, Loss function: 4.761, Average Loss: 3.818, avg. samples / sec: 65303.50
Iteration:    640, Loss function: 5.499, Average Loss: 3.812, avg. samples / sec: 65245.24
Iteration:    640, Loss function: 5.392, Average Loss: 3.798, avg. samples / sec: 65424.49
Iteration:    640, Loss function: 6.268, Average Loss: 3.813, avg. samples / sec: 65131.50
Iteration:    640, Loss function: 5.148, Average Loss: 3.809, avg. samples / sec: 65106.50
Iteration:    640, Loss function: 6.443, Average Loss: 3.799, avg. samples / sec: 65151.04
Iteration:    640, Loss function: 5.600, Average Loss: 3.815, avg. samples / sec: 65149.18
Iteration:    640, Loss function: 5.694, Average Loss: 3.799, avg. samples / sec: 65190.83
Iteration:    640, Loss function: 4.946, Average Loss: 3.804, avg. samples / sec: 65167.25
Iteration:    640, Loss function: 4.507, Average Loss: 3.811, avg. samples / sec: 65189.86
Iteration:    640, Loss function: 6.220, Average Loss: 3.812, avg. samples / sec: 65072.17
Iteration:    660, Loss function: 5.463, Average Loss: 3.857, avg. samples / sec: 66208.09
Iteration:    660, Loss function: 6.851, Average Loss: 3.836, avg. samples / sec: 65968.43
Iteration:    660, Loss function: 6.330, Average Loss: 3.856, avg. samples / sec: 66129.24
Iteration:    660, Loss function: 6.910, Average Loss: 3.877, avg. samples / sec: 65969.54
Iteration:    660, Loss function: 6.269, Average Loss: 3.867, avg. samples / sec: 65933.09
Iteration:    660, Loss function: 5.469, Average Loss: 3.853, avg. samples / sec: 66044.94
Iteration:    660, Loss function: 6.646, Average Loss: 3.855, avg. samples / sec: 66118.91
Iteration:    660, Loss function: 5.736, Average Loss: 3.848, avg. samples / sec: 66127.50
Iteration:    660, Loss function: 5.701, Average Loss: 3.864, avg. samples / sec: 65882.85
Iteration:    660, Loss function: 7.241, Average Loss: 3.844, avg. samples / sec: 66054.57
Iteration:    660, Loss function: 6.068, Average Loss: 3.842, avg. samples / sec: 66108.95
Iteration:    660, Loss function: 5.557, Average Loss: 3.842, avg. samples / sec: 65835.51
Iteration:    660, Loss function: 5.653, Average Loss: 3.841, avg. samples / sec: 65869.85
Iteration:    660, Loss function: 5.332, Average Loss: 3.853, avg. samples / sec: 65886.97
Iteration:    660, Loss function: 5.245, Average Loss: 3.816, avg. samples / sec: 65931.79
Iteration:    660, Loss function: 5.548, Average Loss: 3.875, avg. samples / sec: 65868.37
Iteration:    660, Loss function: 6.913, Average Loss: 3.869, avg. samples / sec: 66049.37
Iteration:    660, Loss function: 5.972, Average Loss: 3.842, avg. samples / sec: 66045.90
Iteration:    660, Loss function: 4.781, Average Loss: 3.863, avg. samples / sec: 65881.71
Iteration:    660, Loss function: 5.596, Average Loss: 3.836, avg. samples / sec: 65806.09
Iteration:    660, Loss function: 5.730, Average Loss: 3.856, avg. samples / sec: 66056.49
Iteration:    660, Loss function: 5.877, Average Loss: 3.852, avg. samples / sec: 65906.57
Iteration:    660, Loss function: 7.156, Average Loss: 3.849, avg. samples / sec: 65891.19
Iteration:    660, Loss function: 5.010, Average Loss: 3.851, avg. samples / sec: 65950.77
Iteration:    660, Loss function: 6.047, Average Loss: 3.853, avg. samples / sec: 65917.05
Iteration:    660, Loss function: 4.851, Average Loss: 3.846, avg. samples / sec: 65849.17
Iteration:    660, Loss function: 6.936, Average Loss: 3.846, avg. samples / sec: 65788.89
Iteration:    660, Loss function: 6.453, Average Loss: 3.870, avg. samples / sec: 65863.94
Iteration:    660, Loss function: 6.005, Average Loss: 3.858, avg. samples / sec: 65894.95
Iteration:    660, Loss function: 7.004, Average Loss: 3.864, avg. samples / sec: 65893.07
Iteration:    680, Loss function: 5.114, Average Loss: 3.902, avg. samples / sec: 66018.00
Iteration:    680, Loss function: 5.825, Average Loss: 3.882, avg. samples / sec: 66100.95
Iteration:    680, Loss function: 5.899, Average Loss: 3.898, avg. samples / sec: 65956.45
Iteration:    680, Loss function: 4.628, Average Loss: 3.895, avg. samples / sec: 65977.88
Iteration:    680, Loss function: 7.045, Average Loss: 3.878, avg. samples / sec: 65906.14
Iteration:    680, Loss function: 5.884, Average Loss: 3.902, avg. samples / sec: 66134.70
Iteration:    680, Loss function: 5.609, Average Loss: 3.879, avg. samples / sec: 66000.43
Iteration:    680, Loss function: 7.260, Average Loss: 3.894, avg. samples / sec: 65942.41
Iteration:    680, Loss function: 4.405, Average Loss: 3.893, avg. samples / sec: 65931.92
Iteration:    680, Loss function: 6.440, Average Loss: 3.892, avg. samples / sec: 65944.60
Iteration:    680, Loss function: 6.088, Average Loss: 3.902, avg. samples / sec: 66127.38
Iteration:    680, Loss function: 5.823, Average Loss: 3.888, avg. samples / sec: 65998.18
Iteration:    680, Loss function: 5.827, Average Loss: 3.882, avg. samples / sec: 65941.17
Iteration:    680, Loss function: 5.678, Average Loss: 3.915, avg. samples / sec: 65883.62
Iteration:    680, Loss function: 5.013, Average Loss: 3.892, avg. samples / sec: 66077.95
Iteration:    680, Loss function: 5.760, Average Loss: 3.892, avg. samples / sec: 66000.96
Iteration:    680, Loss function: 4.665, Average Loss: 3.891, avg. samples / sec: 65998.24
Iteration:    680, Loss function: 5.038, Average Loss: 3.884, avg. samples / sec: 66017.59
Iteration:    680, Loss function: 5.016, Average Loss: 3.880, avg. samples / sec: 65994.59
Iteration:    680, Loss function: 6.784, Average Loss: 3.911, avg. samples / sec: 65953.55
Iteration:    680, Loss function: 3.995, Average Loss: 3.901, avg. samples / sec: 65935.46
Iteration:    680, Loss function: 5.933, Average Loss: 3.879, avg. samples / sec: 65915.60
Iteration:    680, Loss function: 6.817, Average Loss: 3.881, avg. samples / sec: 65888.92
Iteration:    680, Loss function: 5.863, Average Loss: 3.877, avg. samples / sec: 65893.97
Iteration:    680, Loss function: 5.316, Average Loss: 3.904, avg. samples / sec: 65924.05
Iteration:    680, Loss function: 5.356, Average Loss: 3.886, avg. samples / sec: 66019.91
Iteration:    680, Loss function: 5.671, Average Loss: 3.884, avg. samples / sec: 65977.85
Iteration:    680, Loss function: 5.841, Average Loss: 3.871, avg. samples / sec: 65885.25
Iteration:    680, Loss function: 4.616, Average Loss: 3.857, avg. samples / sec: 65837.39
Iteration:    680, Loss function: 4.714, Average Loss: 3.893, avg. samples / sec: 65893.63
:::MLL 1558651708.654 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558651708.655 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 5.091, Average Loss: 3.939, avg. samples / sec: 66113.11
Iteration:    700, Loss function: 4.811, Average Loss: 3.909, avg. samples / sec: 66102.97
Iteration:    700, Loss function: 5.856, Average Loss: 3.927, avg. samples / sec: 65945.65
Iteration:    700, Loss function: 5.664, Average Loss: 3.919, avg. samples / sec: 65924.64
Iteration:    700, Loss function: 5.954, Average Loss: 3.929, avg. samples / sec: 65807.90
Iteration:    700, Loss function: 5.347, Average Loss: 3.926, avg. samples / sec: 65795.03
Iteration:    700, Loss function: 6.160, Average Loss: 3.927, avg. samples / sec: 65853.51
Iteration:    700, Loss function: 5.532, Average Loss: 3.928, avg. samples / sec: 65932.04
Iteration:    700, Loss function: 6.070, Average Loss: 3.924, avg. samples / sec: 65848.40
Iteration:    700, Loss function: 4.513, Average Loss: 3.920, avg. samples / sec: 65744.11
Iteration:    700, Loss function: 6.367, Average Loss: 3.946, avg. samples / sec: 65882.35
Iteration:    700, Loss function: 5.829, Average Loss: 3.942, avg. samples / sec: 65897.66
Iteration:    700, Loss function: 5.628, Average Loss: 3.890, avg. samples / sec: 65974.48
Iteration:    700, Loss function: 5.110, Average Loss: 3.917, avg. samples / sec: 65794.79
Iteration:    700, Loss function: 6.568, Average Loss: 3.916, avg. samples / sec: 65813.59
Iteration:    700, Loss function: 6.001, Average Loss: 3.910, avg. samples / sec: 65889.25
Iteration:    700, Loss function: 5.740, Average Loss: 3.924, avg. samples / sec: 65818.94
Iteration:    700, Loss function: 5.613, Average Loss: 3.940, avg. samples / sec: 65765.74
Iteration:    700, Loss function: 6.230, Average Loss: 3.913, avg. samples / sec: 65752.45
Iteration:    700, Loss function: 5.426, Average Loss: 3.917, avg. samples / sec: 65842.77
Iteration:    700, Loss function: 5.265, Average Loss: 3.921, avg. samples / sec: 65820.84
Iteration:    700, Loss function: 5.921, Average Loss: 3.914, avg. samples / sec: 65849.11
Iteration:    700, Loss function: 5.089, Average Loss: 3.953, avg. samples / sec: 65770.74
Iteration:    700, Loss function: 6.020, Average Loss: 3.939, avg. samples / sec: 65645.10
Iteration:    700, Loss function: 5.566, Average Loss: 3.919, avg. samples / sec: 65864.74
Iteration:    700, Loss function: 7.249, Average Loss: 3.939, avg. samples / sec: 65634.28
Iteration:    700, Loss function: 5.663, Average Loss: 3.924, avg. samples / sec: 65692.78
Iteration:    700, Loss function: 5.492, Average Loss: 3.936, avg. samples / sec: 65667.16
Iteration:    700, Loss function: 7.120, Average Loss: 3.933, avg. samples / sec: 65841.11
Iteration:    700, Loss function: 6.493, Average Loss: 3.927, avg. samples / sec: 65594.26
Iteration:    720, Loss function: 5.009, Average Loss: 3.953, avg. samples / sec: 65503.13
Iteration:    720, Loss function: 5.978, Average Loss: 3.973, avg. samples / sec: 65480.91
Iteration:    720, Loss function: 4.191, Average Loss: 3.975, avg. samples / sec: 65575.28
Iteration:    720, Loss function: 5.929, Average Loss: 3.946, avg. samples / sec: 65520.19
Iteration:    720, Loss function: 4.903, Average Loss: 3.952, avg. samples / sec: 65464.34
Iteration:    720, Loss function: 6.205, Average Loss: 3.959, avg. samples / sec: 65460.23
Iteration:    720, Loss function: 5.001, Average Loss: 3.977, avg. samples / sec: 65473.89
Iteration:    720, Loss function: 5.339, Average Loss: 3.949, avg. samples / sec: 65489.07
Iteration:    720, Loss function: 5.486, Average Loss: 3.960, avg. samples / sec: 65315.85
Iteration:    720, Loss function: 5.466, Average Loss: 3.967, avg. samples / sec: 65488.86
Iteration:    720, Loss function: 6.998, Average Loss: 3.966, avg. samples / sec: 65452.81
Iteration:    720, Loss function: 5.629, Average Loss: 3.973, avg. samples / sec: 65250.08
Iteration:    720, Loss function: 5.897, Average Loss: 3.971, avg. samples / sec: 65583.06
Iteration:    720, Loss function: 5.439, Average Loss: 3.962, avg. samples / sec: 65634.19
Iteration:    720, Loss function: 5.676, Average Loss: 3.948, avg. samples / sec: 65462.76
Iteration:    720, Loss function: 5.067, Average Loss: 3.946, avg. samples / sec: 65481.16
Iteration:    720, Loss function: 3.743, Average Loss: 3.981, avg. samples / sec: 65460.72
Iteration:    720, Loss function: 5.337, Average Loss: 3.956, avg. samples / sec: 65473.16
Iteration:    720, Loss function: 4.832, Average Loss: 3.938, avg. samples / sec: 65254.37
Iteration:    720, Loss function: 6.252, Average Loss: 3.962, avg. samples / sec: 65369.32
Iteration:    720, Loss function: 5.779, Average Loss: 3.955, avg. samples / sec: 65402.82
Iteration:    720, Loss function: 5.537, Average Loss: 3.955, avg. samples / sec: 65364.26
Iteration:    720, Loss function: 4.455, Average Loss: 3.945, avg. samples / sec: 65393.26
Iteration:    720, Loss function: 6.008, Average Loss: 3.960, avg. samples / sec: 65552.46
Iteration:    720, Loss function: 5.158, Average Loss: 3.954, avg. samples / sec: 65484.08
Iteration:    720, Loss function: 5.916, Average Loss: 3.944, avg. samples / sec: 65367.17
Iteration:    720, Loss function: 4.832, Average Loss: 3.922, avg. samples / sec: 65350.71
Iteration:    720, Loss function: 5.630, Average Loss: 3.951, avg. samples / sec: 65366.72
Iteration:    720, Loss function: 5.627, Average Loss: 3.960, avg. samples / sec: 65459.02
Iteration:    720, Loss function: 5.329, Average Loss: 3.972, avg. samples / sec: 65321.30
Iteration:    740, Loss function: 5.588, Average Loss: 4.008, avg. samples / sec: 66142.61
Iteration:    740, Loss function: 5.150, Average Loss: 3.991, avg. samples / sec: 66148.70
Iteration:    740, Loss function: 4.716, Average Loss: 4.012, avg. samples / sec: 66181.10
Iteration:    740, Loss function: 4.898, Average Loss: 4.003, avg. samples / sec: 66111.03
Iteration:    740, Loss function: 4.551, Average Loss: 4.011, avg. samples / sec: 66095.96
Iteration:    740, Loss function: 5.352, Average Loss: 3.981, avg. samples / sec: 66081.18
Iteration:    740, Loss function: 5.367, Average Loss: 3.985, avg. samples / sec: 66208.74
Iteration:    740, Loss function: 4.633, Average Loss: 3.976, avg. samples / sec: 66084.31
Iteration:    740, Loss function: 5.052, Average Loss: 3.991, avg. samples / sec: 66093.67
Iteration:    740, Loss function: 6.487, Average Loss: 4.005, avg. samples / sec: 66044.82
Iteration:    740, Loss function: 5.943, Average Loss: 3.990, avg. samples / sec: 66151.71
Iteration:    740, Loss function: 5.838, Average Loss: 3.982, avg. samples / sec: 66049.59
Iteration:    740, Loss function: 6.115, Average Loss: 3.984, avg. samples / sec: 66097.14
Iteration:    740, Loss function: 4.747, Average Loss: 4.000, avg. samples / sec: 66059.00
Iteration:    740, Loss function: 6.360, Average Loss: 3.980, avg. samples / sec: 66132.47
Iteration:    740, Loss function: 5.450, Average Loss: 3.989, avg. samples / sec: 66162.77
Iteration:    740, Loss function: 5.087, Average Loss: 3.984, avg. samples / sec: 66143.92
Iteration:    740, Loss function: 5.052, Average Loss: 4.000, avg. samples / sec: 66019.36
Iteration:    740, Loss function: 5.390, Average Loss: 4.009, avg. samples / sec: 66179.30
Iteration:    740, Loss function: 5.736, Average Loss: 3.992, avg. samples / sec: 66017.62
Iteration:    740, Loss function: 5.788, Average Loss: 3.987, avg. samples / sec: 65952.87
Iteration:    740, Loss function: 5.698, Average Loss: 3.976, avg. samples / sec: 66087.19
Iteration:    740, Loss function: 5.945, Average Loss: 3.991, avg. samples / sec: 66066.86
Iteration:    740, Loss function: 6.453, Average Loss: 3.972, avg. samples / sec: 66044.23
Iteration:    740, Loss function: 6.010, Average Loss: 3.987, avg. samples / sec: 66119.96
Iteration:    740, Loss function: 6.843, Average Loss: 3.996, avg. samples / sec: 66123.31
Iteration:    740, Loss function: 4.253, Average Loss: 3.989, avg. samples / sec: 66019.42
Iteration:    740, Loss function: 5.753, Average Loss: 3.978, avg. samples / sec: 65966.57
Iteration:    740, Loss function: 5.465, Average Loss: 3.994, avg. samples / sec: 65973.03
Iteration:    740, Loss function: 6.811, Average Loss: 3.951, avg. samples / sec: 65977.85
Iteration:    760, Loss function: 6.411, Average Loss: 4.032, avg. samples / sec: 66174.26
Iteration:    760, Loss function: 5.810, Average Loss: 4.033, avg. samples / sec: 66024.74
Iteration:    760, Loss function: 3.983, Average Loss: 4.004, avg. samples / sec: 66104.70
Iteration:    760, Loss function: 5.229, Average Loss: 4.029, avg. samples / sec: 66145.38
Iteration:    760, Loss function: 6.572, Average Loss: 4.032, avg. samples / sec: 66123.25
Iteration:    760, Loss function: 6.748, Average Loss: 4.010, avg. samples / sec: 66087.71
Iteration:    760, Loss function: 5.288, Average Loss: 4.039, avg. samples / sec: 66146.71
Iteration:    760, Loss function: 5.748, Average Loss: 4.039, avg. samples / sec: 66055.65
Iteration:    760, Loss function: 6.848, Average Loss: 4.017, avg. samples / sec: 66060.52
Iteration:    760, Loss function: 4.864, Average Loss: 4.018, avg. samples / sec: 66099.43
Iteration:    760, Loss function: 5.385, Average Loss: 4.016, avg. samples / sec: 66098.10
Iteration:    760, Loss function: 6.048, Average Loss: 4.012, avg. samples / sec: 66047.14
Iteration:    760, Loss function: 4.918, Average Loss: 4.034, avg. samples / sec: 66046.12
Iteration:    760, Loss function: 5.350, Average Loss: 3.987, avg. samples / sec: 66259.51
Iteration:    760, Loss function: 5.759, Average Loss: 4.003, avg. samples / sec: 66128.12
Iteration:    760, Loss function: 5.549, Average Loss: 4.021, avg. samples / sec: 65963.39
Iteration:    760, Loss function: 5.809, Average Loss: 4.042, avg. samples / sec: 65995.98
Iteration:    760, Loss function: 5.274, Average Loss: 4.016, avg. samples / sec: 66030.40
Iteration:    760, Loss function: 5.168, Average Loss: 4.018, avg. samples / sec: 66066.83
Iteration:    760, Loss function: 6.374, Average Loss: 4.019, avg. samples / sec: 66074.89
Iteration:    760, Loss function: 5.063, Average Loss: 4.007, avg. samples / sec: 66068.20
Iteration:    760, Loss function: 6.144, Average Loss: 4.018, avg. samples / sec: 66065.66
Iteration:    760, Loss function: 6.640, Average Loss: 4.012, avg. samples / sec: 65965.03
Iteration:    760, Loss function: 5.998, Average Loss: 4.011, avg. samples / sec: 66107.68
Iteration:    760, Loss function: 6.011, Average Loss: 4.016, avg. samples / sec: 66024.77
Iteration:    760, Loss function: 6.035, Average Loss: 4.028, avg. samples / sec: 66018.18
Iteration:    760, Loss function: 5.760, Average Loss: 4.019, avg. samples / sec: 66049.03
Iteration:    760, Loss function: 6.192, Average Loss: 4.017, avg. samples / sec: 65930.71
Iteration:    760, Loss function: 5.197, Average Loss: 4.024, avg. samples / sec: 66034.36
Iteration:    760, Loss function: 5.324, Average Loss: 4.017, avg. samples / sec: 65898.62
:::MLL 1558651710.440 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558651710.441 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 5.276, Average Loss: 4.059, avg. samples / sec: 65993.36
Iteration:    780, Loss function: 5.767, Average Loss: 4.061, avg. samples / sec: 65996.26
Iteration:    780, Loss function: 5.300, Average Loss: 4.050, avg. samples / sec: 66174.88
Iteration:    780, Loss function: 5.782, Average Loss: 4.066, avg. samples / sec: 65937.56
Iteration:    780, Loss function: 6.076, Average Loss: 4.078, avg. samples / sec: 65961.05
Iteration:    780, Loss function: 4.702, Average Loss: 4.044, avg. samples / sec: 66167.21
Iteration:    780, Loss function: 4.338, Average Loss: 4.041, avg. samples / sec: 65984.40
Iteration:    780, Loss function: 4.373, Average Loss: 4.048, avg. samples / sec: 66029.29
Iteration:    780, Loss function: 6.303, Average Loss: 4.038, avg. samples / sec: 65892.24
Iteration:    780, Loss function: 5.844, Average Loss: 4.042, avg. samples / sec: 65931.42
Iteration:    780, Loss function: 5.234, Average Loss: 4.041, avg. samples / sec: 66042.56
Iteration:    780, Loss function: 4.758, Average Loss: 4.048, avg. samples / sec: 65988.26
Iteration:    780, Loss function: 5.571, Average Loss: 4.067, avg. samples / sec: 65805.05
Iteration:    780, Loss function: 4.489, Average Loss: 4.035, avg. samples / sec: 66002.44
Iteration:    780, Loss function: 5.050, Average Loss: 4.067, avg. samples / sec: 65905.99
Iteration:    780, Loss function: 5.546, Average Loss: 4.043, avg. samples / sec: 65945.37
Iteration:    780, Loss function: 6.057, Average Loss: 4.060, avg. samples / sec: 66032.07
Iteration:    780, Loss function: 5.961, Average Loss: 4.045, avg. samples / sec: 65941.11
Iteration:    780, Loss function: 4.981, Average Loss: 4.045, avg. samples / sec: 65975.31
Iteration:    780, Loss function: 4.236, Average Loss: 4.056, avg. samples / sec: 66011.63
Iteration:    780, Loss function: 6.474, Average Loss: 4.080, avg. samples / sec: 65901.15
Iteration:    780, Loss function: 5.496, Average Loss: 4.019, avg. samples / sec: 65890.89
Iteration:    780, Loss function: 5.780, Average Loss: 4.072, avg. samples / sec: 65838.25
Iteration:    780, Loss function: 6.073, Average Loss: 4.044, avg. samples / sec: 65863.85
Iteration:    780, Loss function: 4.601, Average Loss: 4.048, avg. samples / sec: 65837.51
Iteration:    780, Loss function: 4.722, Average Loss: 4.049, avg. samples / sec: 65863.39
Iteration:    780, Loss function: 4.644, Average Loss: 4.052, avg. samples / sec: 65923.37
Iteration:    780, Loss function: 6.559, Average Loss: 4.051, avg. samples / sec: 65975.50
Iteration:    780, Loss function: 5.606, Average Loss: 4.049, avg. samples / sec: 65923.03
Iteration:    780, Loss function: 5.000, Average Loss: 4.041, avg. samples / sec: 65790.85
Iteration:    800, Loss function: 4.773, Average Loss: 4.073, avg. samples / sec: 65758.04
Iteration:    800, Loss function: 5.579, Average Loss: 4.091, avg. samples / sec: 65616.01
Iteration:    800, Loss function: 5.509, Average Loss: 4.061, avg. samples / sec: 65668.44
Iteration:    800, Loss function: 5.496, Average Loss: 4.110, avg. samples / sec: 65749.32
Iteration:    800, Loss function: 5.818, Average Loss: 4.103, avg. samples / sec: 65640.61
Iteration:    800, Loss function: 5.708, Average Loss: 4.075, avg. samples / sec: 65763.10
Iteration:    800, Loss function: 4.917, Average Loss: 4.070, avg. samples / sec: 65649.66
Iteration:    800, Loss function: 6.379, Average Loss: 4.096, avg. samples / sec: 65675.57
Iteration:    800, Loss function: 4.655, Average Loss: 4.074, avg. samples / sec: 65703.71
Iteration:    800, Loss function: 5.028, Average Loss: 4.099, avg. samples / sec: 65720.41
Iteration:    800, Loss function: 5.075, Average Loss: 4.078, avg. samples / sec: 65777.50
Iteration:    800, Loss function: 5.797, Average Loss: 4.072, avg. samples / sec: 65588.80
Iteration:    800, Loss function: 4.935, Average Loss: 4.080, avg. samples / sec: 65701.08
Iteration:    800, Loss function: 5.209, Average Loss: 4.070, avg. samples / sec: 65566.89
Iteration:    800, Loss function: 5.901, Average Loss: 4.097, avg. samples / sec: 65611.15
Iteration:    800, Loss function: 5.558, Average Loss: 4.088, avg. samples / sec: 65660.79
Iteration:    800, Loss function: 5.464, Average Loss: 4.081, avg. samples / sec: 65585.41
Iteration:    800, Loss function: 5.773, Average Loss: 4.075, avg. samples / sec: 65638.68
Iteration:    800, Loss function: 4.031, Average Loss: 4.046, avg. samples / sec: 65637.18
Iteration:    800, Loss function: 5.189, Average Loss: 4.080, avg. samples / sec: 65677.35
Iteration:    800, Loss function: 4.980, Average Loss: 4.098, avg. samples / sec: 65487.27
Iteration:    800, Loss function: 5.146, Average Loss: 4.088, avg. samples / sec: 65469.51
Iteration:    800, Loss function: 5.610, Average Loss: 4.081, avg. samples / sec: 65469.81
Iteration:    800, Loss function: 5.965, Average Loss: 4.072, avg. samples / sec: 65579.18
Iteration:    800, Loss function: 5.630, Average Loss: 4.068, avg. samples / sec: 65519.49
Iteration:    800, Loss function: 6.741, Average Loss: 4.078, avg. samples / sec: 65609.22
Iteration:    800, Loss function: 4.188, Average Loss: 4.083, avg. samples / sec: 65593.99
Iteration:    800, Loss function: 4.323, Average Loss: 4.069, avg. samples / sec: 65561.31
Iteration:    800, Loss function: 6.727, Average Loss: 4.076, avg. samples / sec: 65460.69
Iteration:    800, Loss function: 6.517, Average Loss: 4.071, avg. samples / sec: 65592.64
Iteration:    820, Loss function: 4.813, Average Loss: 4.106, avg. samples / sec: 66290.62
Iteration:    820, Loss function: 5.116, Average Loss: 4.117, avg. samples / sec: 66099.40
Iteration:    820, Loss function: 5.228, Average Loss: 4.107, avg. samples / sec: 66145.32
Iteration:    820, Loss function: 4.975, Average Loss: 4.120, avg. samples / sec: 66252.22
Iteration:    820, Loss function: 4.993, Average Loss: 4.096, avg. samples / sec: 66327.43
Iteration:    820, Loss function: 5.557, Average Loss: 4.122, avg. samples / sec: 66165.78
Iteration:    820, Loss function: 5.771, Average Loss: 4.110, avg. samples / sec: 66182.40
Iteration:    820, Loss function: 5.408, Average Loss: 4.087, avg. samples / sec: 66064.88
Iteration:    820, Loss function: 5.695, Average Loss: 4.074, avg. samples / sec: 66185.61
Iteration:    820, Loss function: 5.249, Average Loss: 4.095, avg. samples / sec: 66034.24
Iteration:    820, Loss function: 4.999, Average Loss: 4.105, avg. samples / sec: 66074.24
Iteration:    820, Loss function: 5.096, Average Loss: 4.103, avg. samples / sec: 66160.62
Iteration:    820, Loss function: 4.288, Average Loss: 4.104, avg. samples / sec: 66109.91
Iteration:    820, Loss function: 5.251, Average Loss: 4.114, avg. samples / sec: 66156.25
Iteration:    820, Loss function: 4.696, Average Loss: 4.096, avg. samples / sec: 66055.00
Iteration:    820, Loss function: 5.143, Average Loss: 4.105, avg. samples / sec: 66183.18
Iteration:    820, Loss function: 6.339, Average Loss: 4.129, avg. samples / sec: 66038.32
Iteration:    820, Loss function: 5.000, Average Loss: 4.106, avg. samples / sec: 66125.89
Iteration:    820, Loss function: 4.869, Average Loss: 4.117, avg. samples / sec: 66079.16
Iteration:    820, Loss function: 5.460, Average Loss: 4.103, avg. samples / sec: 66072.16
Iteration:    820, Loss function: 5.297, Average Loss: 4.133, avg. samples / sec: 65966.85
Iteration:    820, Loss function: 4.709, Average Loss: 4.100, avg. samples / sec: 66008.97
Iteration:    820, Loss function: 5.311, Average Loss: 4.134, avg. samples / sec: 65945.00
Iteration:    820, Loss function: 3.999, Average Loss: 4.105, avg. samples / sec: 66030.46
Iteration:    820, Loss function: 4.733, Average Loss: 4.122, avg. samples / sec: 65956.54
Iteration:    820, Loss function: 6.126, Average Loss: 4.101, avg. samples / sec: 66065.90
Iteration:    820, Loss function: 4.636, Average Loss: 4.096, avg. samples / sec: 66036.90
Iteration:    820, Loss function: 5.365, Average Loss: 4.114, avg. samples / sec: 65991.66
Iteration:    820, Loss function: 5.109, Average Loss: 4.108, avg. samples / sec: 65997.99
Iteration:    820, Loss function: 5.883, Average Loss: 4.105, avg. samples / sec: 65920.38
:::MLL 1558651712.225 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558651712.226 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 5.214, Average Loss: 4.118, avg. samples / sec: 65912.46
Iteration:    840, Loss function: 5.554, Average Loss: 4.097, avg. samples / sec: 65895.57
Iteration:    840, Loss function: 4.991, Average Loss: 4.151, avg. samples / sec: 65994.50
Iteration:    840, Loss function: 4.909, Average Loss: 4.138, avg. samples / sec: 65819.65
Iteration:    840, Loss function: 4.587, Average Loss: 4.153, avg. samples / sec: 65990.76
Iteration:    840, Loss function: 5.017, Average Loss: 4.129, avg. samples / sec: 65920.01
Iteration:    840, Loss function: 5.199, Average Loss: 4.125, avg. samples / sec: 66053.58
Iteration:    840, Loss function: 5.159, Average Loss: 4.115, avg. samples / sec: 65904.72
Iteration:    840, Loss function: 6.139, Average Loss: 4.124, avg. samples / sec: 65761.17
Iteration:    840, Loss function: 5.993, Average Loss: 4.147, avg. samples / sec: 65986.22
Iteration:    840, Loss function: 4.565, Average Loss: 4.133, avg. samples / sec: 65780.81
Iteration:    840, Loss function: 5.073, Average Loss: 4.119, avg. samples / sec: 65901.58
Iteration:    840, Loss function: 4.500, Average Loss: 4.144, avg. samples / sec: 65817.28
Iteration:    840, Loss function: 4.754, Average Loss: 4.108, avg. samples / sec: 65814.17
Iteration:    840, Loss function: 4.166, Average Loss: 4.121, avg. samples / sec: 65827.92
Iteration:    840, Loss function: 5.945, Average Loss: 4.134, avg. samples / sec: 65998.39
Iteration:    840, Loss function: 4.825, Average Loss: 4.116, avg. samples / sec: 65802.16
Iteration:    840, Loss function: 5.228, Average Loss: 4.130, avg. samples / sec: 65741.50
Iteration:    840, Loss function: 5.187, Average Loss: 4.128, avg. samples / sec: 65876.44
Iteration:    840, Loss function: 4.294, Average Loss: 4.131, avg. samples / sec: 65780.23
Iteration:    840, Loss function: 3.844, Average Loss: 4.153, avg. samples / sec: 65834.03
Iteration:    840, Loss function: 5.014, Average Loss: 4.133, avg. samples / sec: 65832.22
Iteration:    840, Loss function: 5.367, Average Loss: 4.130, avg. samples / sec: 65901.73
Iteration:    840, Loss function: 4.595, Average Loss: 4.138, avg. samples / sec: 65820.11
Iteration:    840, Loss function: 5.280, Average Loss: 4.136, avg. samples / sec: 65913.14
Iteration:    840, Loss function: 4.853, Average Loss: 4.123, avg. samples / sec: 65742.02
Iteration:    840, Loss function: 5.888, Average Loss: 4.126, avg. samples / sec: 65770.56
Iteration:    840, Loss function: 6.226, Average Loss: 4.127, avg. samples / sec: 65859.63
Iteration:    840, Loss function: 4.467, Average Loss: 4.118, avg. samples / sec: 65858.15
Iteration:    840, Loss function: 4.525, Average Loss: 4.126, avg. samples / sec: 65661.50
Iteration:    860, Loss function: 4.605, Average Loss: 4.158, avg. samples / sec: 65851.51
Iteration:    860, Loss function: 4.816, Average Loss: 4.172, avg. samples / sec: 65804.68
Iteration:    860, Loss function: 4.720, Average Loss: 4.133, avg. samples / sec: 65876.96
Iteration:    860, Loss function: 4.628, Average Loss: 4.177, avg. samples / sec: 65831.70
Iteration:    860, Loss function: 3.887, Average Loss: 4.171, avg. samples / sec: 65893.78
Iteration:    860, Loss function: 4.740, Average Loss: 4.170, avg. samples / sec: 65816.66
Iteration:    860, Loss function: 5.305, Average Loss: 4.158, avg. samples / sec: 65936.08
Iteration:    860, Loss function: 5.241, Average Loss: 4.119, avg. samples / sec: 65719.80
Iteration:    860, Loss function: 5.075, Average Loss: 4.142, avg. samples / sec: 65666.18
Iteration:    860, Loss function: 5.243, Average Loss: 4.144, avg. samples / sec: 65798.32
Iteration:    860, Loss function: 5.321, Average Loss: 4.141, avg. samples / sec: 65786.83
Iteration:    860, Loss function: 5.917, Average Loss: 4.147, avg. samples / sec: 65767.86
Iteration:    860, Loss function: 6.353, Average Loss: 4.151, avg. samples / sec: 65753.19
Iteration:    860, Loss function: 5.937, Average Loss: 4.164, avg. samples / sec: 65804.62
Iteration:    860, Loss function: 5.676, Average Loss: 4.147, avg. samples / sec: 65864.43
Iteration:    860, Loss function: 4.597, Average Loss: 4.144, avg. samples / sec: 65895.42
Iteration:    860, Loss function: 5.228, Average Loss: 4.161, avg. samples / sec: 65741.63
Iteration:    860, Loss function: 4.936, Average Loss: 4.153, avg. samples / sec: 65774.12
Iteration:    860, Loss function: 5.537, Average Loss: 4.156, avg. samples / sec: 65814.27
Iteration:    860, Loss function: 4.040, Average Loss: 4.156, avg. samples / sec: 65927.94
Iteration:    860, Loss function: 6.308, Average Loss: 4.173, avg. samples / sec: 65718.30
Iteration:    860, Loss function: 4.996, Average Loss: 4.148, avg. samples / sec: 65695.32
Iteration:    860, Loss function: 5.635, Average Loss: 4.158, avg. samples / sec: 65725.62
Iteration:    860, Loss function: 4.388, Average Loss: 4.151, avg. samples / sec: 65797.34
Iteration:    860, Loss function: 5.711, Average Loss: 4.146, avg. samples / sec: 65715.20
Iteration:    860, Loss function: 5.851, Average Loss: 4.158, avg. samples / sec: 65721.18
Iteration:    860, Loss function: 5.037, Average Loss: 4.155, avg. samples / sec: 65741.66
Iteration:    860, Loss function: 4.973, Average Loss: 4.151, avg. samples / sec: 65706.04
Iteration:    860, Loss function: 5.581, Average Loss: 4.143, avg. samples / sec: 65748.96
Iteration:    860, Loss function: 4.496, Average Loss: 4.123, avg. samples / sec: 65624.38
Iteration:    880, Loss function: 6.397, Average Loss: 4.179, avg. samples / sec: 65046.01
Iteration:    880, Loss function: 4.211, Average Loss: 4.153, avg. samples / sec: 65056.31
Iteration:    880, Loss function: 5.646, Average Loss: 4.148, avg. samples / sec: 65326.30
Iteration:    880, Loss function: 4.981, Average Loss: 4.172, avg. samples / sec: 65088.01
Iteration:    880, Loss function: 4.772, Average Loss: 4.181, avg. samples / sec: 65146.56
Iteration:    880, Loss function: 4.494, Average Loss: 4.170, avg. samples / sec: 65113.48
Iteration:    880, Loss function: 4.808, Average Loss: 4.169, avg. samples / sec: 65124.07
Iteration:    880, Loss function: 4.729, Average Loss: 4.179, avg. samples / sec: 65190.13
Iteration:    880, Loss function: 6.698, Average Loss: 4.185, avg. samples / sec: 65142.19
Iteration:    880, Loss function: 5.654, Average Loss: 4.166, avg. samples / sec: 65161.08
Iteration:    880, Loss function: 5.392, Average Loss: 4.178, avg. samples / sec: 65112.33
Iteration:    880, Loss function: 4.709, Average Loss: 4.161, avg. samples / sec: 65066.28
Iteration:    880, Loss function: 5.306, Average Loss: 4.172, avg. samples / sec: 65193.24
Iteration:    880, Loss function: 5.901, Average Loss: 4.189, avg. samples / sec: 64999.60
Iteration:    880, Loss function: 5.024, Average Loss: 4.165, avg. samples / sec: 65049.88
Iteration:    880, Loss function: 5.666, Average Loss: 4.140, avg. samples / sec: 65020.08
Iteration:    880, Loss function: 4.444, Average Loss: 4.174, avg. samples / sec: 65120.52
Iteration:    880, Loss function: 5.288, Average Loss: 4.165, avg. samples / sec: 65162.16
Iteration:    880, Loss function: 5.365, Average Loss: 4.169, avg. samples / sec: 65045.74
Iteration:    880, Loss function: 5.282, Average Loss: 4.195, avg. samples / sec: 65067.42
Iteration:    880, Loss function: 4.412, Average Loss: 4.194, avg. samples / sec: 64917.38
Iteration:    880, Loss function: 4.374, Average Loss: 4.181, avg. samples / sec: 65014.77
Iteration:    880, Loss function: 5.039, Average Loss: 4.195, avg. samples / sec: 64903.09
Iteration:    880, Loss function: 4.876, Average Loss: 4.167, avg. samples / sec: 65032.74
Iteration:    880, Loss function: 3.936, Average Loss: 4.165, avg. samples / sec: 64947.56
Iteration:    880, Loss function: 4.625, Average Loss: 4.177, avg. samples / sec: 65001.72
Iteration:    880, Loss function: 5.527, Average Loss: 4.194, avg. samples / sec: 64863.71
Iteration:    880, Loss function: 6.001, Average Loss: 4.168, avg. samples / sec: 64896.18
Iteration:    880, Loss function: 6.491, Average Loss: 4.167, avg. samples / sec: 64898.78
Iteration:    880, Loss function: 4.587, Average Loss: 4.175, avg. samples / sec: 64977.45
Iteration:    900, Loss function: 5.098, Average Loss: 4.201, avg. samples / sec: 66354.91
Iteration:    900, Loss function: 4.508, Average Loss: 4.181, avg. samples / sec: 66436.90
Iteration:    900, Loss function: 5.894, Average Loss: 4.218, avg. samples / sec: 66442.79
Iteration:    900, Loss function: 4.493, Average Loss: 4.199, avg. samples / sec: 66333.05
Iteration:    900, Loss function: 5.037, Average Loss: 4.164, avg. samples / sec: 66291.96
Iteration:    900, Loss function: 4.157, Average Loss: 4.190, avg. samples / sec: 66333.21
Iteration:    900, Loss function: 6.366, Average Loss: 4.208, avg. samples / sec: 66402.72
Iteration:    900, Loss function: 3.816, Average Loss: 4.196, avg. samples / sec: 66415.49
Iteration:    900, Loss function: 4.571, Average Loss: 4.201, avg. samples / sec: 66378.60
Iteration:    900, Loss function: 4.600, Average Loss: 4.188, avg. samples / sec: 66465.48
Iteration:    900, Loss function: 5.272, Average Loss: 4.205, avg. samples / sec: 66335.42
Iteration:    900, Loss function: 5.925, Average Loss: 4.193, avg. samples / sec: 66532.13
Iteration:    900, Loss function: 3.955, Average Loss: 4.196, avg. samples / sec: 66392.93
Iteration:    900, Loss function: 5.754, Average Loss: 4.187, avg. samples / sec: 66318.13
Iteration:    900, Loss function: 4.872, Average Loss: 4.170, avg. samples / sec: 66227.75
Iteration:    900, Loss function: 4.691, Average Loss: 4.188, avg. samples / sec: 66323.19
Iteration:    900, Loss function: 5.717, Average Loss: 4.183, avg. samples / sec: 66300.32
Iteration:    900, Loss function: 4.726, Average Loss: 4.190, avg. samples / sec: 66223.86
Iteration:    900, Loss function: 5.304, Average Loss: 4.192, avg. samples / sec: 66394.33
Iteration:    900, Loss function: 4.787, Average Loss: 4.213, avg. samples / sec: 66333.02
Iteration:    900, Loss function: 4.969, Average Loss: 4.217, avg. samples / sec: 66321.31
Iteration:    900, Loss function: 5.242, Average Loss: 4.182, avg. samples / sec: 66438.59
Iteration:    900, Loss function: 5.276, Average Loss: 4.190, avg. samples / sec: 66419.18
Iteration:    900, Loss function: 5.259, Average Loss: 4.192, avg. samples / sec: 66187.28
Iteration:    900, Loss function: 4.244, Average Loss: 4.207, avg. samples / sec: 66374.60
Iteration:    900, Loss function: 5.473, Average Loss: 4.183, avg. samples / sec: 66275.00
Iteration:    900, Loss function: 6.076, Average Loss: 4.199, avg. samples / sec: 66168.11
Iteration:    900, Loss function: 4.805, Average Loss: 4.161, avg. samples / sec: 66199.41
Iteration:    900, Loss function: 5.650, Average Loss: 4.190, avg. samples / sec: 66196.74
Iteration:    900, Loss function: 6.095, Average Loss: 4.198, avg. samples / sec: 66247.99
:::MLL 1558651714.016 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558651714.016 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 5.520, Average Loss: 4.219, avg. samples / sec: 65520.61
Iteration:    920, Loss function: 3.991, Average Loss: 4.209, avg. samples / sec: 65660.12
Iteration:    920, Loss function: 5.409, Average Loss: 4.221, avg. samples / sec: 65597.50
Iteration:    920, Loss function: 5.192, Average Loss: 4.187, avg. samples / sec: 65570.52
Iteration:    920, Loss function: 4.769, Average Loss: 4.208, avg. samples / sec: 65521.77
Iteration:    920, Loss function: 6.059, Average Loss: 4.207, avg. samples / sec: 65574.73
Iteration:    920, Loss function: 4.542, Average Loss: 4.190, avg. samples / sec: 65592.83
Iteration:    920, Loss function: 4.912, Average Loss: 4.240, avg. samples / sec: 65525.27
Iteration:    920, Loss function: 4.893, Average Loss: 4.211, avg. samples / sec: 65615.95
Iteration:    920, Loss function: 5.302, Average Loss: 4.221, avg. samples / sec: 65527.89
Iteration:    920, Loss function: 4.845, Average Loss: 4.213, avg. samples / sec: 65658.16
Iteration:    920, Loss function: 5.313, Average Loss: 4.201, avg. samples / sec: 65675.17
Iteration:    920, Loss function: 5.317, Average Loss: 4.214, avg. samples / sec: 65743.77
Iteration:    920, Loss function: 4.681, Average Loss: 4.214, avg. samples / sec: 65532.01
Iteration:    920, Loss function: 5.821, Average Loss: 4.229, avg. samples / sec: 65510.23
Iteration:    920, Loss function: 5.662, Average Loss: 4.186, avg. samples / sec: 65682.31
Iteration:    920, Loss function: 3.604, Average Loss: 4.206, avg. samples / sec: 65612.22
Iteration:    920, Loss function: 4.108, Average Loss: 4.238, avg. samples / sec: 65583.49
Iteration:    920, Loss function: 4.656, Average Loss: 4.211, avg. samples / sec: 65451.14
Iteration:    920, Loss function: 5.131, Average Loss: 4.235, avg. samples / sec: 65540.15
Iteration:    920, Loss function: 5.025, Average Loss: 4.212, avg. samples / sec: 65474.37
Iteration:    920, Loss function: 4.929, Average Loss: 4.225, avg. samples / sec: 65423.37
Iteration:    920, Loss function: 5.160, Average Loss: 4.203, avg. samples / sec: 65517.48
Iteration:    920, Loss function: 5.463, Average Loss: 4.219, avg. samples / sec: 65680.50
Iteration:    920, Loss function: 3.954, Average Loss: 4.214, avg. samples / sec: 65435.73
Iteration:    920, Loss function: 3.949, Average Loss: 4.208, avg. samples / sec: 65489.31
Iteration:    920, Loss function: 4.741, Average Loss: 4.208, avg. samples / sec: 65543.38
Iteration:    920, Loss function: 5.135, Average Loss: 4.211, avg. samples / sec: 65458.96
Iteration:    920, Loss function: 5.292, Average Loss: 4.219, avg. samples / sec: 65553.32
Iteration:    920, Loss function: 4.628, Average Loss: 4.226, avg. samples / sec: 65516.96
Iteration:    940, Loss function: 7.463, Average Loss: 4.227, avg. samples / sec: 65098.08
Iteration:    940, Loss function: 4.559, Average Loss: 4.231, avg. samples / sec: 64918.57
Iteration:    940, Loss function: 6.065, Average Loss: 4.201, avg. samples / sec: 64981.58
Iteration:    940, Loss function: 4.061, Average Loss: 4.206, avg. samples / sec: 64909.63
Iteration:    940, Loss function: 5.209, Average Loss: 4.255, avg. samples / sec: 64923.75
Iteration:    940, Loss function: 4.112, Average Loss: 4.224, avg. samples / sec: 64903.15
Iteration:    940, Loss function: 5.419, Average Loss: 4.236, avg. samples / sec: 64931.64
Iteration:    940, Loss function: 4.812, Average Loss: 4.236, avg. samples / sec: 64942.18
Iteration:    940, Loss function: 5.499, Average Loss: 4.234, avg. samples / sec: 65012.31
Iteration:    940, Loss function: 4.058, Average Loss: 4.252, avg. samples / sec: 64971.85
Iteration:    940, Loss function: 4.716, Average Loss: 4.218, avg. samples / sec: 64946.13
Iteration:    940, Loss function: 4.861, Average Loss: 4.201, avg. samples / sec: 64951.96
Iteration:    940, Loss function: 4.522, Average Loss: 4.221, avg. samples / sec: 64964.45
Iteration:    940, Loss function: 5.402, Average Loss: 4.243, avg. samples / sec: 64995.46
Iteration:    940, Loss function: 5.910, Average Loss: 4.228, avg. samples / sec: 64799.29
Iteration:    940, Loss function: 3.802, Average Loss: 4.228, avg. samples / sec: 64951.54
Iteration:    940, Loss function: 5.421, Average Loss: 4.216, avg. samples / sec: 64882.74
Iteration:    940, Loss function: 4.543, Average Loss: 4.249, avg. samples / sec: 64897.65
Iteration:    940, Loss function: 4.825, Average Loss: 4.225, avg. samples / sec: 64826.45
Iteration:    940, Loss function: 4.766, Average Loss: 4.230, avg. samples / sec: 64933.68
Iteration:    940, Loss function: 6.414, Average Loss: 4.230, avg. samples / sec: 64826.12
Iteration:    940, Loss function: 4.663, Average Loss: 4.223, avg. samples / sec: 64945.89
Iteration:    940, Loss function: 5.353, Average Loss: 4.234, avg. samples / sec: 64970.11
Iteration:    940, Loss function: 6.583, Average Loss: 4.236, avg. samples / sec: 64725.87
Iteration:    940, Loss function: 4.845, Average Loss: 4.225, avg. samples / sec: 64886.92
Iteration:    940, Loss function: 5.598, Average Loss: 4.226, avg. samples / sec: 64952.44
Iteration:    940, Loss function: 5.449, Average Loss: 4.243, avg. samples / sec: 64946.88
Iteration:    940, Loss function: 5.110, Average Loss: 4.227, avg. samples / sec: 64817.12
Iteration:    940, Loss function: 5.877, Average Loss: 4.233, avg. samples / sec: 64848.28
Iteration:    940, Loss function: 4.132, Average Loss: 4.249, avg. samples / sec: 64858.55
Iteration:    960, Loss function: 5.304, Average Loss: 4.252, avg. samples / sec: 66544.69
Iteration:    960, Loss function: 5.049, Average Loss: 4.242, avg. samples / sec: 66189.03
Iteration:    960, Loss function: 5.488, Average Loss: 4.243, avg. samples / sec: 66271.01
Iteration:    960, Loss function: 4.637, Average Loss: 4.265, avg. samples / sec: 66334.58
Iteration:    960, Loss function: 3.988, Average Loss: 4.242, avg. samples / sec: 66359.29
Iteration:    960, Loss function: 6.231, Average Loss: 4.250, avg. samples / sec: 66413.70
Iteration:    960, Loss function: 5.058, Average Loss: 4.241, avg. samples / sec: 66427.95
Iteration:    960, Loss function: 5.097, Average Loss: 4.275, avg. samples / sec: 66285.91
Iteration:    960, Loss function: 3.874, Average Loss: 4.239, avg. samples / sec: 66265.37
Iteration:    960, Loss function: 6.557, Average Loss: 4.218, avg. samples / sec: 66182.09
Iteration:    960, Loss function: 6.288, Average Loss: 4.235, avg. samples / sec: 66314.26
Iteration:    960, Loss function: 5.229, Average Loss: 4.249, avg. samples / sec: 66343.14
Iteration:    960, Loss function: 3.641, Average Loss: 4.244, avg. samples / sec: 66306.21
Iteration:    960, Loss function: 5.696, Average Loss: 4.246, avg. samples / sec: 66404.00
Iteration:    960, Loss function: 5.137, Average Loss: 4.248, avg. samples / sec: 66254.47
Iteration:    960, Loss function: 4.791, Average Loss: 4.248, avg. samples / sec: 66226.32
Iteration:    960, Loss function: 5.670, Average Loss: 4.226, avg. samples / sec: 66191.26
Iteration:    960, Loss function: 4.464, Average Loss: 4.259, avg. samples / sec: 66246.59
Iteration:    960, Loss function: 5.090, Average Loss: 4.245, avg. samples / sec: 66352.10
Iteration:    960, Loss function: 6.053, Average Loss: 4.239, avg. samples / sec: 66232.51
Iteration:    960, Loss function: 4.860, Average Loss: 4.237, avg. samples / sec: 66291.40
Iteration:    960, Loss function: 4.860, Average Loss: 4.249, avg. samples / sec: 66377.57
Iteration:    960, Loss function: 5.259, Average Loss: 4.269, avg. samples / sec: 66378.95
Iteration:    960, Loss function: 4.899, Average Loss: 4.216, avg. samples / sec: 66223.46
Iteration:    960, Loss function: 4.795, Average Loss: 4.253, avg. samples / sec: 66278.83
Iteration:    960, Loss function: 4.430, Average Loss: 4.255, avg. samples / sec: 66296.17
Iteration:    960, Loss function: 7.097, Average Loss: 4.266, avg. samples / sec: 66192.45
Iteration:    960, Loss function: 6.749, Average Loss: 4.250, avg. samples / sec: 66111.34
Iteration:    960, Loss function: 4.770, Average Loss: 4.241, avg. samples / sec: 66183.99
Iteration:    960, Loss function: 5.184, Average Loss: 4.231, avg. samples / sec: 66050.51
:::MLL 1558651715.814 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558651715.814 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 5.882, Average Loss: 4.261, avg. samples / sec: 64991.17
Iteration:    980, Loss function: 4.706, Average Loss: 4.283, avg. samples / sec: 64947.74
Iteration:    980, Loss function: 5.708, Average Loss: 4.265, avg. samples / sec: 65003.46
Iteration:    980, Loss function: 4.118, Average Loss: 4.257, avg. samples / sec: 64892.51
Iteration:    980, Loss function: 4.299, Average Loss: 4.258, avg. samples / sec: 65019.54
Iteration:    980, Loss function: 6.364, Average Loss: 4.262, avg. samples / sec: 65132.38
Iteration:    980, Loss function: 3.719, Average Loss: 4.247, avg. samples / sec: 65008.32
Iteration:    980, Loss function: 4.163, Average Loss: 4.267, avg. samples / sec: 64814.88
Iteration:    980, Loss function: 5.008, Average Loss: 4.264, avg. samples / sec: 65129.03
Iteration:    980, Loss function: 4.903, Average Loss: 4.283, avg. samples / sec: 65023.86
Iteration:    980, Loss function: 5.485, Average Loss: 4.264, avg. samples / sec: 64898.18
Iteration:    980, Loss function: 4.007, Average Loss: 4.260, avg. samples / sec: 64910.83
Iteration:    980, Loss function: 6.462, Average Loss: 4.275, avg. samples / sec: 65011.23
Iteration:    980, Loss function: 4.956, Average Loss: 4.254, avg. samples / sec: 65004.45
Iteration:    980, Loss function: 5.393, Average Loss: 4.234, avg. samples / sec: 64946.73
Iteration:    980, Loss function: 6.202, Average Loss: 4.276, avg. samples / sec: 65045.23
Iteration:    980, Loss function: 4.346, Average Loss: 4.292, avg. samples / sec: 64886.44
Iteration:    980, Loss function: 4.982, Average Loss: 4.262, avg. samples / sec: 64984.01
Iteration:    980, Loss function: 4.802, Average Loss: 4.288, avg. samples / sec: 65061.08
Iteration:    980, Loss function: 4.590, Average Loss: 4.253, avg. samples / sec: 64917.41
Iteration:    980, Loss function: 4.784, Average Loss: 4.256, avg. samples / sec: 64881.51
Iteration:    980, Loss function: 5.614, Average Loss: 4.255, avg. samples / sec: 64851.15
Iteration:    980, Loss function: 4.950, Average Loss: 4.269, avg. samples / sec: 64928.02
Iteration:    980, Loss function: 5.569, Average Loss: 4.231, avg. samples / sec: 64943.13
Iteration:    980, Loss function: 4.395, Average Loss: 4.262, avg. samples / sec: 64955.86
Iteration:    980, Loss function: 6.451, Average Loss: 4.260, avg. samples / sec: 64883.84
Iteration:    980, Loss function: 4.559, Average Loss: 4.262, avg. samples / sec: 64877.90
Iteration:    980, Loss function: 4.681, Average Loss: 4.273, avg. samples / sec: 64941.37
Iteration:    980, Loss function: 3.613, Average Loss: 4.248, avg. samples / sec: 64969.63
Iteration:    980, Loss function: 5.153, Average Loss: 4.262, avg. samples / sec: 64742.58
Iteration:   1000, Loss function: 4.759, Average Loss: 4.247, avg. samples / sec: 66354.45
Iteration:   1000, Loss function: 3.908, Average Loss: 4.283, avg. samples / sec: 66250.54
Iteration:   1000, Loss function: 4.296, Average Loss: 4.261, avg. samples / sec: 66221.87
Iteration:   1000, Loss function: 4.398, Average Loss: 4.274, avg. samples / sec: 66225.82
Iteration:   1000, Loss function: 4.867, Average Loss: 4.312, avg. samples / sec: 66259.42
Iteration:   1000, Loss function: 5.672, Average Loss: 4.301, avg. samples / sec: 66200.69
Iteration:   1000, Loss function: 5.703, Average Loss: 4.281, avg. samples / sec: 66170.88
Iteration:   1000, Loss function: 3.924, Average Loss: 4.281, avg. samples / sec: 66205.38
Iteration:   1000, Loss function: 5.606, Average Loss: 4.271, avg. samples / sec: 66241.57
Iteration:   1000, Loss function: 5.285, Average Loss: 4.280, avg. samples / sec: 66261.19
Iteration:   1000, Loss function: 4.329, Average Loss: 4.278, avg. samples / sec: 66042.59
Iteration:   1000, Loss function: 6.592, Average Loss: 4.294, avg. samples / sec: 66163.17
Iteration:   1000, Loss function: 5.096, Average Loss: 4.288, avg. samples / sec: 66239.46
Iteration:   1000, Loss function: 5.102, Average Loss: 4.271, avg. samples / sec: 66231.61
Iteration:   1000, Loss function: 4.999, Average Loss: 4.282, avg. samples / sec: 66140.94
Iteration:   1000, Loss function: 5.453, Average Loss: 4.288, avg. samples / sec: 66164.97
Iteration:   1000, Loss function: 6.003, Average Loss: 4.286, avg. samples / sec: 66102.62
Iteration:   1000, Loss function: 5.444, Average Loss: 4.278, avg. samples / sec: 66109.88
Iteration:   1000, Loss function: 4.657, Average Loss: 4.278, avg. samples / sec: 66145.81
Iteration:   1000, Loss function: 6.258, Average Loss: 4.299, avg. samples / sec: 66049.09
Iteration:   1000, Loss function: 4.387, Average Loss: 4.273, avg. samples / sec: 66077.21
Iteration:   1000, Loss function: 6.522, Average Loss: 4.248, avg. samples / sec: 66108.95
Iteration:   1000, Loss function: 5.771, Average Loss: 4.271, avg. samples / sec: 66155.50
Iteration:   1000, Loss function: 4.274, Average Loss: 4.265, avg. samples / sec: 66118.63
Iteration:   1000, Loss function: 4.079, Average Loss: 4.276, avg. samples / sec: 66134.92
Iteration:   1000, Loss function: 5.288, Average Loss: 4.282, avg. samples / sec: 66118.57
Iteration:   1000, Loss function: 5.749, Average Loss: 4.306, avg. samples / sec: 66049.21
Iteration:   1000, Loss function: 4.403, Average Loss: 4.280, avg. samples / sec: 66003.06
Iteration:   1000, Loss function: 6.362, Average Loss: 4.265, avg. samples / sec: 66199.97
Iteration:   1000, Loss function: 5.275, Average Loss: 4.275, avg. samples / sec: 66179.73
Iteration:   1020, Loss function: 4.828, Average Loss: 4.299, avg. samples / sec: 66095.96
Iteration:   1020, Loss function: 4.003, Average Loss: 4.297, avg. samples / sec: 66072.25
Iteration:   1020, Loss function: 2.890, Average Loss: 4.311, avg. samples / sec: 66146.50
Iteration:   1020, Loss function: 6.393, Average Loss: 4.332, avg. samples / sec: 66005.07
Iteration:   1020, Loss function: 4.907, Average Loss: 4.260, avg. samples / sec: 66094.69
Iteration:   1020, Loss function: 4.869, Average Loss: 4.317, avg. samples / sec: 65938.76
Iteration:   1020, Loss function: 5.067, Average Loss: 4.303, avg. samples / sec: 65882.66
Iteration:   1020, Loss function: 4.497, Average Loss: 4.296, avg. samples / sec: 65916.65
Iteration:   1020, Loss function: 3.883, Average Loss: 4.290, avg. samples / sec: 65899.98
Iteration:   1020, Loss function: 5.393, Average Loss: 4.292, avg. samples / sec: 66070.39
Iteration:   1020, Loss function: 5.934, Average Loss: 4.290, avg. samples / sec: 65961.17
Iteration:   1020, Loss function: 5.045, Average Loss: 4.306, avg. samples / sec: 65959.10
Iteration:   1020, Loss function: 5.335, Average Loss: 4.263, avg. samples / sec: 65831.14
Iteration:   1020, Loss function: 5.307, Average Loss: 4.277, avg. samples / sec: 65850.98
Iteration:   1020, Loss function: 5.286, Average Loss: 4.284, avg. samples / sec: 66010.82
Iteration:   1020, Loss function: 4.978, Average Loss: 4.296, avg. samples / sec: 66078.76
Iteration:   1020, Loss function: 5.392, Average Loss: 4.282, avg. samples / sec: 66031.95
Iteration:   1020, Loss function: 5.049, Average Loss: 4.301, avg. samples / sec: 65924.64
Iteration:   1020, Loss function: 4.924, Average Loss: 4.291, avg. samples / sec: 66129.58
Iteration:   1020, Loss function: 4.638, Average Loss: 4.280, avg. samples / sec: 66075.23
Iteration:   1020, Loss function: 4.565, Average Loss: 4.296, avg. samples / sec: 65947.25
Iteration:   1020, Loss function: 5.530, Average Loss: 4.288, avg. samples / sec: 65955.46
Iteration:   1020, Loss function: 5.225, Average Loss: 4.291, avg. samples / sec: 66043.24
Iteration:   1020, Loss function: 6.047, Average Loss: 4.304, avg. samples / sec: 65917.48
Iteration:   1020, Loss function: 4.203, Average Loss: 4.290, avg. samples / sec: 65873.36
Iteration:   1020, Loss function: 4.280, Average Loss: 4.312, avg. samples / sec: 65865.39
Iteration:   1020, Loss function: 6.456, Average Loss: 4.295, avg. samples / sec: 65921.15
Iteration:   1020, Loss function: 4.643, Average Loss: 4.303, avg. samples / sec: 65885.31
Iteration:   1020, Loss function: 4.509, Average Loss: 4.299, avg. samples / sec: 65836.22
Iteration:   1020, Loss function: 4.054, Average Loss: 4.324, avg. samples / sec: 65963.21
Iteration:   1040, Loss function: 4.602, Average Loss: 4.337, avg. samples / sec: 66283.51
Iteration:   1040, Loss function: 4.106, Average Loss: 4.307, avg. samples / sec: 66325.87
Iteration:   1040, Loss function: 5.416, Average Loss: 4.272, avg. samples / sec: 66248.21
Iteration:   1040, Loss function: 5.397, Average Loss: 4.312, avg. samples / sec: 66373.92
Iteration:   1040, Loss function: 5.004, Average Loss: 4.332, avg. samples / sec: 66279.99
Iteration:   1040, Loss function: 3.704, Average Loss: 4.320, avg. samples / sec: 66278.46
Iteration:   1040, Loss function: 4.791, Average Loss: 4.314, avg. samples / sec: 66131.78
Iteration:   1040, Loss function: 4.297, Average Loss: 4.320, avg. samples / sec: 66158.02
Iteration:   1040, Loss function: 6.405, Average Loss: 4.317, avg. samples / sec: 66308.55
Iteration:   1040, Loss function: 4.926, Average Loss: 4.307, avg. samples / sec: 66116.61
Iteration:   1040, Loss function: 4.447, Average Loss: 4.301, avg. samples / sec: 66338.77
Iteration:   1040, Loss function: 3.995, Average Loss: 4.296, avg. samples / sec: 66297.63
Iteration:   1040, Loss function: 4.614, Average Loss: 4.285, avg. samples / sec: 66256.37
Iteration:   1040, Loss function: 5.023, Average Loss: 4.303, avg. samples / sec: 66243.88
Iteration:   1040, Loss function: 3.672, Average Loss: 4.292, avg. samples / sec: 66275.37
Iteration:   1040, Loss function: 4.270, Average Loss: 4.330, avg. samples / sec: 66336.52
Iteration:   1040, Loss function: 5.183, Average Loss: 4.313, avg. samples / sec: 66234.66
Iteration:   1040, Loss function: 6.578, Average Loss: 4.301, avg. samples / sec: 66235.19
Iteration:   1040, Loss function: 4.701, Average Loss: 4.312, avg. samples / sec: 66203.42
Iteration:   1040, Loss function: 6.101, Average Loss: 4.331, avg. samples / sec: 66334.68
Iteration:   1040, Loss function: 4.866, Average Loss: 4.318, avg. samples / sec: 66194.00
Iteration:   1040, Loss function: 4.479, Average Loss: 4.301, avg. samples / sec: 66266.43
Iteration:   1040, Loss function: 5.000, Average Loss: 4.307, avg. samples / sec: 66265.59
Iteration:   1040, Loss function: 4.617, Average Loss: 4.292, avg. samples / sec: 66215.83
Iteration:   1040, Loss function: 6.065, Average Loss: 4.302, avg. samples / sec: 66165.47
Iteration:   1040, Loss function: 4.085, Average Loss: 4.304, avg. samples / sec: 66191.30
Iteration:   1040, Loss function: 5.220, Average Loss: 4.308, avg. samples / sec: 66209.27
Iteration:   1040, Loss function: 4.812, Average Loss: 4.318, avg. samples / sec: 66216.95
Iteration:   1040, Loss function: 5.291, Average Loss: 4.322, avg. samples / sec: 66205.10
Iteration:   1040, Loss function: 4.676, Average Loss: 4.314, avg. samples / sec: 66163.82
:::MLL 1558651717.594 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558651717.594 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 6.186, Average Loss: 4.344, avg. samples / sec: 65928.12
Iteration:   1060, Loss function: 5.310, Average Loss: 4.319, avg. samples / sec: 66003.80
Iteration:   1060, Loss function: 5.440, Average Loss: 4.326, avg. samples / sec: 66085.92
Iteration:   1060, Loss function: 5.478, Average Loss: 4.336, avg. samples / sec: 65868.28
Iteration:   1060, Loss function: 4.721, Average Loss: 4.333, avg. samples / sec: 65852.77
Iteration:   1060, Loss function: 4.116, Average Loss: 4.279, avg. samples / sec: 65836.37
Iteration:   1060, Loss function: 5.531, Average Loss: 4.320, avg. samples / sec: 66001.55
Iteration:   1060, Loss function: 4.337, Average Loss: 4.321, avg. samples / sec: 65909.35
Iteration:   1060, Loss function: 5.390, Average Loss: 4.310, avg. samples / sec: 65890.12
Iteration:   1060, Loss function: 5.538, Average Loss: 4.312, avg. samples / sec: 65813.65
Iteration:   1060, Loss function: 6.250, Average Loss: 4.353, avg. samples / sec: 65700.10
Iteration:   1060, Loss function: 5.410, Average Loss: 4.335, avg. samples / sec: 65955.89
Iteration:   1060, Loss function: 4.851, Average Loss: 4.315, avg. samples / sec: 65883.80
Iteration:   1060, Loss function: 5.566, Average Loss: 4.312, avg. samples / sec: 65907.03
Iteration:   1060, Loss function: 4.628, Average Loss: 4.320, avg. samples / sec: 65749.05
Iteration:   1060, Loss function: 4.142, Average Loss: 4.329, avg. samples / sec: 65756.23
Iteration:   1060, Loss function: 4.416, Average Loss: 4.339, avg. samples / sec: 65908.94
Iteration:   1060, Loss function: 5.027, Average Loss: 4.317, avg. samples / sec: 65708.43
Iteration:   1060, Loss function: 5.874, Average Loss: 4.321, avg. samples / sec: 65756.53
Iteration:   1060, Loss function: 3.814, Average Loss: 4.342, avg. samples / sec: 65791.38
Iteration:   1060, Loss function: 5.443, Average Loss: 4.300, avg. samples / sec: 65787.57
Iteration:   1060, Loss function: 5.096, Average Loss: 4.310, avg. samples / sec: 65749.54
Iteration:   1060, Loss function: 4.137, Average Loss: 4.329, avg. samples / sec: 65806.34
Iteration:   1060, Loss function: 4.081, Average Loss: 4.334, avg. samples / sec: 65822.63
Iteration:   1060, Loss function: 4.253, Average Loss: 4.306, avg. samples / sec: 65858.31
Iteration:   1060, Loss function: 4.337, Average Loss: 4.300, avg. samples / sec: 65752.30
Iteration:   1060, Loss function: 5.259, Average Loss: 4.323, avg. samples / sec: 65800.01
Iteration:   1060, Loss function: 5.380, Average Loss: 4.318, avg. samples / sec: 65683.19
Iteration:   1060, Loss function: 4.926, Average Loss: 4.313, avg. samples / sec: 65699.52
Iteration:   1060, Loss function: 5.247, Average Loss: 4.341, avg. samples / sec: 65670.77
Iteration:   1080, Loss function: 4.316, Average Loss: 4.352, avg. samples / sec: 66634.65
Iteration:   1080, Loss function: 4.691, Average Loss: 4.336, avg. samples / sec: 66724.37
Iteration:   1080, Loss function: 5.310, Average Loss: 4.339, avg. samples / sec: 66789.23
Iteration:   1080, Loss function: 3.926, Average Loss: 4.337, avg. samples / sec: 66586.89
Iteration:   1080, Loss function: 5.169, Average Loss: 4.345, avg. samples / sec: 66718.69
Iteration:   1080, Loss function: 5.273, Average Loss: 4.342, avg. samples / sec: 66585.91
Iteration:   1080, Loss function: 3.859, Average Loss: 4.329, avg. samples / sec: 66655.64
Iteration:   1080, Loss function: 4.638, Average Loss: 4.290, avg. samples / sec: 66548.12
Iteration:   1080, Loss function: 5.330, Average Loss: 4.349, avg. samples / sec: 66699.27
Iteration:   1080, Loss function: 5.142, Average Loss: 4.323, avg. samples / sec: 66603.91
Iteration:   1080, Loss function: 4.833, Average Loss: 4.315, avg. samples / sec: 66683.74
Iteration:   1080, Loss function: 5.644, Average Loss: 4.347, avg. samples / sec: 66568.05
Iteration:   1080, Loss function: 4.867, Average Loss: 4.330, avg. samples / sec: 66616.73
Iteration:   1080, Loss function: 5.542, Average Loss: 4.332, avg. samples / sec: 66520.13
Iteration:   1080, Loss function: 4.654, Average Loss: 4.335, avg. samples / sec: 66479.96
Iteration:   1080, Loss function: 5.656, Average Loss: 4.319, avg. samples / sec: 66597.43
Iteration:   1080, Loss function: 4.803, Average Loss: 4.364, avg. samples / sec: 66497.97
Iteration:   1080, Loss function: 6.400, Average Loss: 4.324, avg. samples / sec: 66567.26
Iteration:   1080, Loss function: 4.617, Average Loss: 4.348, avg. samples / sec: 66528.29
Iteration:   1080, Loss function: 4.266, Average Loss: 4.319, avg. samples / sec: 66531.28
Iteration:   1080, Loss function: 4.304, Average Loss: 4.325, avg. samples / sec: 66628.28
Iteration:   1080, Loss function: 5.559, Average Loss: 4.333, avg. samples / sec: 66474.13
Iteration:   1080, Loss function: 5.145, Average Loss: 4.348, avg. samples / sec: 66504.97
Iteration:   1080, Loss function: 5.098, Average Loss: 4.361, avg. samples / sec: 66500.10
Iteration:   1080, Loss function: 5.626, Average Loss: 4.359, avg. samples / sec: 66654.66
Iteration:   1080, Loss function: 5.051, Average Loss: 4.333, avg. samples / sec: 66353.85
Iteration:   1080, Loss function: 4.274, Average Loss: 4.356, avg. samples / sec: 66269.14
Iteration:   1080, Loss function: 4.534, Average Loss: 4.339, avg. samples / sec: 66506.85
Iteration:   1080, Loss function: 4.227, Average Loss: 4.324, avg. samples / sec: 66371.29
Iteration:   1080, Loss function: 5.049, Average Loss: 4.323, avg. samples / sec: 66277.55
Iteration:   1100, Loss function: 4.571, Average Loss: 4.350, avg. samples / sec: 66073.96
Iteration:   1100, Loss function: 6.363, Average Loss: 4.374, avg. samples / sec: 66036.09
Iteration:   1100, Loss function: 4.888, Average Loss: 4.360, avg. samples / sec: 66064.51
Iteration:   1100, Loss function: 5.669, Average Loss: 4.345, avg. samples / sec: 66063.21
Iteration:   1100, Loss function: 5.140, Average Loss: 4.352, avg. samples / sec: 66030.74
Iteration:   1100, Loss function: 4.470, Average Loss: 4.301, avg. samples / sec: 66035.84
Iteration:   1100, Loss function: 4.495, Average Loss: 4.339, avg. samples / sec: 66188.78
Iteration:   1100, Loss function: 6.366, Average Loss: 4.383, avg. samples / sec: 66169.76
Iteration:   1100, Loss function: 5.351, Average Loss: 4.354, avg. samples / sec: 66105.26
Iteration:   1100, Loss function: 5.092, Average Loss: 4.331, avg. samples / sec: 66029.78
Iteration:   1100, Loss function: 5.243, Average Loss: 4.337, avg. samples / sec: 66035.35
Iteration:   1100, Loss function: 4.604, Average Loss: 4.373, avg. samples / sec: 66173.70
Iteration:   1100, Loss function: 4.864, Average Loss: 4.333, avg. samples / sec: 66132.43
Iteration:   1100, Loss function: 3.623, Average Loss: 4.357, avg. samples / sec: 66043.86
Iteration:   1100, Loss function: 4.288, Average Loss: 4.343, avg. samples / sec: 66157.39
Iteration:   1100, Loss function: 4.330, Average Loss: 4.348, avg. samples / sec: 66177.77
Iteration:   1100, Loss function: 4.988, Average Loss: 4.357, avg. samples / sec: 65952.71
Iteration:   1100, Loss function: 5.440, Average Loss: 4.332, avg. samples / sec: 66221.12
Iteration:   1100, Loss function: 5.296, Average Loss: 4.373, avg. samples / sec: 66129.52
Iteration:   1100, Loss function: 4.661, Average Loss: 4.336, avg. samples / sec: 66082.85
Iteration:   1100, Loss function: 4.177, Average Loss: 4.348, avg. samples / sec: 66018.24
Iteration:   1100, Loss function: 4.170, Average Loss: 4.340, avg. samples / sec: 65985.63
Iteration:   1100, Loss function: 4.576, Average Loss: 4.335, avg. samples / sec: 66025.02
Iteration:   1100, Loss function: 4.954, Average Loss: 4.368, avg. samples / sec: 65884.05
Iteration:   1100, Loss function: 5.270, Average Loss: 4.361, avg. samples / sec: 65917.58
Iteration:   1100, Loss function: 4.575, Average Loss: 4.356, avg. samples / sec: 66133.30
Iteration:   1100, Loss function: 4.228, Average Loss: 4.356, avg. samples / sec: 66019.48
Iteration:   1100, Loss function: 4.374, Average Loss: 4.373, avg. samples / sec: 66082.35
Iteration:   1100, Loss function: 4.362, Average Loss: 4.340, avg. samples / sec: 66119.12
Iteration:   1100, Loss function: 4.777, Average Loss: 4.367, avg. samples / sec: 65057.45
:::MLL 1558651719.377 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558651719.377 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 3.838, Average Loss: 4.346, avg. samples / sec: 65552.13
Iteration:   1120, Loss function: 5.127, Average Loss: 4.346, avg. samples / sec: 65414.56
Iteration:   1120, Loss function: 4.929, Average Loss: 4.385, avg. samples / sec: 65407.58
Iteration:   1120, Loss function: 5.850, Average Loss: 4.346, avg. samples / sec: 65481.10
Iteration:   1120, Loss function: 3.984, Average Loss: 4.364, avg. samples / sec: 65384.79
Iteration:   1120, Loss function: 4.261, Average Loss: 4.312, avg. samples / sec: 65353.05
Iteration:   1120, Loss function: 3.471, Average Loss: 4.370, avg. samples / sec: 65298.33
Iteration:   1120, Loss function: 3.953, Average Loss: 4.354, avg. samples / sec: 65405.61
Iteration:   1120, Loss function: 5.353, Average Loss: 4.368, avg. samples / sec: 65407.43
Iteration:   1120, Loss function: 5.772, Average Loss: 4.349, avg. samples / sec: 65302.84
Iteration:   1120, Loss function: 3.763, Average Loss: 4.355, avg. samples / sec: 65435.98
Iteration:   1120, Loss function: 3.950, Average Loss: 4.345, avg. samples / sec: 65356.44
Iteration:   1120, Loss function: 3.940, Average Loss: 4.377, avg. samples / sec: 65245.30
Iteration:   1120, Loss function: 5.476, Average Loss: 4.360, avg. samples / sec: 65227.61
Iteration:   1120, Loss function: 5.400, Average Loss: 4.356, avg. samples / sec: 65376.39
Iteration:   1120, Loss function: 4.644, Average Loss: 4.361, avg. samples / sec: 65273.62
Iteration:   1120, Loss function: 5.075, Average Loss: 4.350, avg. samples / sec: 65545.21
Iteration:   1120, Loss function: 6.031, Average Loss: 4.357, avg. samples / sec: 65250.65
Iteration:   1120, Loss function: 5.256, Average Loss: 4.367, avg. samples / sec: 65405.64
Iteration:   1120, Loss function: 5.356, Average Loss: 4.365, avg. samples / sec: 65336.23
Iteration:   1120, Loss function: 4.648, Average Loss: 4.347, avg. samples / sec: 65336.71
Iteration:   1120, Loss function: 4.906, Average Loss: 4.365, avg. samples / sec: 65427.47
Iteration:   1120, Loss function: 5.066, Average Loss: 4.379, avg. samples / sec: 66413.76
Iteration:   1120, Loss function: 5.039, Average Loss: 4.382, avg. samples / sec: 65340.29
Iteration:   1120, Loss function: 4.333, Average Loss: 4.380, avg. samples / sec: 65401.24
Iteration:   1120, Loss function: 5.004, Average Loss: 4.366, avg. samples / sec: 65354.29
Iteration:   1120, Loss function: 3.403, Average Loss: 4.395, avg. samples / sec: 65199.48
Iteration:   1120, Loss function: 3.024, Average Loss: 4.343, avg. samples / sec: 65290.58
Iteration:   1120, Loss function: 4.204, Average Loss: 4.379, avg. samples / sec: 65314.61
Iteration:   1120, Loss function: 4.720, Average Loss: 4.353, avg. samples / sec: 65217.31
Iteration:   1140, Loss function: 5.487, Average Loss: 4.355, avg. samples / sec: 66325.84
Iteration:   1140, Loss function: 4.615, Average Loss: 4.364, avg. samples / sec: 66299.57
Iteration:   1140, Loss function: 6.001, Average Loss: 4.317, avg. samples / sec: 66281.95
Iteration:   1140, Loss function: 5.071, Average Loss: 4.383, avg. samples / sec: 66298.26
Iteration:   1140, Loss function: 4.329, Average Loss: 4.357, avg. samples / sec: 66303.68
Iteration:   1140, Loss function: 5.731, Average Loss: 4.379, avg. samples / sec: 66414.61
Iteration:   1140, Loss function: 5.647, Average Loss: 4.379, avg. samples / sec: 66257.86
Iteration:   1140, Loss function: 5.053, Average Loss: 4.366, avg. samples / sec: 66278.89
Iteration:   1140, Loss function: 4.980, Average Loss: 4.358, avg. samples / sec: 66307.93
Iteration:   1140, Loss function: 4.373, Average Loss: 4.389, avg. samples / sec: 66397.24
Iteration:   1140, Loss function: 5.740, Average Loss: 4.390, avg. samples / sec: 66292.55
Iteration:   1140, Loss function: 5.231, Average Loss: 4.357, avg. samples / sec: 66240.89
Iteration:   1140, Loss function: 4.408, Average Loss: 4.363, avg. samples / sec: 66222.90
Iteration:   1140, Loss function: 4.225, Average Loss: 4.388, avg. samples / sec: 66297.70
Iteration:   1140, Loss function: 6.106, Average Loss: 4.393, avg. samples / sec: 66286.28
Iteration:   1140, Loss function: 5.302, Average Loss: 4.377, avg. samples / sec: 66169.17
Iteration:   1140, Loss function: 5.666, Average Loss: 4.355, avg. samples / sec: 66051.26
Iteration:   1140, Loss function: 6.648, Average Loss: 4.376, avg. samples / sec: 66149.20
Iteration:   1140, Loss function: 6.072, Average Loss: 4.394, avg. samples / sec: 66128.96
Iteration:   1140, Loss function: 6.131, Average Loss: 4.368, avg. samples / sec: 66411.45
Iteration:   1140, Loss function: 4.649, Average Loss: 4.371, avg. samples / sec: 66210.76
Iteration:   1140, Loss function: 4.667, Average Loss: 4.373, avg. samples / sec: 66214.87
Iteration:   1140, Loss function: 4.458, Average Loss: 4.366, avg. samples / sec: 66148.36
Iteration:   1140, Loss function: 4.181, Average Loss: 4.404, avg. samples / sec: 66310.08
Iteration:   1140, Loss function: 5.098, Average Loss: 4.347, avg. samples / sec: 66318.72
Iteration:   1140, Loss function: 4.562, Average Loss: 4.375, avg. samples / sec: 66217.42
Iteration:   1140, Loss function: 4.836, Average Loss: 4.363, avg. samples / sec: 66196.15
Iteration:   1140, Loss function: 4.683, Average Loss: 4.355, avg. samples / sec: 66063.36
Iteration:   1140, Loss function: 5.362, Average Loss: 4.379, avg. samples / sec: 66185.61
Iteration:   1140, Loss function: 4.960, Average Loss: 4.358, avg. samples / sec: 66106.28
Iteration:   1160, Loss function: 4.387, Average Loss: 4.389, avg. samples / sec: 64800.96
Iteration:   1160, Loss function: 4.571, Average Loss: 4.390, avg. samples / sec: 64835.31
Iteration:   1160, Loss function: 4.526, Average Loss: 4.374, avg. samples / sec: 64721.65
Iteration:   1160, Loss function: 5.089, Average Loss: 4.369, avg. samples / sec: 64757.96
Iteration:   1160, Loss function: 5.736, Average Loss: 4.382, avg. samples / sec: 64819.47
Iteration:   1160, Loss function: 3.916, Average Loss: 4.332, avg. samples / sec: 64701.98
Iteration:   1160, Loss function: 5.113, Average Loss: 4.411, avg. samples / sec: 64804.57
Iteration:   1160, Loss function: 4.163, Average Loss: 4.372, avg. samples / sec: 64724.21
Iteration:   1160, Loss function: 5.209, Average Loss: 4.391, avg. samples / sec: 64717.10
Iteration:   1160, Loss function: 5.125, Average Loss: 4.369, avg. samples / sec: 64684.55
Iteration:   1160, Loss function: 5.252, Average Loss: 4.368, avg. samples / sec: 64607.42
Iteration:   1160, Loss function: 4.663, Average Loss: 4.384, avg. samples / sec: 64792.11
Iteration:   1160, Loss function: 5.486, Average Loss: 4.369, avg. samples / sec: 64869.69
Iteration:   1160, Loss function: 5.054, Average Loss: 4.380, avg. samples / sec: 64774.34
Iteration:   1160, Loss function: 4.464, Average Loss: 4.359, avg. samples / sec: 64793.51
Iteration:   1160, Loss function: 5.382, Average Loss: 4.376, avg. samples / sec: 64705.66
Iteration:   1160, Loss function: 5.320, Average Loss: 4.383, avg. samples / sec: 64752.94
Iteration:   1160, Loss function: 4.239, Average Loss: 4.400, avg. samples / sec: 64719.10
Iteration:   1160, Loss function: 5.376, Average Loss: 4.370, avg. samples / sec: 64685.02
Iteration:   1160, Loss function: 3.817, Average Loss: 4.374, avg. samples / sec: 64709.50
Iteration:   1160, Loss function: 5.153, Average Loss: 4.363, avg. samples / sec: 64713.36
Iteration:   1160, Loss function: 6.324, Average Loss: 4.399, avg. samples / sec: 64652.94
Iteration:   1160, Loss function: 5.525, Average Loss: 4.403, avg. samples / sec: 64694.47
Iteration:   1160, Loss function: 5.002, Average Loss: 4.375, avg. samples / sec: 64704.39
Iteration:   1160, Loss function: 6.441, Average Loss: 4.403, avg. samples / sec: 64649.65
Iteration:   1160, Loss function: 4.247, Average Loss: 4.363, avg. samples / sec: 64715.68
Iteration:   1160, Loss function: 5.585, Average Loss: 4.392, avg. samples / sec: 64716.42
Iteration:   1160, Loss function: 4.155, Average Loss: 4.390, avg. samples / sec: 64527.31
Iteration:   1160, Loss function: 5.123, Average Loss: 4.395, avg. samples / sec: 64566.10
Iteration:   1160, Loss function: 4.907, Average Loss: 4.381, avg. samples / sec: 64607.27
Iteration:   1180, Loss function: 5.783, Average Loss: 4.408, avg. samples / sec: 66385.51
Iteration:   1180, Loss function: 5.083, Average Loss: 4.384, avg. samples / sec: 66407.26
Iteration:   1180, Loss function: 4.360, Average Loss: 4.409, avg. samples / sec: 66530.24
Iteration:   1180, Loss function: 5.122, Average Loss: 4.374, avg. samples / sec: 66470.40
Iteration:   1180, Loss function: 5.329, Average Loss: 4.391, avg. samples / sec: 66374.73
Iteration:   1180, Loss function: 5.088, Average Loss: 4.392, avg. samples / sec: 66575.25
Iteration:   1180, Loss function: 5.463, Average Loss: 4.382, avg. samples / sec: 66358.29
Iteration:   1180, Loss function: 4.734, Average Loss: 4.346, avg. samples / sec: 66340.33
Iteration:   1180, Loss function: 5.460, Average Loss: 4.380, avg. samples / sec: 66341.26
Iteration:   1180, Loss function: 4.720, Average Loss: 4.419, avg. samples / sec: 66460.93
Iteration:   1180, Loss function: 3.731, Average Loss: 4.377, avg. samples / sec: 66367.19
Iteration:   1180, Loss function: 5.208, Average Loss: 4.411, avg. samples / sec: 66421.72
Iteration:   1180, Loss function: 4.930, Average Loss: 4.380, avg. samples / sec: 66337.49
Iteration:   1180, Loss function: 4.142, Average Loss: 4.381, avg. samples / sec: 66451.66
Iteration:   1180, Loss function: 3.440, Average Loss: 4.412, avg. samples / sec: 66448.18
Iteration:   1180, Loss function: 5.911, Average Loss: 4.388, avg. samples / sec: 66395.09
Iteration:   1180, Loss function: 4.906, Average Loss: 4.389, avg. samples / sec: 66352.91
Iteration:   1180, Loss function: 5.250, Average Loss: 4.419, avg. samples / sec: 66298.29
Iteration:   1180, Loss function: 4.592, Average Loss: 4.401, avg. samples / sec: 66423.59
Iteration:   1180, Loss function: 5.412, Average Loss: 4.403, avg. samples / sec: 66268.98
Iteration:   1180, Loss function: 3.938, Average Loss: 4.386, avg. samples / sec: 66309.89
Iteration:   1180, Loss function: 4.257, Average Loss: 4.373, avg. samples / sec: 66301.44
Iteration:   1180, Loss function: 4.641, Average Loss: 4.374, avg. samples / sec: 66389.58
Iteration:   1180, Loss function: 4.477, Average Loss: 4.397, avg. samples / sec: 66407.41
Iteration:   1180, Loss function: 4.232, Average Loss: 4.394, avg. samples / sec: 66209.30
Iteration:   1180, Loss function: 5.070, Average Loss: 4.378, avg. samples / sec: 66177.40
Iteration:   1180, Loss function: 7.014, Average Loss: 4.381, avg. samples / sec: 66291.65
Iteration:   1180, Loss function: 5.433, Average Loss: 4.399, avg. samples / sec: 66391.83
Iteration:   1180, Loss function: 4.248, Average Loss: 4.389, avg. samples / sec: 66295.04
Iteration:   1180, Loss function: 4.797, Average Loss: 4.399, avg. samples / sec: 66041.26
:::MLL 1558651721.165 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558651721.165 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 4.679, Average Loss: 4.415, avg. samples / sec: 65744.11
Iteration:   1200, Loss function: 5.791, Average Loss: 4.413, avg. samples / sec: 65851.75
Iteration:   1200, Loss function: 5.700, Average Loss: 4.360, avg. samples / sec: 65716.37
Iteration:   1200, Loss function: 5.159, Average Loss: 4.383, avg. samples / sec: 65696.27
Iteration:   1200, Loss function: 5.256, Average Loss: 4.395, avg. samples / sec: 65614.72
Iteration:   1200, Loss function: 5.283, Average Loss: 4.419, avg. samples / sec: 65693.97
Iteration:   1200, Loss function: 5.029, Average Loss: 4.428, avg. samples / sec: 65730.13
Iteration:   1200, Loss function: 4.746, Average Loss: 4.390, avg. samples / sec: 65802.40
Iteration:   1200, Loss function: 5.406, Average Loss: 4.386, avg. samples / sec: 65677.81
Iteration:   1200, Loss function: 4.348, Average Loss: 4.389, avg. samples / sec: 65657.52
Iteration:   1200, Loss function: 5.511, Average Loss: 4.397, avg. samples / sec: 65676.43
Iteration:   1200, Loss function: 4.823, Average Loss: 4.390, avg. samples / sec: 65784.31
Iteration:   1200, Loss function: 4.086, Average Loss: 4.407, avg. samples / sec: 65703.77
Iteration:   1200, Loss function: 4.043, Average Loss: 4.392, avg. samples / sec: 65694.58
Iteration:   1200, Loss function: 4.706, Average Loss: 4.391, avg. samples / sec: 65616.40
Iteration:   1200, Loss function: 4.840, Average Loss: 4.390, avg. samples / sec: 65652.50
Iteration:   1200, Loss function: 4.977, Average Loss: 4.401, avg. samples / sec: 65761.81
Iteration:   1200, Loss function: 4.388, Average Loss: 4.406, avg. samples / sec: 65708.06
Iteration:   1200, Loss function: 4.412, Average Loss: 4.403, avg. samples / sec: 65706.04
Iteration:   1200, Loss function: 4.854, Average Loss: 4.410, avg. samples / sec: 65545.91
Iteration:   1200, Loss function: 4.285, Average Loss: 4.416, avg. samples / sec: 65623.61
Iteration:   1200, Loss function: 4.991, Average Loss: 4.381, avg. samples / sec: 65542.19
Iteration:   1200, Loss function: 4.829, Average Loss: 4.378, avg. samples / sec: 65633.18
Iteration:   1200, Loss function: 3.741, Average Loss: 4.402, avg. samples / sec: 65712.81
Iteration:   1200, Loss function: 5.150, Average Loss: 4.399, avg. samples / sec: 65546.70
Iteration:   1200, Loss function: 3.760, Average Loss: 4.410, avg. samples / sec: 65758.56
Iteration:   1200, Loss function: 4.831, Average Loss: 4.379, avg. samples / sec: 65610.90
Iteration:   1200, Loss function: 4.349, Average Loss: 4.396, avg. samples / sec: 65589.19
Iteration:   1200, Loss function: 4.972, Average Loss: 4.398, avg. samples / sec: 65467.96
Iteration:   1200, Loss function: 5.114, Average Loss: 4.430, avg. samples / sec: 65483.38
Iteration:   1220, Loss function: 6.186, Average Loss: 4.424, avg. samples / sec: 66398.34
Iteration:   1220, Loss function: 6.090, Average Loss: 4.399, avg. samples / sec: 66488.28
Iteration:   1220, Loss function: 4.722, Average Loss: 4.392, avg. samples / sec: 66515.29
Iteration:   1220, Loss function: 3.106, Average Loss: 4.365, avg. samples / sec: 66429.92
Iteration:   1220, Loss function: 3.919, Average Loss: 4.384, avg. samples / sec: 66405.66
Iteration:   1220, Loss function: 4.076, Average Loss: 4.417, avg. samples / sec: 66541.17
Iteration:   1220, Loss function: 5.357, Average Loss: 4.411, avg. samples / sec: 66487.59
Iteration:   1220, Loss function: 3.652, Average Loss: 4.405, avg. samples / sec: 66466.07
Iteration:   1220, Loss function: 4.269, Average Loss: 4.404, avg. samples / sec: 66452.06
Iteration:   1220, Loss function: 4.085, Average Loss: 4.387, avg. samples / sec: 66565.97
Iteration:   1220, Loss function: 5.598, Average Loss: 4.424, avg. samples / sec: 66482.54
Iteration:   1220, Loss function: 3.547, Average Loss: 4.439, avg. samples / sec: 66586.51
Iteration:   1220, Loss function: 5.158, Average Loss: 4.402, avg. samples / sec: 66433.90
Iteration:   1220, Loss function: 4.546, Average Loss: 4.420, avg. samples / sec: 66420.06
Iteration:   1220, Loss function: 4.625, Average Loss: 4.407, avg. samples / sec: 66577.13
Iteration:   1220, Loss function: 5.775, Average Loss: 4.405, avg. samples / sec: 66478.80
Iteration:   1220, Loss function: 5.154, Average Loss: 4.396, avg. samples / sec: 66409.48
Iteration:   1220, Loss function: 5.865, Average Loss: 4.398, avg. samples / sec: 66374.45
Iteration:   1220, Loss function: 4.305, Average Loss: 4.429, avg. samples / sec: 66342.76
Iteration:   1220, Loss function: 5.915, Average Loss: 4.403, avg. samples / sec: 66400.72
Iteration:   1220, Loss function: 4.604, Average Loss: 4.411, avg. samples / sec: 66433.83
Iteration:   1220, Loss function: 4.715, Average Loss: 4.406, avg. samples / sec: 66411.67
Iteration:   1220, Loss function: 5.799, Average Loss: 4.433, avg. samples / sec: 66294.14
Iteration:   1220, Loss function: 5.258, Average Loss: 4.385, avg. samples / sec: 66435.71
Iteration:   1220, Loss function: 4.634, Average Loss: 4.422, avg. samples / sec: 66146.06
Iteration:   1220, Loss function: 5.732, Average Loss: 4.417, avg. samples / sec: 66373.82
Iteration:   1220, Loss function: 5.330, Average Loss: 4.393, avg. samples / sec: 66387.83
Iteration:   1220, Loss function: 5.492, Average Loss: 4.405, avg. samples / sec: 66435.24
Iteration:   1220, Loss function: 4.731, Average Loss: 4.393, avg. samples / sec: 66287.84
Iteration:   1220, Loss function: 4.544, Average Loss: 4.400, avg. samples / sec: 66303.31
Iteration:   1240, Loss function: 4.152, Average Loss: 4.431, avg. samples / sec: 65343.50
Iteration:   1240, Loss function: 3.928, Average Loss: 4.406, avg. samples / sec: 65134.24
Iteration:   1240, Loss function: 4.625, Average Loss: 4.399, avg. samples / sec: 65112.09
Iteration:   1240, Loss function: 4.976, Average Loss: 4.407, avg. samples / sec: 65240.50
Iteration:   1240, Loss function: 4.805, Average Loss: 4.407, avg. samples / sec: 65303.02
Iteration:   1240, Loss function: 4.273, Average Loss: 4.411, avg. samples / sec: 65199.87
Iteration:   1240, Loss function: 5.622, Average Loss: 4.442, avg. samples / sec: 65211.13
Iteration:   1240, Loss function: 4.821, Average Loss: 4.412, avg. samples / sec: 65233.01
Iteration:   1240, Loss function: 4.571, Average Loss: 4.364, avg. samples / sec: 65079.65
Iteration:   1240, Loss function: 5.099, Average Loss: 4.393, avg. samples / sec: 65126.90
Iteration:   1240, Loss function: 3.824, Average Loss: 4.403, avg. samples / sec: 65183.89
Iteration:   1240, Loss function: 5.240, Average Loss: 4.420, avg. samples / sec: 65125.54
Iteration:   1240, Loss function: 4.548, Average Loss: 4.432, avg. samples / sec: 65036.52
Iteration:   1240, Loss function: 5.686, Average Loss: 4.439, avg. samples / sec: 65232.11
Iteration:   1240, Loss function: 5.400, Average Loss: 4.414, avg. samples / sec: 65157.61
Iteration:   1240, Loss function: 4.395, Average Loss: 4.403, avg. samples / sec: 65248.38
Iteration:   1240, Loss function: 4.870, Average Loss: 4.412, avg. samples / sec: 65090.32
Iteration:   1240, Loss function: 5.471, Average Loss: 4.405, avg. samples / sec: 65133.58
Iteration:   1240, Loss function: 5.421, Average Loss: 4.420, avg. samples / sec: 65167.43
Iteration:   1240, Loss function: 4.367, Average Loss: 4.414, avg. samples / sec: 65212.82
Iteration:   1240, Loss function: 5.006, Average Loss: 4.427, avg. samples / sec: 65091.25
Iteration:   1240, Loss function: 4.826, Average Loss: 4.413, avg. samples / sec: 65108.54
Iteration:   1240, Loss function: 4.203, Average Loss: 4.397, avg. samples / sec: 65149.06
Iteration:   1240, Loss function: 5.396, Average Loss: 4.427, avg. samples / sec: 65025.96
Iteration:   1240, Loss function: 4.487, Average Loss: 4.447, avg. samples / sec: 65049.43
Iteration:   1240, Loss function: 6.922, Average Loss: 4.418, avg. samples / sec: 65003.43
Iteration:   1240, Loss function: 5.487, Average Loss: 4.434, avg. samples / sec: 65030.25
Iteration:   1240, Loss function: 4.867, Average Loss: 4.392, avg. samples / sec: 64987.61
Iteration:   1240, Loss function: 5.445, Average Loss: 4.409, avg. samples / sec: 65078.81
Iteration:   1240, Loss function: 5.264, Average Loss: 4.424, avg. samples / sec: 65018.01
:::MLL 1558651722.952 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558651722.952 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 4.622, Average Loss: 4.451, avg. samples / sec: 66235.88
Iteration:   1260, Loss function: 4.826, Average Loss: 4.440, avg. samples / sec: 66091.06
Iteration:   1260, Loss function: 3.790, Average Loss: 4.401, avg. samples / sec: 66183.52
Iteration:   1260, Loss function: 5.536, Average Loss: 4.443, avg. samples / sec: 66160.78
Iteration:   1260, Loss function: 4.605, Average Loss: 4.438, avg. samples / sec: 66241.20
Iteration:   1260, Loss function: 5.030, Average Loss: 4.439, avg. samples / sec: 66152.64
Iteration:   1260, Loss function: 6.569, Average Loss: 4.428, avg. samples / sec: 66136.16
Iteration:   1260, Loss function: 5.580, Average Loss: 4.420, avg. samples / sec: 65967.69
Iteration:   1260, Loss function: 4.889, Average Loss: 4.433, avg. samples / sec: 66066.00
Iteration:   1260, Loss function: 3.560, Average Loss: 4.415, avg. samples / sec: 66048.41
Iteration:   1260, Loss function: 5.313, Average Loss: 4.424, avg. samples / sec: 66213.19
Iteration:   1260, Loss function: 6.648, Average Loss: 4.423, avg. samples / sec: 66026.47
Iteration:   1260, Loss function: 4.874, Average Loss: 4.452, avg. samples / sec: 66153.33
Iteration:   1260, Loss function: 5.028, Average Loss: 4.424, avg. samples / sec: 66114.04
Iteration:   1260, Loss function: 5.749, Average Loss: 4.368, avg. samples / sec: 66031.54
Iteration:   1260, Loss function: 6.107, Average Loss: 4.418, avg. samples / sec: 65982.39
Iteration:   1260, Loss function: 4.943, Average Loss: 4.418, avg. samples / sec: 66250.57
Iteration:   1260, Loss function: 4.776, Average Loss: 4.448, avg. samples / sec: 66012.15
Iteration:   1260, Loss function: 5.207, Average Loss: 4.408, avg. samples / sec: 66079.63
Iteration:   1260, Loss function: 3.724, Average Loss: 4.415, avg. samples / sec: 66055.72
Iteration:   1260, Loss function: 4.152, Average Loss: 4.407, avg. samples / sec: 66084.99
Iteration:   1260, Loss function: 5.492, Average Loss: 4.422, avg. samples / sec: 66054.38
Iteration:   1260, Loss function: 4.597, Average Loss: 4.423, avg. samples / sec: 65968.58
Iteration:   1260, Loss function: 5.076, Average Loss: 4.444, avg. samples / sec: 66155.34
Iteration:   1260, Loss function: 4.100, Average Loss: 4.431, avg. samples / sec: 66049.18
Iteration:   1260, Loss function: 4.689, Average Loss: 4.431, avg. samples / sec: 65988.54
Iteration:   1260, Loss function: 4.549, Average Loss: 4.415, avg. samples / sec: 65896.00
Iteration:   1260, Loss function: 4.636, Average Loss: 4.409, avg. samples / sec: 65834.13
Iteration:   1260, Loss function: 4.642, Average Loss: 4.434, avg. samples / sec: 66055.68
Iteration:   1260, Loss function: 3.952, Average Loss: 4.402, avg. samples / sec: 65970.25
Iteration:   1280, Loss function: 3.527, Average Loss: 4.451, avg. samples / sec: 65868.53
Iteration:   1280, Loss function: 5.521, Average Loss: 4.451, avg. samples / sec: 65854.95
Iteration:   1280, Loss function: 4.382, Average Loss: 4.417, avg. samples / sec: 65952.90
Iteration:   1280, Loss function: 4.646, Average Loss: 4.376, avg. samples / sec: 65932.44
Iteration:   1280, Loss function: 5.129, Average Loss: 4.430, avg. samples / sec: 65900.38
Iteration:   1280, Loss function: 4.955, Average Loss: 4.436, avg. samples / sec: 65909.93
Iteration:   1280, Loss function: 4.328, Average Loss: 4.430, avg. samples / sec: 65905.25
Iteration:   1280, Loss function: 4.216, Average Loss: 4.429, avg. samples / sec: 65944.20
Iteration:   1280, Loss function: 3.581, Average Loss: 4.433, avg. samples / sec: 65906.05
Iteration:   1280, Loss function: 4.043, Average Loss: 4.457, avg. samples / sec: 65919.95
Iteration:   1280, Loss function: 4.318, Average Loss: 4.449, avg. samples / sec: 65728.23
Iteration:   1280, Loss function: 4.014, Average Loss: 4.417, avg. samples / sec: 66030.86
Iteration:   1280, Loss function: 5.111, Average Loss: 4.422, avg. samples / sec: 65874.66
Iteration:   1280, Loss function: 4.771, Average Loss: 4.425, avg. samples / sec: 65901.05
Iteration:   1280, Loss function: 5.463, Average Loss: 4.460, avg. samples / sec: 65895.82
Iteration:   1280, Loss function: 5.038, Average Loss: 4.430, avg. samples / sec: 65898.10
Iteration:   1280, Loss function: 4.034, Average Loss: 4.427, avg. samples / sec: 65900.41
Iteration:   1280, Loss function: 4.696, Average Loss: 4.422, avg. samples / sec: 65966.91
Iteration:   1280, Loss function: 4.079, Average Loss: 4.466, avg. samples / sec: 65861.76
Iteration:   1280, Loss function: 5.965, Average Loss: 4.430, avg. samples / sec: 65860.25
Iteration:   1280, Loss function: 4.091, Average Loss: 4.454, avg. samples / sec: 65670.37
Iteration:   1280, Loss function: 6.651, Average Loss: 4.408, avg. samples / sec: 65657.80
Iteration:   1280, Loss function: 5.284, Average Loss: 4.445, avg. samples / sec: 66017.16
Iteration:   1280, Loss function: 4.701, Average Loss: 4.439, avg. samples / sec: 65829.30
Iteration:   1280, Loss function: 3.735, Average Loss: 4.410, avg. samples / sec: 66030.65
Iteration:   1280, Loss function: 4.949, Average Loss: 4.449, avg. samples / sec: 65759.30
Iteration:   1280, Loss function: 5.007, Average Loss: 4.446, avg. samples / sec: 65715.60
Iteration:   1280, Loss function: 5.004, Average Loss: 4.429, avg. samples / sec: 65783.91
Iteration:   1280, Loss function: 4.540, Average Loss: 4.436, avg. samples / sec: 65707.85
Iteration:   1280, Loss function: 4.450, Average Loss: 4.439, avg. samples / sec: 65753.19
Iteration:   1300, Loss function: 4.276, Average Loss: 4.455, avg. samples / sec: 66317.23
Iteration:   1300, Loss function: 3.254, Average Loss: 4.455, avg. samples / sec: 66343.04
Iteration:   1300, Loss function: 4.573, Average Loss: 4.434, avg. samples / sec: 66262.50
Iteration:   1300, Loss function: 5.701, Average Loss: 4.429, avg. samples / sec: 66271.23
Iteration:   1300, Loss function: 5.042, Average Loss: 4.433, avg. samples / sec: 66287.53
Iteration:   1300, Loss function: 4.428, Average Loss: 4.446, avg. samples / sec: 66484.82
Iteration:   1300, Loss function: 4.092, Average Loss: 4.435, avg. samples / sec: 66354.35
Iteration:   1300, Loss function: 4.198, Average Loss: 4.443, avg. samples / sec: 66375.51
Iteration:   1300, Loss function: 4.073, Average Loss: 4.436, avg. samples / sec: 66190.02
Iteration:   1300, Loss function: 4.384, Average Loss: 4.435, avg. samples / sec: 66200.50
Iteration:   1300, Loss function: 3.683, Average Loss: 4.412, avg. samples / sec: 66300.50
Iteration:   1300, Loss function: 5.109, Average Loss: 4.422, avg. samples / sec: 66212.63
Iteration:   1300, Loss function: 4.759, Average Loss: 4.465, avg. samples / sec: 66213.97
Iteration:   1300, Loss function: 4.614, Average Loss: 4.471, avg. samples / sec: 66225.14
Iteration:   1300, Loss function: 5.220, Average Loss: 4.455, avg. samples / sec: 66123.78
Iteration:   1300, Loss function: 4.927, Average Loss: 4.382, avg. samples / sec: 66142.86
Iteration:   1300, Loss function: 4.037, Average Loss: 4.420, avg. samples / sec: 66144.66
Iteration:   1300, Loss function: 5.054, Average Loss: 4.438, avg. samples / sec: 66171.22
Iteration:   1300, Loss function: 5.255, Average Loss: 4.461, avg. samples / sec: 66075.69
Iteration:   1300, Loss function: 5.136, Average Loss: 4.438, avg. samples / sec: 66193.47
Iteration:   1300, Loss function: 4.966, Average Loss: 4.449, avg. samples / sec: 66276.09
Iteration:   1300, Loss function: 5.345, Average Loss: 4.428, avg. samples / sec: 66172.90
Iteration:   1300, Loss function: 3.810, Average Loss: 4.451, avg. samples / sec: 66252.44
Iteration:   1300, Loss function: 4.758, Average Loss: 4.449, avg. samples / sec: 66246.74
Iteration:   1300, Loss function: 3.483, Average Loss: 4.435, avg. samples / sec: 66108.11
Iteration:   1300, Loss function: 4.052, Average Loss: 4.432, avg. samples / sec: 66085.27
Iteration:   1300, Loss function: 5.898, Average Loss: 4.445, avg. samples / sec: 66047.76
Iteration:   1300, Loss function: 5.089, Average Loss: 4.416, avg. samples / sec: 66160.31
Iteration:   1300, Loss function: 4.227, Average Loss: 4.453, avg. samples / sec: 66141.22
Iteration:   1300, Loss function: 5.162, Average Loss: 4.459, avg. samples / sec: 66020.16
Iteration:   1320, Loss function: 5.312, Average Loss: 4.445, avg. samples / sec: 65922.69
Iteration:   1320, Loss function: 4.727, Average Loss: 4.455, avg. samples / sec: 65992.15
Iteration:   1320, Loss function: 3.896, Average Loss: 4.447, avg. samples / sec: 66021.24
Iteration:   1320, Loss function: 4.664, Average Loss: 4.420, avg. samples / sec: 65922.73
Iteration:   1320, Loss function: 5.256, Average Loss: 4.391, avg. samples / sec: 65917.02
Iteration:   1320, Loss function: 4.601, Average Loss: 4.458, avg. samples / sec: 65893.07
Iteration:   1320, Loss function: 3.821, Average Loss: 4.449, avg. samples / sec: 66001.39
Iteration:   1320, Loss function: 4.813, Average Loss: 4.436, avg. samples / sec: 65870.22
Iteration:   1320, Loss function: 5.247, Average Loss: 4.424, avg. samples / sec: 65873.42
Iteration:   1320, Loss function: 5.895, Average Loss: 4.474, avg. samples / sec: 65890.79
Iteration:   1320, Loss function: 5.332, Average Loss: 4.472, avg. samples / sec: 65856.34
Iteration:   1320, Loss function: 3.689, Average Loss: 4.461, avg. samples / sec: 65765.92
Iteration:   1320, Loss function: 4.021, Average Loss: 4.413, avg. samples / sec: 65836.65
Iteration:   1320, Loss function: 5.741, Average Loss: 4.469, avg. samples / sec: 65886.27
Iteration:   1320, Loss function: 4.399, Average Loss: 4.442, avg. samples / sec: 65820.29
Iteration:   1320, Loss function: 4.754, Average Loss: 4.439, avg. samples / sec: 65851.69
Iteration:   1320, Loss function: 5.008, Average Loss: 4.458, avg. samples / sec: 65719.52
Iteration:   1320, Loss function: 4.471, Average Loss: 4.430, avg. samples / sec: 65876.35
Iteration:   1320, Loss function: 5.651, Average Loss: 4.441, avg. samples / sec: 65771.33
Iteration:   1320, Loss function: 5.218, Average Loss: 4.428, avg. samples / sec: 65961.39
Iteration:   1320, Loss function: 4.681, Average Loss: 4.433, avg. samples / sec: 65735.09
Iteration:   1320, Loss function: 4.589, Average Loss: 4.461, avg. samples / sec: 65986.09
Iteration:   1320, Loss function: 4.585, Average Loss: 4.465, avg. samples / sec: 65945.65
Iteration:   1320, Loss function: 4.492, Average Loss: 4.438, avg. samples / sec: 65805.94
Iteration:   1320, Loss function: 6.056, Average Loss: 4.453, avg. samples / sec: 65807.72
Iteration:   1320, Loss function: 3.650, Average Loss: 4.455, avg. samples / sec: 65820.91
Iteration:   1320, Loss function: 4.510, Average Loss: 4.451, avg. samples / sec: 65743.01
Iteration:   1320, Loss function: 4.193, Average Loss: 4.440, avg. samples / sec: 65860.25
Iteration:   1320, Loss function: 4.312, Average Loss: 4.437, avg. samples / sec: 65658.53
Iteration:   1320, Loss function: 4.367, Average Loss: 4.449, avg. samples / sec: 65613.04
:::MLL 1558651724.737 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558651724.738 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 5.063, Average Loss: 4.442, avg. samples / sec: 65867.05
Iteration:   1340, Loss function: 3.670, Average Loss: 4.442, avg. samples / sec: 65749.97
Iteration:   1340, Loss function: 4.288, Average Loss: 4.478, avg. samples / sec: 65725.47
Iteration:   1340, Loss function: 3.735, Average Loss: 4.462, avg. samples / sec: 65736.38
Iteration:   1340, Loss function: 4.615, Average Loss: 4.393, avg. samples / sec: 65617.59
Iteration:   1340, Loss function: 4.825, Average Loss: 4.428, avg. samples / sec: 65647.37
Iteration:   1340, Loss function: 4.612, Average Loss: 4.453, avg. samples / sec: 65616.37
Iteration:   1340, Loss function: 3.837, Average Loss: 4.451, avg. samples / sec: 65556.76
Iteration:   1340, Loss function: 4.928, Average Loss: 4.438, avg. samples / sec: 65711.59
Iteration:   1340, Loss function: 4.911, Average Loss: 4.449, avg. samples / sec: 65670.98
Iteration:   1340, Loss function: 4.609, Average Loss: 4.473, avg. samples / sec: 65649.32
Iteration:   1340, Loss function: 4.761, Average Loss: 4.441, avg. samples / sec: 65597.44
Iteration:   1340, Loss function: 5.537, Average Loss: 4.453, avg. samples / sec: 65601.19
Iteration:   1340, Loss function: 6.068, Average Loss: 4.474, avg. samples / sec: 65611.36
Iteration:   1340, Loss function: 3.928, Average Loss: 4.463, avg. samples / sec: 65662.41
Iteration:   1340, Loss function: 4.703, Average Loss: 4.463, avg. samples / sec: 65540.48
Iteration:   1340, Loss function: 4.252, Average Loss: 4.413, avg. samples / sec: 65603.67
Iteration:   1340, Loss function: 4.627, Average Loss: 4.422, avg. samples / sec: 65541.06
Iteration:   1340, Loss function: 4.340, Average Loss: 4.430, avg. samples / sec: 65591.82
Iteration:   1340, Loss function: 4.280, Average Loss: 4.457, avg. samples / sec: 65670.09
Iteration:   1340, Loss function: 5.156, Average Loss: 4.444, avg. samples / sec: 65678.17
Iteration:   1340, Loss function: 3.987, Average Loss: 4.444, avg. samples / sec: 65586.78
Iteration:   1340, Loss function: 4.919, Average Loss: 4.465, avg. samples / sec: 65533.38
Iteration:   1340, Loss function: 5.319, Average Loss: 4.467, avg. samples / sec: 65600.40
Iteration:   1340, Loss function: 4.173, Average Loss: 4.452, avg. samples / sec: 65623.98
Iteration:   1340, Loss function: 4.155, Average Loss: 4.431, avg. samples / sec: 65555.33
Iteration:   1340, Loss function: 3.200, Average Loss: 4.462, avg. samples / sec: 65501.73
Iteration:   1340, Loss function: 5.887, Average Loss: 4.456, avg. samples / sec: 65701.32
Iteration:   1340, Loss function: 3.323, Average Loss: 4.453, avg. samples / sec: 65605.01
Iteration:   1340, Loss function: 4.252, Average Loss: 4.442, avg. samples / sec: 65597.19
Iteration:   1360, Loss function: 4.562, Average Loss: 4.436, avg. samples / sec: 66457.20
Iteration:   1360, Loss function: 4.594, Average Loss: 4.454, avg. samples / sec: 66312.17
Iteration:   1360, Loss function: 5.311, Average Loss: 4.463, avg. samples / sec: 66234.38
Iteration:   1360, Loss function: 3.616, Average Loss: 4.429, avg. samples / sec: 66241.26
Iteration:   1360, Loss function: 4.430, Average Loss: 4.413, avg. samples / sec: 66323.84
Iteration:   1360, Loss function: 4.689, Average Loss: 4.446, avg. samples / sec: 66150.56
Iteration:   1360, Loss function: 4.046, Average Loss: 4.455, avg. samples / sec: 66222.21
Iteration:   1360, Loss function: 4.015, Average Loss: 4.478, avg. samples / sec: 66150.56
Iteration:   1360, Loss function: 4.432, Average Loss: 4.476, avg. samples / sec: 66243.07
Iteration:   1360, Loss function: 5.857, Average Loss: 4.440, avg. samples / sec: 66237.00
Iteration:   1360, Loss function: 4.420, Average Loss: 4.446, avg. samples / sec: 66249.89
Iteration:   1360, Loss function: 4.617, Average Loss: 4.448, avg. samples / sec: 66305.06
Iteration:   1360, Loss function: 4.032, Average Loss: 4.475, avg. samples / sec: 66234.07
Iteration:   1360, Loss function: 4.185, Average Loss: 4.470, avg. samples / sec: 66240.20
Iteration:   1360, Loss function: 4.464, Average Loss: 4.446, avg. samples / sec: 66058.47
Iteration:   1360, Loss function: 4.216, Average Loss: 4.445, avg. samples / sec: 66316.66
Iteration:   1360, Loss function: 3.937, Average Loss: 4.446, avg. samples / sec: 66359.48
Iteration:   1360, Loss function: 4.306, Average Loss: 4.426, avg. samples / sec: 66236.12
Iteration:   1360, Loss function: 4.993, Average Loss: 4.463, avg. samples / sec: 66295.89
Iteration:   1360, Loss function: 3.696, Average Loss: 4.466, avg. samples / sec: 66202.05
Iteration:   1360, Loss function: 4.392, Average Loss: 4.400, avg. samples / sec: 66127.25
Iteration:   1360, Loss function: 5.031, Average Loss: 4.456, avg. samples / sec: 66283.82
Iteration:   1360, Loss function: 4.666, Average Loss: 4.469, avg. samples / sec: 66222.62
Iteration:   1360, Loss function: 4.590, Average Loss: 4.448, avg. samples / sec: 66225.11
Iteration:   1360, Loss function: 3.862, Average Loss: 4.456, avg. samples / sec: 66068.13
Iteration:   1360, Loss function: 3.346, Average Loss: 4.470, avg. samples / sec: 66205.35
Iteration:   1360, Loss function: 4.151, Average Loss: 4.460, avg. samples / sec: 66105.29
Iteration:   1360, Loss function: 5.506, Average Loss: 4.467, avg. samples / sec: 66130.42
Iteration:   1360, Loss function: 4.091, Average Loss: 4.463, avg. samples / sec: 66172.96
Iteration:   1360, Loss function: 4.352, Average Loss: 4.459, avg. samples / sec: 66091.90
Iteration:   1380, Loss function: 4.601, Average Loss: 4.449, avg. samples / sec: 66165.94
Iteration:   1380, Loss function: 4.325, Average Loss: 4.418, avg. samples / sec: 66130.51
Iteration:   1380, Loss function: 4.093, Average Loss: 4.461, avg. samples / sec: 66304.43
Iteration:   1380, Loss function: 5.254, Average Loss: 4.472, avg. samples / sec: 66227.81
Iteration:   1380, Loss function: 5.021, Average Loss: 4.470, avg. samples / sec: 66075.17
Iteration:   1380, Loss function: 4.744, Average Loss: 4.432, avg. samples / sec: 66101.97
Iteration:   1380, Loss function: 3.850, Average Loss: 4.479, avg. samples / sec: 66137.37
Iteration:   1380, Loss function: 3.170, Average Loss: 4.445, avg. samples / sec: 66120.92
Iteration:   1380, Loss function: 4.956, Average Loss: 4.460, avg. samples / sec: 66114.25
Iteration:   1380, Loss function: 4.466, Average Loss: 4.448, avg. samples / sec: 66152.64
Iteration:   1380, Loss function: 4.603, Average Loss: 4.469, avg. samples / sec: 66155.56
Iteration:   1380, Loss function: 3.613, Average Loss: 4.453, avg. samples / sec: 66003.80
Iteration:   1380, Loss function: 5.158, Average Loss: 4.461, avg. samples / sec: 66164.26
Iteration:   1380, Loss function: 5.084, Average Loss: 4.473, avg. samples / sec: 66187.63
Iteration:   1380, Loss function: 3.905, Average Loss: 4.430, avg. samples / sec: 66115.68
Iteration:   1380, Loss function: 4.575, Average Loss: 4.462, avg. samples / sec: 66231.39
Iteration:   1380, Loss function: 5.311, Average Loss: 4.482, avg. samples / sec: 66017.50
Iteration:   1380, Loss function: 5.840, Average Loss: 4.475, avg. samples / sec: 66183.93
Iteration:   1380, Loss function: 4.463, Average Loss: 4.453, avg. samples / sec: 66140.63
Iteration:   1380, Loss function: 5.232, Average Loss: 4.454, avg. samples / sec: 66091.99
Iteration:   1380, Loss function: 4.573, Average Loss: 4.449, avg. samples / sec: 66072.66
Iteration:   1380, Loss function: 4.478, Average Loss: 4.463, avg. samples / sec: 66281.54
Iteration:   1380, Loss function: 4.618, Average Loss: 4.477, avg. samples / sec: 66035.44
Iteration:   1380, Loss function: 5.695, Average Loss: 4.446, avg. samples / sec: 66001.11
Iteration:   1380, Loss function: 4.417, Average Loss: 4.466, avg. samples / sec: 66150.66
Iteration:   1380, Loss function: 4.256, Average Loss: 4.407, avg. samples / sec: 66048.22
Iteration:   1380, Loss function: 4.381, Average Loss: 4.473, avg. samples / sec: 65981.12
Iteration:   1380, Loss function: 4.292, Average Loss: 4.444, avg. samples / sec: 65787.84
Iteration:   1380, Loss function: 4.555, Average Loss: 4.466, avg. samples / sec: 66127.62
Iteration:   1380, Loss function: 5.226, Average Loss: 4.447, avg. samples / sec: 65921.55
:::MLL 1558651726.517 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558651726.517 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 4.155, Average Loss: 4.485, avg. samples / sec: 66109.51
Iteration:   1400, Loss function: 4.219, Average Loss: 4.424, avg. samples / sec: 65935.53
Iteration:   1400, Loss function: 4.736, Average Loss: 4.452, avg. samples / sec: 66153.33
Iteration:   1400, Loss function: 3.652, Average Loss: 4.469, avg. samples / sec: 66056.33
Iteration:   1400, Loss function: 5.527, Average Loss: 4.447, avg. samples / sec: 66086.85
Iteration:   1400, Loss function: 5.199, Average Loss: 4.452, avg. samples / sec: 65901.05
Iteration:   1400, Loss function: 4.482, Average Loss: 4.441, avg. samples / sec: 65907.99
Iteration:   1400, Loss function: 4.696, Average Loss: 4.473, avg. samples / sec: 65872.81
Iteration:   1400, Loss function: 5.112, Average Loss: 4.451, avg. samples / sec: 66138.18
Iteration:   1400, Loss function: 5.344, Average Loss: 4.475, avg. samples / sec: 65889.99
Iteration:   1400, Loss function: 4.321, Average Loss: 4.459, avg. samples / sec: 65919.21
Iteration:   1400, Loss function: 4.323, Average Loss: 4.437, avg. samples / sec: 65946.42
Iteration:   1400, Loss function: 3.965, Average Loss: 4.466, avg. samples / sec: 65971.85
Iteration:   1400, Loss function: 4.044, Average Loss: 4.458, avg. samples / sec: 65970.68
Iteration:   1400, Loss function: 3.419, Average Loss: 4.482, avg. samples / sec: 65865.54
Iteration:   1400, Loss function: 4.673, Average Loss: 4.450, avg. samples / sec: 65847.11
Iteration:   1400, Loss function: 3.969, Average Loss: 4.479, avg. samples / sec: 65913.35
Iteration:   1400, Loss function: 4.266, Average Loss: 4.457, avg. samples / sec: 65920.32
Iteration:   1400, Loss function: 5.199, Average Loss: 4.482, avg. samples / sec: 65802.83
Iteration:   1400, Loss function: 4.958, Average Loss: 4.455, avg. samples / sec: 65896.09
Iteration:   1400, Loss function: 5.311, Average Loss: 4.456, avg. samples / sec: 65916.28
Iteration:   1400, Loss function: 4.581, Average Loss: 4.467, avg. samples / sec: 65875.27
Iteration:   1400, Loss function: 3.655, Average Loss: 4.409, avg. samples / sec: 65957.68
Iteration:   1400, Loss function: 4.509, Average Loss: 4.451, avg. samples / sec: 65755.80
Iteration:   1400, Loss function: 4.594, Average Loss: 4.478, avg. samples / sec: 65783.27
Iteration:   1400, Loss function: 5.663, Average Loss: 4.485, avg. samples / sec: 65854.77
Iteration:   1400, Loss function: 6.151, Average Loss: 4.474, avg. samples / sec: 65861.14
Iteration:   1400, Loss function: 5.586, Average Loss: 4.480, avg. samples / sec: 65788.61
Iteration:   1400, Loss function: 6.523, Average Loss: 4.476, avg. samples / sec: 65881.52
Iteration:   1400, Loss function: 5.017, Average Loss: 4.476, avg. samples / sec: 65840.03
Iteration:   1420, Loss function: 4.259, Average Loss: 4.433, avg. samples / sec: 66082.14
Iteration:   1420, Loss function: 4.657, Average Loss: 4.475, avg. samples / sec: 66139.82
Iteration:   1420, Loss function: 4.476, Average Loss: 4.488, avg. samples / sec: 66273.66
Iteration:   1420, Loss function: 4.387, Average Loss: 4.457, avg. samples / sec: 66108.33
Iteration:   1420, Loss function: 5.079, Average Loss: 4.481, avg. samples / sec: 66087.68
Iteration:   1420, Loss function: 4.723, Average Loss: 4.459, avg. samples / sec: 66080.34
Iteration:   1420, Loss function: 4.624, Average Loss: 4.481, avg. samples / sec: 66068.66
Iteration:   1420, Loss function: 4.588, Average Loss: 4.481, avg. samples / sec: 66271.91
Iteration:   1420, Loss function: 5.291, Average Loss: 4.454, avg. samples / sec: 66013.63
Iteration:   1420, Loss function: 6.295, Average Loss: 4.441, avg. samples / sec: 66048.90
Iteration:   1420, Loss function: 4.613, Average Loss: 4.487, avg. samples / sec: 66067.24
Iteration:   1420, Loss function: 3.414, Average Loss: 4.450, avg. samples / sec: 66002.20
Iteration:   1420, Loss function: 4.262, Average Loss: 4.454, avg. samples / sec: 65986.40
Iteration:   1420, Loss function: 4.861, Average Loss: 4.474, avg. samples / sec: 66214.84
Iteration:   1420, Loss function: 4.225, Average Loss: 4.453, avg. samples / sec: 66083.47
Iteration:   1420, Loss function: 4.403, Average Loss: 4.452, avg. samples / sec: 66071.70
Iteration:   1420, Loss function: 5.488, Average Loss: 4.485, avg. samples / sec: 65896.80
Iteration:   1420, Loss function: 4.408, Average Loss: 4.484, avg. samples / sec: 66204.42
Iteration:   1420, Loss function: 4.263, Average Loss: 4.475, avg. samples / sec: 66092.58
Iteration:   1420, Loss function: 4.946, Average Loss: 4.417, avg. samples / sec: 66087.19
Iteration:   1420, Loss function: 3.764, Average Loss: 4.460, avg. samples / sec: 66057.57
Iteration:   1420, Loss function: 3.414, Average Loss: 4.453, avg. samples / sec: 65943.61
Iteration:   1420, Loss function: 3.194, Average Loss: 4.467, avg. samples / sec: 65960.86
Iteration:   1420, Loss function: 4.656, Average Loss: 4.468, avg. samples / sec: 65876.41
Iteration:   1420, Loss function: 4.130, Average Loss: 4.460, avg. samples / sec: 65966.17
Iteration:   1420, Loss function: 4.865, Average Loss: 4.442, avg. samples / sec: 65914.89
Iteration:   1420, Loss function: 4.062, Average Loss: 4.479, avg. samples / sec: 66043.18
Iteration:   1420, Loss function: 4.119, Average Loss: 4.479, avg. samples / sec: 66121.70
Iteration:   1420, Loss function: 4.465, Average Loss: 4.453, avg. samples / sec: 66001.30
Iteration:   1420, Loss function: 5.133, Average Loss: 4.482, avg. samples / sec: 65896.09
Iteration:   1440, Loss function: 4.168, Average Loss: 4.454, avg. samples / sec: 65736.96
Iteration:   1440, Loss function: 4.360, Average Loss: 4.466, avg. samples / sec: 65686.16
Iteration:   1440, Loss function: 3.289, Average Loss: 4.449, avg. samples / sec: 65695.75
Iteration:   1440, Loss function: 4.947, Average Loss: 4.478, avg. samples / sec: 65732.15
Iteration:   1440, Loss function: 5.539, Average Loss: 4.489, avg. samples / sec: 65672.91
Iteration:   1440, Loss function: 4.232, Average Loss: 4.450, avg. samples / sec: 65691.61
Iteration:   1440, Loss function: 5.778, Average Loss: 4.448, avg. samples / sec: 65646.82
Iteration:   1440, Loss function: 4.874, Average Loss: 4.484, avg. samples / sec: 65620.59
Iteration:   1440, Loss function: 4.477, Average Loss: 4.444, avg. samples / sec: 65801.24
Iteration:   1440, Loss function: 4.716, Average Loss: 4.459, avg. samples / sec: 65621.20
Iteration:   1440, Loss function: 4.788, Average Loss: 4.496, avg. samples / sec: 65594.81
Iteration:   1440, Loss function: 3.842, Average Loss: 4.489, avg. samples / sec: 65661.93
Iteration:   1440, Loss function: 4.036, Average Loss: 4.477, avg. samples / sec: 65629.97
Iteration:   1440, Loss function: 3.602, Average Loss: 4.483, avg. samples / sec: 65591.57
Iteration:   1440, Loss function: 4.297, Average Loss: 4.485, avg. samples / sec: 65653.15
Iteration:   1440, Loss function: 5.415, Average Loss: 4.475, avg. samples / sec: 65726.20
Iteration:   1440, Loss function: 4.587, Average Loss: 4.475, avg. samples / sec: 65536.12
Iteration:   1440, Loss function: 5.274, Average Loss: 4.457, avg. samples / sec: 65590.90
Iteration:   1440, Loss function: 4.083, Average Loss: 4.461, avg. samples / sec: 65529.72
Iteration:   1440, Loss function: 3.615, Average Loss: 4.481, avg. samples / sec: 65540.94
Iteration:   1440, Loss function: 4.358, Average Loss: 4.467, avg. samples / sec: 65657.24
Iteration:   1440, Loss function: 3.863, Average Loss: 4.424, avg. samples / sec: 65610.23
Iteration:   1440, Loss function: 4.652, Average Loss: 4.484, avg. samples / sec: 65682.70
Iteration:   1440, Loss function: 4.309, Average Loss: 4.433, avg. samples / sec: 65429.08
Iteration:   1440, Loss function: 4.046, Average Loss: 4.460, avg. samples / sec: 65688.55
Iteration:   1440, Loss function: 3.974, Average Loss: 4.455, avg. samples / sec: 65710.42
Iteration:   1440, Loss function: 5.116, Average Loss: 4.465, avg. samples / sec: 65560.79
Iteration:   1440, Loss function: 4.466, Average Loss: 4.457, avg. samples / sec: 65533.07
Iteration:   1440, Loss function: 3.494, Average Loss: 4.477, avg. samples / sec: 65649.93
Iteration:   1440, Loss function: 5.613, Average Loss: 4.478, avg. samples / sec: 65557.98
Iteration:   1460, Loss function: 3.598, Average Loss: 4.449, avg. samples / sec: 66251.72
Iteration:   1460, Loss function: 4.385, Average Loss: 4.449, avg. samples / sec: 66215.40
Iteration:   1460, Loss function: 4.386, Average Loss: 4.489, avg. samples / sec: 66205.82
Iteration:   1460, Loss function: 5.638, Average Loss: 4.462, avg. samples / sec: 66263.16
Iteration:   1460, Loss function: 3.713, Average Loss: 4.460, avg. samples / sec: 66189.74
Iteration:   1460, Loss function: 4.739, Average Loss: 4.470, avg. samples / sec: 66127.07
Iteration:   1460, Loss function: 3.768, Average Loss: 4.487, avg. samples / sec: 66263.84
Iteration:   1460, Loss function: 4.381, Average Loss: 4.484, avg. samples / sec: 66292.83
Iteration:   1460, Loss function: 5.232, Average Loss: 4.424, avg. samples / sec: 66268.67
Iteration:   1460, Loss function: 3.816, Average Loss: 4.448, avg. samples / sec: 66144.48
Iteration:   1460, Loss function: 5.108, Average Loss: 4.495, avg. samples / sec: 66149.41
Iteration:   1460, Loss function: 4.235, Average Loss: 4.468, avg. samples / sec: 66248.02
Iteration:   1460, Loss function: 4.541, Average Loss: 4.437, avg. samples / sec: 66258.98
Iteration:   1460, Loss function: 4.696, Average Loss: 4.481, avg. samples / sec: 66352.38
Iteration:   1460, Loss function: 3.713, Average Loss: 4.480, avg. samples / sec: 66380.79
Iteration:   1460, Loss function: 5.435, Average Loss: 4.470, avg. samples / sec: 66214.50
Iteration:   1460, Loss function: 4.659, Average Loss: 4.480, avg. samples / sec: 66086.29
Iteration:   1460, Loss function: 4.450, Average Loss: 4.476, avg. samples / sec: 66129.36
Iteration:   1460, Loss function: 4.796, Average Loss: 4.471, avg. samples / sec: 66165.41
Iteration:   1460, Loss function: 4.598, Average Loss: 4.484, avg. samples / sec: 66127.78
Iteration:   1460, Loss function: 3.488, Average Loss: 4.463, avg. samples / sec: 66184.95
Iteration:   1460, Loss function: 4.913, Average Loss: 4.467, avg. samples / sec: 66242.48
Iteration:   1460, Loss function: 3.503, Average Loss: 4.446, avg. samples / sec: 66090.04
Iteration:   1460, Loss function: 4.676, Average Loss: 4.486, avg. samples / sec: 66111.74
Iteration:   1460, Loss function: 3.283, Average Loss: 4.476, avg. samples / sec: 66125.64
Iteration:   1460, Loss function: 5.091, Average Loss: 4.455, avg. samples / sec: 65946.79
Iteration:   1460, Loss function: 3.706, Average Loss: 4.490, avg. samples / sec: 66050.58
Iteration:   1460, Loss function: 3.766, Average Loss: 4.451, avg. samples / sec: 66155.16
Iteration:   1460, Loss function: 4.406, Average Loss: 4.479, avg. samples / sec: 65947.65
Iteration:   1460, Loss function: 4.991, Average Loss: 4.459, avg. samples / sec: 66146.62
:::MLL 1558651728.302 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558651728.302 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.351, Average Loss: 4.460, avg. samples / sec: 65664.89
Iteration:   1480, Loss function: 4.772, Average Loss: 4.479, avg. samples / sec: 65739.26
Iteration:   1480, Loss function: 4.349, Average Loss: 4.489, avg. samples / sec: 65614.26
Iteration:   1480, Loss function: 4.818, Average Loss: 4.461, avg. samples / sec: 65874.69
Iteration:   1480, Loss function: 5.023, Average Loss: 4.438, avg. samples / sec: 65661.99
Iteration:   1480, Loss function: 2.939, Average Loss: 4.456, avg. samples / sec: 65776.02
Iteration:   1480, Loss function: 3.277, Average Loss: 4.459, avg. samples / sec: 65593.50
Iteration:   1480, Loss function: 5.239, Average Loss: 4.490, avg. samples / sec: 65693.91
Iteration:   1480, Loss function: 4.187, Average Loss: 4.448, avg. samples / sec: 65698.99
Iteration:   1480, Loss function: 3.169, Average Loss: 4.484, avg. samples / sec: 65631.84
Iteration:   1480, Loss function: 5.133, Average Loss: 4.453, avg. samples / sec: 65460.20
Iteration:   1480, Loss function: 4.256, Average Loss: 4.464, avg. samples / sec: 65690.97
Iteration:   1480, Loss function: 4.881, Average Loss: 4.451, avg. samples / sec: 65519.94
Iteration:   1480, Loss function: 4.007, Average Loss: 4.442, avg. samples / sec: 65596.37
Iteration:   1480, Loss function: 4.568, Average Loss: 4.483, avg. samples / sec: 65675.17
Iteration:   1480, Loss function: 4.049, Average Loss: 4.473, avg. samples / sec: 65541.73
Iteration:   1480, Loss function: 4.697, Average Loss: 4.480, avg. samples / sec: 65605.96
Iteration:   1480, Loss function: 4.487, Average Loss: 4.462, avg. samples / sec: 65621.35
Iteration:   1480, Loss function: 4.356, Average Loss: 4.477, avg. samples / sec: 65656.91
Iteration:   1480, Loss function: 5.102, Average Loss: 4.457, avg. samples / sec: 65712.47
Iteration:   1480, Loss function: 4.718, Average Loss: 4.486, avg. samples / sec: 65544.05
Iteration:   1480, Loss function: 4.013, Average Loss: 4.492, avg. samples / sec: 65669.57
Iteration:   1480, Loss function: 6.221, Average Loss: 4.486, avg. samples / sec: 65576.38
Iteration:   1480, Loss function: 4.329, Average Loss: 4.470, avg. samples / sec: 65556.61
Iteration:   1480, Loss function: 5.014, Average Loss: 4.498, avg. samples / sec: 65500.33
Iteration:   1480, Loss function: 4.044, Average Loss: 4.471, avg. samples / sec: 65555.88
Iteration:   1480, Loss function: 4.374, Average Loss: 4.482, avg. samples / sec: 65662.41
Iteration:   1480, Loss function: 5.198, Average Loss: 4.476, avg. samples / sec: 65548.41
Iteration:   1480, Loss function: 3.947, Average Loss: 4.472, avg. samples / sec: 65515.47
Iteration:   1480, Loss function: 3.194, Average Loss: 4.419, avg. samples / sec: 65435.04
Iteration:   1500, Loss function: 4.915, Average Loss: 4.455, avg. samples / sec: 66441.22
Iteration:   1500, Loss function: 3.850, Average Loss: 4.467, avg. samples / sec: 66448.52
Iteration:   1500, Loss function: 3.787, Average Loss: 4.481, avg. samples / sec: 66429.67
Iteration:   1500, Loss function: 3.688, Average Loss: 4.463, avg. samples / sec: 66307.62
Iteration:   1500, Loss function: 4.801, Average Loss: 4.441, avg. samples / sec: 66337.27
Iteration:   1500, Loss function: 4.530, Average Loss: 4.460, avg. samples / sec: 66336.99
Iteration:   1500, Loss function: 5.426, Average Loss: 4.452, avg. samples / sec: 66362.91
Iteration:   1500, Loss function: 4.502, Average Loss: 4.482, avg. samples / sec: 66409.45
Iteration:   1500, Loss function: 6.410, Average Loss: 4.494, avg. samples / sec: 66291.96
Iteration:   1500, Loss function: 4.058, Average Loss: 4.476, avg. samples / sec: 66259.23
Iteration:   1500, Loss function: 4.138, Average Loss: 4.498, avg. samples / sec: 66390.74
Iteration:   1500, Loss function: 3.173, Average Loss: 4.444, avg. samples / sec: 66317.76
Iteration:   1500, Loss function: 4.132, Average Loss: 4.472, avg. samples / sec: 66448.81
Iteration:   1500, Loss function: 5.033, Average Loss: 4.487, avg. samples / sec: 66278.89
Iteration:   1500, Loss function: 4.277, Average Loss: 4.457, avg. samples / sec: 66327.81
Iteration:   1500, Loss function: 4.325, Average Loss: 4.485, avg. samples / sec: 66385.86
Iteration:   1500, Loss function: 5.879, Average Loss: 4.455, avg. samples / sec: 66221.31
Iteration:   1500, Loss function: 5.707, Average Loss: 4.453, avg. samples / sec: 66205.60
Iteration:   1500, Loss function: 4.299, Average Loss: 4.483, avg. samples / sec: 66245.90
Iteration:   1500, Loss function: 4.516, Average Loss: 4.423, avg. samples / sec: 66388.27
Iteration:   1500, Loss function: 4.611, Average Loss: 4.480, avg. samples / sec: 66341.14
Iteration:   1500, Loss function: 4.552, Average Loss: 4.479, avg. samples / sec: 66327.96
Iteration:   1500, Loss function: 5.493, Average Loss: 4.495, avg. samples / sec: 66329.09
Iteration:   1500, Loss function: 4.479, Average Loss: 4.479, avg. samples / sec: 66209.24
Iteration:   1500, Loss function: 4.711, Average Loss: 4.468, avg. samples / sec: 66175.72
Iteration:   1500, Loss function: 4.662, Average Loss: 4.493, avg. samples / sec: 66153.64
Iteration:   1500, Loss function: 4.409, Average Loss: 4.465, avg. samples / sec: 66085.70
Iteration:   1500, Loss function: 4.287, Average Loss: 4.485, avg. samples / sec: 66211.63
Iteration:   1500, Loss function: 4.516, Average Loss: 4.482, avg. samples / sec: 66102.04
Iteration:   1500, Loss function: 5.185, Average Loss: 4.469, avg. samples / sec: 66155.41
Iteration:   1520, Loss function: 4.907, Average Loss: 4.457, avg. samples / sec: 66130.88
Iteration:   1520, Loss function: 3.450, Average Loss: 4.481, avg. samples / sec: 66090.44
Iteration:   1520, Loss function: 3.928, Average Loss: 4.438, avg. samples / sec: 66060.05
Iteration:   1520, Loss function: 3.985, Average Loss: 4.457, avg. samples / sec: 66190.74
Iteration:   1520, Loss function: 4.537, Average Loss: 4.465, avg. samples / sec: 66030.99
Iteration:   1520, Loss function: 3.322, Average Loss: 4.457, avg. samples / sec: 65975.84
Iteration:   1520, Loss function: 3.242, Average Loss: 4.463, avg. samples / sec: 66219.44
Iteration:   1520, Loss function: 3.762, Average Loss: 4.477, avg. samples / sec: 66059.99
Iteration:   1520, Loss function: 4.182, Average Loss: 4.460, avg. samples / sec: 66103.90
Iteration:   1520, Loss function: 5.363, Average Loss: 4.469, avg. samples / sec: 65980.97
Iteration:   1520, Loss function: 5.140, Average Loss: 4.484, avg. samples / sec: 66170.63
Iteration:   1520, Loss function: 5.296, Average Loss: 4.484, avg. samples / sec: 66148.23
Iteration:   1520, Loss function: 4.707, Average Loss: 4.484, avg. samples / sec: 66180.04
Iteration:   1520, Loss function: 4.556, Average Loss: 4.495, avg. samples / sec: 65977.88
Iteration:   1520, Loss function: 5.984, Average Loss: 4.477, avg. samples / sec: 66265.37
Iteration:   1520, Loss function: 5.013, Average Loss: 4.490, avg. samples / sec: 66168.58
Iteration:   1520, Loss function: 5.091, Average Loss: 4.467, avg. samples / sec: 65984.74
Iteration:   1520, Loss function: 3.752, Average Loss: 4.424, avg. samples / sec: 66123.99
Iteration:   1520, Loss function: 3.720, Average Loss: 4.499, avg. samples / sec: 66127.75
Iteration:   1520, Loss function: 4.111, Average Loss: 4.450, avg. samples / sec: 66025.76
Iteration:   1520, Loss function: 6.108, Average Loss: 4.470, avg. samples / sec: 66192.07
Iteration:   1520, Loss function: 4.707, Average Loss: 4.453, avg. samples / sec: 66064.85
Iteration:   1520, Loss function: 4.575, Average Loss: 4.477, avg. samples / sec: 65992.15
Iteration:   1520, Loss function: 6.258, Average Loss: 4.490, avg. samples / sec: 65981.96
Iteration:   1520, Loss function: 4.603, Average Loss: 4.500, avg. samples / sec: 65959.41
Iteration:   1520, Loss function: 5.905, Average Loss: 4.489, avg. samples / sec: 66003.52
Iteration:   1520, Loss function: 5.545, Average Loss: 4.481, avg. samples / sec: 66197.98
Iteration:   1520, Loss function: 3.830, Average Loss: 4.483, avg. samples / sec: 66051.54
Iteration:   1520, Loss function: 3.798, Average Loss: 4.479, avg. samples / sec: 65870.62
Iteration:   1520, Loss function: 4.372, Average Loss: 4.486, avg. samples / sec: 66028.08
:::MLL 1558651730.082 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558651730.082 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.201, Average Loss: 4.455, avg. samples / sec: 66064.01
Iteration:   1540, Loss function: 4.844, Average Loss: 4.489, avg. samples / sec: 66147.30
Iteration:   1540, Loss function: 3.429, Average Loss: 4.480, avg. samples / sec: 66002.66
Iteration:   1540, Loss function: 4.922, Average Loss: 4.501, avg. samples / sec: 66192.32
Iteration:   1540, Loss function: 3.928, Average Loss: 4.470, avg. samples / sec: 66140.66
Iteration:   1540, Loss function: 4.385, Average Loss: 4.468, avg. samples / sec: 66003.80
Iteration:   1540, Loss function: 4.279, Average Loss: 4.452, avg. samples / sec: 66015.92
Iteration:   1540, Loss function: 4.773, Average Loss: 4.448, avg. samples / sec: 66094.78
Iteration:   1540, Loss function: 3.854, Average Loss: 4.488, avg. samples / sec: 66068.54
Iteration:   1540, Loss function: 4.326, Average Loss: 4.465, avg. samples / sec: 66068.54
Iteration:   1540, Loss function: 4.107, Average Loss: 4.436, avg. samples / sec: 65970.34
Iteration:   1540, Loss function: 5.126, Average Loss: 4.492, avg. samples / sec: 66112.36
Iteration:   1540, Loss function: 4.387, Average Loss: 4.454, avg. samples / sec: 65994.28
Iteration:   1540, Loss function: 3.698, Average Loss: 4.455, avg. samples / sec: 65960.74
Iteration:   1540, Loss function: 4.031, Average Loss: 4.492, avg. samples / sec: 66106.93
Iteration:   1540, Loss function: 5.157, Average Loss: 4.484, avg. samples / sec: 65957.50
Iteration:   1540, Loss function: 4.094, Average Loss: 4.490, avg. samples / sec: 66023.84
Iteration:   1540, Loss function: 4.022, Average Loss: 4.466, avg. samples / sec: 65968.30
Iteration:   1540, Loss function: 4.208, Average Loss: 4.482, avg. samples / sec: 66092.43
Iteration:   1540, Loss function: 4.221, Average Loss: 4.467, avg. samples / sec: 65947.28
Iteration:   1540, Loss function: 3.263, Average Loss: 4.475, avg. samples / sec: 66038.69
Iteration:   1540, Loss function: 3.811, Average Loss: 4.499, avg. samples / sec: 65982.48
Iteration:   1540, Loss function: 4.943, Average Loss: 4.489, avg. samples / sec: 65936.64
Iteration:   1540, Loss function: 4.820, Average Loss: 4.426, avg. samples / sec: 65985.66
Iteration:   1540, Loss function: 4.688, Average Loss: 4.453, avg. samples / sec: 66011.47
Iteration:   1540, Loss function: 5.259, Average Loss: 4.486, avg. samples / sec: 65945.03
Iteration:   1540, Loss function: 4.753, Average Loss: 4.481, avg. samples / sec: 66046.99
Iteration:   1540, Loss function: 4.686, Average Loss: 4.477, avg. samples / sec: 65921.06
Iteration:   1540, Loss function: 3.725, Average Loss: 4.482, avg. samples / sec: 65946.97
Iteration:   1540, Loss function: 3.892, Average Loss: 4.486, avg. samples / sec: 66012.89
Iteration:   1560, Loss function: 4.945, Average Loss: 4.484, avg. samples / sec: 66142.21
Iteration:   1560, Loss function: 4.646, Average Loss: 4.467, avg. samples / sec: 66055.62
Iteration:   1560, Loss function: 5.628, Average Loss: 4.458, avg. samples / sec: 65900.41
Iteration:   1560, Loss function: 3.619, Average Loss: 4.486, avg. samples / sec: 65939.75
Iteration:   1560, Loss function: 4.086, Average Loss: 4.437, avg. samples / sec: 66031.20
Iteration:   1560, Loss function: 5.012, Average Loss: 4.471, avg. samples / sec: 66022.85
Iteration:   1560, Loss function: 4.226, Average Loss: 4.490, avg. samples / sec: 66048.19
Iteration:   1560, Loss function: 4.406, Average Loss: 4.446, avg. samples / sec: 65953.18
Iteration:   1560, Loss function: 3.694, Average Loss: 4.496, avg. samples / sec: 66056.15
Iteration:   1560, Loss function: 4.896, Average Loss: 4.450, avg. samples / sec: 66006.03
Iteration:   1560, Loss function: 4.721, Average Loss: 4.484, avg. samples / sec: 65950.61
Iteration:   1560, Loss function: 5.024, Average Loss: 4.485, avg. samples / sec: 66000.84
Iteration:   1560, Loss function: 4.727, Average Loss: 4.476, avg. samples / sec: 66094.63
Iteration:   1560, Loss function: 3.597, Average Loss: 4.477, avg. samples / sec: 66076.62
Iteration:   1560, Loss function: 4.690, Average Loss: 4.462, avg. samples / sec: 65996.88
Iteration:   1560, Loss function: 4.792, Average Loss: 4.498, avg. samples / sec: 65938.46
Iteration:   1560, Loss function: 4.043, Average Loss: 4.476, avg. samples / sec: 65835.66
Iteration:   1560, Loss function: 4.836, Average Loss: 4.495, avg. samples / sec: 65906.57
Iteration:   1560, Loss function: 3.544, Average Loss: 4.449, avg. samples / sec: 65962.84
Iteration:   1560, Loss function: 6.061, Average Loss: 4.470, avg. samples / sec: 65804.56
Iteration:   1560, Loss function: 3.878, Average Loss: 4.499, avg. samples / sec: 65803.42
Iteration:   1560, Loss function: 4.402, Average Loss: 4.429, avg. samples / sec: 65963.18
Iteration:   1560, Loss function: 4.503, Average Loss: 4.449, avg. samples / sec: 65844.83
Iteration:   1560, Loss function: 5.022, Average Loss: 4.467, avg. samples / sec: 65928.96
Iteration:   1560, Loss function: 3.758, Average Loss: 4.484, avg. samples / sec: 65937.35
Iteration:   1560, Loss function: 4.008, Average Loss: 4.488, avg. samples / sec: 66071.05
Iteration:   1560, Loss function: 5.657, Average Loss: 4.491, avg. samples / sec: 65929.36
Iteration:   1560, Loss function: 4.468, Average Loss: 4.487, avg. samples / sec: 65962.68
Iteration:   1560, Loss function: 3.683, Average Loss: 4.453, avg. samples / sec: 65789.47
Iteration:   1560, Loss function: 4.549, Average Loss: 4.473, avg. samples / sec: 65759.76
Iteration:   1580, Loss function: 4.333, Average Loss: 4.468, avg. samples / sec: 66268.08
Iteration:   1580, Loss function: 4.671, Average Loss: 4.494, avg. samples / sec: 66313.42
Iteration:   1580, Loss function: 4.442, Average Loss: 4.461, avg. samples / sec: 66254.09
Iteration:   1580, Loss function: 4.819, Average Loss: 4.491, avg. samples / sec: 66259.67
Iteration:   1580, Loss function: 4.572, Average Loss: 4.441, avg. samples / sec: 66247.05
Iteration:   1580, Loss function: 4.910, Average Loss: 4.487, avg. samples / sec: 66178.43
Iteration:   1580, Loss function: 3.516, Average Loss: 4.473, avg. samples / sec: 66237.90
Iteration:   1580, Loss function: 4.395, Average Loss: 4.453, avg. samples / sec: 66376.17
Iteration:   1580, Loss function: 5.108, Average Loss: 4.454, avg. samples / sec: 66261.44
Iteration:   1580, Loss function: 3.740, Average Loss: 4.459, avg. samples / sec: 66286.25
Iteration:   1580, Loss function: 4.330, Average Loss: 4.485, avg. samples / sec: 66370.54
Iteration:   1580, Loss function: 4.009, Average Loss: 4.475, avg. samples / sec: 66270.88
Iteration:   1580, Loss function: 5.034, Average Loss: 4.490, avg. samples / sec: 66371.16
Iteration:   1580, Loss function: 5.374, Average Loss: 4.496, avg. samples / sec: 66329.93
Iteration:   1580, Loss function: 5.267, Average Loss: 4.485, avg. samples / sec: 66252.78
Iteration:   1580, Loss function: 4.048, Average Loss: 4.475, avg. samples / sec: 66272.10
Iteration:   1580, Loss function: 4.867, Average Loss: 4.424, avg. samples / sec: 66320.57
Iteration:   1580, Loss function: 4.033, Average Loss: 4.474, avg. samples / sec: 66495.08
Iteration:   1580, Loss function: 3.776, Average Loss: 4.482, avg. samples / sec: 66221.18
Iteration:   1580, Loss function: 4.942, Average Loss: 4.497, avg. samples / sec: 66242.07
Iteration:   1580, Loss function: 3.746, Average Loss: 4.446, avg. samples / sec: 66203.20
Iteration:   1580, Loss function: 4.984, Average Loss: 4.450, avg. samples / sec: 66396.93
Iteration:   1580, Loss function: 3.481, Average Loss: 4.477, avg. samples / sec: 66212.50
Iteration:   1580, Loss function: 4.013, Average Loss: 4.494, avg. samples / sec: 66183.12
Iteration:   1580, Loss function: 3.963, Average Loss: 4.493, avg. samples / sec: 66264.03
Iteration:   1580, Loss function: 3.169, Average Loss: 4.466, avg. samples / sec: 66260.54
Iteration:   1580, Loss function: 5.236, Average Loss: 4.448, avg. samples / sec: 66247.15
Iteration:   1580, Loss function: 5.205, Average Loss: 4.487, avg. samples / sec: 66307.55
Iteration:   1580, Loss function: 4.129, Average Loss: 4.464, avg. samples / sec: 66169.26
Iteration:   1580, Loss function: 4.601, Average Loss: 4.490, avg. samples / sec: 66046.99
Iteration:   1600, Loss function: 3.671, Average Loss: 4.484, avg. samples / sec: 66501.92
Iteration:   1600, Loss function: 4.234, Average Loss: 4.475, avg. samples / sec: 66549.78
Iteration:   1600, Loss function: 3.964, Average Loss: 4.447, avg. samples / sec: 66588.81
Iteration:   1600, Loss function: 3.967, Average Loss: 4.469, avg. samples / sec: 66467.92
Iteration:   1600, Loss function: 4.114, Average Loss: 4.461, avg. samples / sec: 66441.41
Iteration:   1600, Loss function: 4.913, Average Loss: 4.492, avg. samples / sec: 66413.73
Iteration:   1600, Loss function: 4.073, Average Loss: 4.487, avg. samples / sec: 66529.64
Iteration:   1600, Loss function: 3.860, Average Loss: 4.467, avg. samples / sec: 66363.48
Iteration:   1600, Loss function: 5.083, Average Loss: 4.427, avg. samples / sec: 66502.99
Iteration:   1600, Loss function: 3.566, Average Loss: 4.457, avg. samples / sec: 66481.25
Iteration:   1600, Loss function: 5.116, Average Loss: 4.495, avg. samples / sec: 66551.86
Iteration:   1600, Loss function: 5.301, Average Loss: 4.477, avg. samples / sec: 66536.02
Iteration:   1600, Loss function: 5.620, Average Loss: 4.442, avg. samples / sec: 66386.86
Iteration:   1600, Loss function: 5.000, Average Loss: 4.493, avg. samples / sec: 66466.98
Iteration:   1600, Loss function: 3.851, Average Loss: 4.498, avg. samples / sec: 66351.67
Iteration:   1600, Loss function: 4.166, Average Loss: 4.490, avg. samples / sec: 66595.70
Iteration:   1600, Loss function: 3.782, Average Loss: 4.477, avg. samples / sec: 66489.47
Iteration:   1600, Loss function: 4.914, Average Loss: 4.477, avg. samples / sec: 66467.89
Iteration:   1600, Loss function: 3.592, Average Loss: 4.487, avg. samples / sec: 66438.09
Iteration:   1600, Loss function: 5.063, Average Loss: 4.466, avg. samples / sec: 66619.65
Iteration:   1600, Loss function: 4.644, Average Loss: 4.496, avg. samples / sec: 66498.06
Iteration:   1600, Loss function: 4.346, Average Loss: 4.456, avg. samples / sec: 66393.58
Iteration:   1600, Loss function: 5.839, Average Loss: 4.485, avg. samples / sec: 66420.18
Iteration:   1600, Loss function: 4.462, Average Loss: 4.494, avg. samples / sec: 66460.78
Iteration:   1600, Loss function: 3.739, Average Loss: 4.452, avg. samples / sec: 66359.48
Iteration:   1600, Loss function: 4.435, Average Loss: 4.445, avg. samples / sec: 66500.48
Iteration:   1600, Loss function: 3.844, Average Loss: 4.459, avg. samples / sec: 66442.95
Iteration:   1600, Loss function: 5.756, Average Loss: 4.463, avg. samples / sec: 66472.41
Iteration:   1600, Loss function: 3.868, Average Loss: 4.489, avg. samples / sec: 66369.85
Iteration:   1600, Loss function: 4.405, Average Loss: 4.487, avg. samples / sec: 66550.19
:::MLL 1558651731.859 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558651731.860 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 4.411, Average Loss: 4.489, avg. samples / sec: 66069.43
Iteration:   1620, Loss function: 4.567, Average Loss: 4.460, avg. samples / sec: 65929.23
Iteration:   1620, Loss function: 4.109, Average Loss: 4.446, avg. samples / sec: 65922.91
Iteration:   1620, Loss function: 4.288, Average Loss: 4.475, avg. samples / sec: 65887.19
Iteration:   1620, Loss function: 4.094, Average Loss: 4.497, avg. samples / sec: 65945.00
Iteration:   1620, Loss function: 4.119, Average Loss: 4.453, avg. samples / sec: 66030.71
Iteration:   1620, Loss function: 3.912, Average Loss: 4.465, avg. samples / sec: 65935.43
Iteration:   1620, Loss function: 3.647, Average Loss: 4.473, avg. samples / sec: 66008.25
Iteration:   1620, Loss function: 4.263, Average Loss: 4.481, avg. samples / sec: 65857.79
Iteration:   1620, Loss function: 5.064, Average Loss: 4.495, avg. samples / sec: 65961.91
Iteration:   1620, Loss function: 4.211, Average Loss: 4.485, avg. samples / sec: 65993.70
Iteration:   1620, Loss function: 4.812, Average Loss: 4.457, avg. samples / sec: 65930.19
Iteration:   1620, Loss function: 4.582, Average Loss: 4.469, avg. samples / sec: 65892.46
Iteration:   1620, Loss function: 6.259, Average Loss: 4.490, avg. samples / sec: 65942.16
Iteration:   1620, Loss function: 5.559, Average Loss: 4.475, avg. samples / sec: 65938.76
Iteration:   1620, Loss function: 5.432, Average Loss: 4.451, avg. samples / sec: 65989.86
Iteration:   1620, Loss function: 3.583, Average Loss: 4.491, avg. samples / sec: 65928.80
Iteration:   1620, Loss function: 3.911, Average Loss: 4.442, avg. samples / sec: 65962.25
Iteration:   1620, Loss function: 4.702, Average Loss: 4.462, avg. samples / sec: 65977.63
Iteration:   1620, Loss function: 4.780, Average Loss: 4.431, avg. samples / sec: 65875.21
Iteration:   1620, Loss function: 3.913, Average Loss: 4.499, avg. samples / sec: 65929.48
Iteration:   1620, Loss function: 4.219, Average Loss: 4.479, avg. samples / sec: 65922.79
Iteration:   1620, Loss function: 4.044, Average Loss: 4.466, avg. samples / sec: 65886.97
Iteration:   1620, Loss function: 3.720, Average Loss: 4.441, avg. samples / sec: 65866.13
Iteration:   1620, Loss function: 5.802, Average Loss: 4.465, avg. samples / sec: 65930.47
Iteration:   1620, Loss function: 4.452, Average Loss: 4.479, avg. samples / sec: 65837.26
Iteration:   1620, Loss function: 5.054, Average Loss: 4.491, avg. samples / sec: 65813.56
Iteration:   1620, Loss function: 4.426, Average Loss: 4.482, avg. samples / sec: 65910.49
Iteration:   1620, Loss function: 3.865, Average Loss: 4.491, avg. samples / sec: 65826.16
Iteration:   1620, Loss function: 4.754, Average Loss: 4.490, avg. samples / sec: 65964.81
Iteration:   1640, Loss function: 4.036, Average Loss: 4.467, avg. samples / sec: 66589.88
Iteration:   1640, Loss function: 3.282, Average Loss: 4.441, avg. samples / sec: 66696.05
Iteration:   1640, Loss function: 3.837, Average Loss: 4.459, avg. samples / sec: 66516.71
Iteration:   1640, Loss function: 5.218, Average Loss: 4.494, avg. samples / sec: 66553.05
Iteration:   1640, Loss function: 4.800, Average Loss: 4.499, avg. samples / sec: 66487.80
Iteration:   1640, Loss function: 4.534, Average Loss: 4.478, avg. samples / sec: 66503.71
Iteration:   1640, Loss function: 3.735, Average Loss: 4.441, avg. samples / sec: 66548.37
Iteration:   1640, Loss function: 5.356, Average Loss: 4.470, avg. samples / sec: 66498.13
Iteration:   1640, Loss function: 4.713, Average Loss: 4.464, avg. samples / sec: 66541.71
Iteration:   1640, Loss function: 4.658, Average Loss: 4.500, avg. samples / sec: 66557.73
Iteration:   1640, Loss function: 4.566, Average Loss: 4.489, avg. samples / sec: 66603.16
Iteration:   1640, Loss function: 4.516, Average Loss: 4.488, avg. samples / sec: 66336.77
Iteration:   1640, Loss function: 3.557, Average Loss: 4.477, avg. samples / sec: 66439.44
Iteration:   1640, Loss function: 5.044, Average Loss: 4.446, avg. samples / sec: 66412.98
Iteration:   1640, Loss function: 3.837, Average Loss: 4.469, avg. samples / sec: 66544.19
Iteration:   1640, Loss function: 3.197, Average Loss: 4.486, avg. samples / sec: 66612.13
Iteration:   1640, Loss function: 4.801, Average Loss: 4.464, avg. samples / sec: 66430.95
Iteration:   1640, Loss function: 3.108, Average Loss: 4.484, avg. samples / sec: 66583.05
Iteration:   1640, Loss function: 3.670, Average Loss: 4.490, avg. samples / sec: 66455.67
Iteration:   1640, Loss function: 3.896, Average Loss: 4.473, avg. samples / sec: 66373.73
Iteration:   1640, Loss function: 4.957, Average Loss: 4.488, avg. samples / sec: 66639.59
Iteration:   1640, Loss function: 3.241, Average Loss: 4.479, avg. samples / sec: 66421.75
Iteration:   1640, Loss function: 4.530, Average Loss: 4.481, avg. samples / sec: 66495.30
Iteration:   1640, Loss function: 4.497, Average Loss: 4.453, avg. samples / sec: 66397.02
Iteration:   1640, Loss function: 5.217, Average Loss: 4.480, avg. samples / sec: 66440.88
Iteration:   1640, Loss function: 4.783, Average Loss: 4.486, avg. samples / sec: 66358.10
Iteration:   1640, Loss function: 3.627, Average Loss: 4.495, avg. samples / sec: 66374.45
Iteration:   1640, Loss function: 4.396, Average Loss: 4.464, avg. samples / sec: 66413.98
Iteration:   1640, Loss function: 4.658, Average Loss: 4.454, avg. samples / sec: 66314.79
Iteration:   1640, Loss function: 6.344, Average Loss: 4.436, avg. samples / sec: 66318.32
Iteration:   1660, Loss function: 4.434, Average Loss: 4.444, avg. samples / sec: 66498.28
Iteration:   1660, Loss function: 4.594, Average Loss: 4.452, avg. samples / sec: 66636.73
Iteration:   1660, Loss function: 4.983, Average Loss: 4.475, avg. samples / sec: 66497.44
Iteration:   1660, Loss function: 5.520, Average Loss: 4.479, avg. samples / sec: 66565.53
Iteration:   1660, Loss function: 5.080, Average Loss: 4.489, avg. samples / sec: 66464.07
Iteration:   1660, Loss function: 3.819, Average Loss: 4.458, avg. samples / sec: 66353.73
Iteration:   1660, Loss function: 4.671, Average Loss: 4.465, avg. samples / sec: 66601.52
Iteration:   1660, Loss function: 3.862, Average Loss: 4.477, avg. samples / sec: 66364.76
Iteration:   1660, Loss function: 4.654, Average Loss: 4.466, avg. samples / sec: 66411.86
Iteration:   1660, Loss function: 3.515, Average Loss: 4.493, avg. samples / sec: 66383.33
Iteration:   1660, Loss function: 4.850, Average Loss: 4.474, avg. samples / sec: 66479.81
Iteration:   1660, Loss function: 4.447, Average Loss: 4.472, avg. samples / sec: 66251.13
Iteration:   1660, Loss function: 3.638, Average Loss: 4.458, avg. samples / sec: 66465.76
Iteration:   1660, Loss function: 3.858, Average Loss: 4.444, avg. samples / sec: 66237.24
Iteration:   1660, Loss function: 5.026, Average Loss: 4.483, avg. samples / sec: 66426.13
Iteration:   1660, Loss function: 3.210, Average Loss: 4.470, avg. samples / sec: 66426.29
Iteration:   1660, Loss function: 4.386, Average Loss: 4.476, avg. samples / sec: 66416.83
Iteration:   1660, Loss function: 3.263, Average Loss: 4.458, avg. samples / sec: 66311.92
Iteration:   1660, Loss function: 4.931, Average Loss: 4.432, avg. samples / sec: 66559.18
Iteration:   1660, Loss function: 2.894, Average Loss: 4.485, avg. samples / sec: 66301.53
Iteration:   1660, Loss function: 5.349, Average Loss: 4.464, avg. samples / sec: 66350.29
Iteration:   1660, Loss function: 4.399, Average Loss: 4.495, avg. samples / sec: 66416.17
Iteration:   1660, Loss function: 5.099, Average Loss: 4.493, avg. samples / sec: 66225.73
Iteration:   1660, Loss function: 4.666, Average Loss: 4.479, avg. samples / sec: 66314.76
Iteration:   1660, Loss function: 3.602, Average Loss: 4.465, avg. samples / sec: 66257.18
Iteration:   1660, Loss function: 4.227, Average Loss: 4.489, avg. samples / sec: 66379.42
Iteration:   1660, Loss function: 4.773, Average Loss: 4.487, avg. samples / sec: 66318.32
Iteration:   1660, Loss function: 3.682, Average Loss: 4.438, avg. samples / sec: 66246.90
Iteration:   1660, Loss function: 4.298, Average Loss: 4.494, avg. samples / sec: 66155.38
Iteration:   1660, Loss function: 4.735, Average Loss: 4.493, avg. samples / sec: 66242.20
:::MLL 1558651733.632 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558651733.633 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 6.165, Average Loss: 4.443, avg. samples / sec: 66637.26
Iteration:   1680, Loss function: 4.060, Average Loss: 4.494, avg. samples / sec: 66587.67
Iteration:   1680, Loss function: 4.955, Average Loss: 4.464, avg. samples / sec: 66336.05
Iteration:   1680, Loss function: 4.037, Average Loss: 4.468, avg. samples / sec: 66413.83
Iteration:   1680, Loss function: 4.976, Average Loss: 4.442, avg. samples / sec: 66407.91
Iteration:   1680, Loss function: 3.098, Average Loss: 4.480, avg. samples / sec: 66280.48
Iteration:   1680, Loss function: 5.689, Average Loss: 4.461, avg. samples / sec: 66418.21
Iteration:   1680, Loss function: 4.362, Average Loss: 4.494, avg. samples / sec: 66416.08
Iteration:   1680, Loss function: 3.637, Average Loss: 4.475, avg. samples / sec: 66362.85
Iteration:   1680, Loss function: 4.763, Average Loss: 4.493, avg. samples / sec: 66319.57
Iteration:   1680, Loss function: 3.850, Average Loss: 4.473, avg. samples / sec: 66366.60
Iteration:   1680, Loss function: 3.737, Average Loss: 4.475, avg. samples / sec: 66293.17
Iteration:   1680, Loss function: 5.541, Average Loss: 4.493, avg. samples / sec: 66389.58
Iteration:   1680, Loss function: 3.558, Average Loss: 4.463, avg. samples / sec: 66309.74
Iteration:   1680, Loss function: 3.499, Average Loss: 4.469, avg. samples / sec: 66321.25
Iteration:   1680, Loss function: 4.452, Average Loss: 4.484, avg. samples / sec: 66230.05
Iteration:   1680, Loss function: 4.468, Average Loss: 4.443, avg. samples / sec: 66192.76
Iteration:   1680, Loss function: 4.314, Average Loss: 4.456, avg. samples / sec: 66330.96
Iteration:   1680, Loss function: 2.799, Average Loss: 4.465, avg. samples / sec: 66285.16
Iteration:   1680, Loss function: 4.765, Average Loss: 4.476, avg. samples / sec: 66370.48
Iteration:   1680, Loss function: 3.033, Average Loss: 4.464, avg. samples / sec: 66377.70
Iteration:   1680, Loss function: 4.304, Average Loss: 4.493, avg. samples / sec: 66471.31
Iteration:   1680, Loss function: 4.080, Average Loss: 4.458, avg. samples / sec: 66184.77
Iteration:   1680, Loss function: 4.501, Average Loss: 4.490, avg. samples / sec: 66329.06
Iteration:   1680, Loss function: 4.492, Average Loss: 4.481, avg. samples / sec: 66303.62
Iteration:   1680, Loss function: 3.825, Average Loss: 4.468, avg. samples / sec: 66111.62
Iteration:   1680, Loss function: 5.480, Average Loss: 4.456, avg. samples / sec: 66226.35
Iteration:   1680, Loss function: 5.420, Average Loss: 4.425, avg. samples / sec: 66230.33
Iteration:   1680, Loss function: 4.711, Average Loss: 4.448, avg. samples / sec: 66064.14
Iteration:   1680, Loss function: 4.423, Average Loss: 4.483, avg. samples / sec: 66251.04
Iteration:   1700, Loss function: 3.446, Average Loss: 4.471, avg. samples / sec: 66478.33
Iteration:   1700, Loss function: 4.022, Average Loss: 4.485, avg. samples / sec: 66636.82
Iteration:   1700, Loss function: 4.838, Average Loss: 4.465, avg. samples / sec: 66504.15
Iteration:   1700, Loss function: 5.770, Average Loss: 4.469, avg. samples / sec: 66464.76
Iteration:   1700, Loss function: 4.310, Average Loss: 4.459, avg. samples / sec: 66514.92
Iteration:   1700, Loss function: 3.543, Average Loss: 4.494, avg. samples / sec: 66329.52
Iteration:   1700, Loss function: 3.645, Average Loss: 4.450, avg. samples / sec: 66563.52
Iteration:   1700, Loss function: 4.600, Average Loss: 4.498, avg. samples / sec: 66413.42
Iteration:   1700, Loss function: 5.158, Average Loss: 4.466, avg. samples / sec: 66440.32
Iteration:   1700, Loss function: 4.713, Average Loss: 4.439, avg. samples / sec: 66343.17
Iteration:   1700, Loss function: 4.183, Average Loss: 4.477, avg. samples / sec: 66384.20
Iteration:   1700, Loss function: 4.702, Average Loss: 4.461, avg. samples / sec: 66289.90
Iteration:   1700, Loss function: 3.722, Average Loss: 4.489, avg. samples / sec: 66361.60
Iteration:   1700, Loss function: 5.313, Average Loss: 4.467, avg. samples / sec: 66307.86
Iteration:   1700, Loss function: 3.729, Average Loss: 4.440, avg. samples / sec: 66130.39
Iteration:   1700, Loss function: 4.392, Average Loss: 4.459, avg. samples / sec: 66358.41
Iteration:   1700, Loss function: 3.930, Average Loss: 4.472, avg. samples / sec: 66284.88
Iteration:   1700, Loss function: 3.784, Average Loss: 4.482, avg. samples / sec: 66335.61
Iteration:   1700, Loss function: 4.399, Average Loss: 4.496, avg. samples / sec: 66360.66
Iteration:   1700, Loss function: 4.066, Average Loss: 4.495, avg. samples / sec: 66328.56
Iteration:   1700, Loss function: 3.432, Average Loss: 4.466, avg. samples / sec: 66302.97
Iteration:   1700, Loss function: 4.278, Average Loss: 4.473, avg. samples / sec: 66292.89
Iteration:   1700, Loss function: 3.299, Average Loss: 4.421, avg. samples / sec: 66444.08
Iteration:   1700, Loss function: 4.205, Average Loss: 4.480, avg. samples / sec: 66257.18
Iteration:   1700, Loss function: 5.807, Average Loss: 4.443, avg. samples / sec: 66304.40
Iteration:   1700, Loss function: 4.685, Average Loss: 4.483, avg. samples / sec: 66368.23
Iteration:   1700, Loss function: 3.157, Average Loss: 4.472, avg. samples / sec: 66257.64
Iteration:   1700, Loss function: 3.604, Average Loss: 4.454, avg. samples / sec: 66390.55
Iteration:   1700, Loss function: 4.460, Average Loss: 4.487, avg. samples / sec: 66326.28
Iteration:   1700, Loss function: 4.878, Average Loss: 4.471, avg. samples / sec: 66283.35
Iteration:   1720, Loss function: 4.310, Average Loss: 4.456, avg. samples / sec: 66452.41
Iteration:   1720, Loss function: 3.449, Average Loss: 4.470, avg. samples / sec: 66404.00
Iteration:   1720, Loss function: 3.529, Average Loss: 4.488, avg. samples / sec: 66420.34
Iteration:   1720, Loss function: 4.858, Average Loss: 4.500, avg. samples / sec: 66378.32
Iteration:   1720, Loss function: 4.798, Average Loss: 4.482, avg. samples / sec: 66491.10
Iteration:   1720, Loss function: 3.963, Average Loss: 4.486, avg. samples / sec: 66455.17
Iteration:   1720, Loss function: 6.717, Average Loss: 4.471, avg. samples / sec: 66500.48
Iteration:   1720, Loss function: 4.868, Average Loss: 4.477, avg. samples / sec: 66404.00
Iteration:   1720, Loss function: 4.438, Average Loss: 4.463, avg. samples / sec: 66296.79
Iteration:   1720, Loss function: 3.815, Average Loss: 4.456, avg. samples / sec: 66514.54
Iteration:   1720, Loss function: 5.269, Average Loss: 4.461, avg. samples / sec: 66398.28
Iteration:   1720, Loss function: 4.461, Average Loss: 4.475, avg. samples / sec: 66375.04
Iteration:   1720, Loss function: 4.485, Average Loss: 4.436, avg. samples / sec: 66373.92
Iteration:   1720, Loss function: 4.725, Average Loss: 4.495, avg. samples / sec: 66364.04
Iteration:   1720, Loss function: 4.843, Average Loss: 4.426, avg. samples / sec: 66386.83
Iteration:   1720, Loss function: 4.262, Average Loss: 4.464, avg. samples / sec: 66374.92
Iteration:   1720, Loss function: 4.492, Average Loss: 4.486, avg. samples / sec: 66422.22
Iteration:   1720, Loss function: 4.248, Average Loss: 4.486, avg. samples / sec: 66447.90
Iteration:   1720, Loss function: 3.809, Average Loss: 4.468, avg. samples / sec: 66521.73
Iteration:   1720, Loss function: 3.466, Average Loss: 4.477, avg. samples / sec: 66215.96
Iteration:   1720, Loss function: 3.498, Average Loss: 4.466, avg. samples / sec: 66271.04
Iteration:   1720, Loss function: 4.139, Average Loss: 4.480, avg. samples / sec: 66386.55
Iteration:   1720, Loss function: 4.108, Average Loss: 4.443, avg. samples / sec: 66255.65
Iteration:   1720, Loss function: 4.667, Average Loss: 4.453, avg. samples / sec: 66244.53
Iteration:   1720, Loss function: 3.750, Average Loss: 4.466, avg. samples / sec: 66362.10
Iteration:   1720, Loss function: 4.452, Average Loss: 4.467, avg. samples / sec: 66170.13
Iteration:   1720, Loss function: 4.326, Average Loss: 4.493, avg. samples / sec: 66290.06
Iteration:   1720, Loss function: 3.669, Average Loss: 4.459, avg. samples / sec: 66264.87
Iteration:   1720, Loss function: 4.288, Average Loss: 4.440, avg. samples / sec: 66304.56
Iteration:   1720, Loss function: 3.778, Average Loss: 4.468, avg. samples / sec: 66286.63
Iteration:   1740, Loss function: 5.634, Average Loss: 4.464, avg. samples / sec: 66697.44
Iteration:   1740, Loss function: 3.519, Average Loss: 4.488, avg. samples / sec: 66620.76
Iteration:   1740, Loss function: 3.587, Average Loss: 4.463, avg. samples / sec: 66769.42
Iteration:   1740, Loss function: 4.551, Average Loss: 4.436, avg. samples / sec: 66663.96
Iteration:   1740, Loss function: 5.206, Average Loss: 4.454, avg. samples / sec: 66451.03
Iteration:   1740, Loss function: 3.758, Average Loss: 4.474, avg. samples / sec: 66612.51
Iteration:   1740, Loss function: 5.894, Average Loss: 4.454, avg. samples / sec: 66666.04
Iteration:   1740, Loss function: 5.395, Average Loss: 4.468, avg. samples / sec: 66654.12
Iteration:   1740, Loss function: 3.552, Average Loss: 4.460, avg. samples / sec: 66561.95
Iteration:   1740, Loss function: 5.460, Average Loss: 4.462, avg. samples / sec: 66702.49
Iteration:   1740, Loss function: 4.309, Average Loss: 4.477, avg. samples / sec: 66548.49
Iteration:   1740, Loss function: 5.406, Average Loss: 4.461, avg. samples / sec: 66648.95
Iteration:   1740, Loss function: 3.943, Average Loss: 4.444, avg. samples / sec: 66714.93
Iteration:   1740, Loss function: 3.157, Average Loss: 4.490, avg. samples / sec: 66591.26
Iteration:   1740, Loss function: 5.219, Average Loss: 4.471, avg. samples / sec: 66723.77
Iteration:   1740, Loss function: 5.359, Average Loss: 4.480, avg. samples / sec: 66452.72
Iteration:   1740, Loss function: 5.635, Average Loss: 4.484, avg. samples / sec: 66583.05
Iteration:   1740, Loss function: 4.387, Average Loss: 4.425, avg. samples / sec: 66573.20
Iteration:   1740, Loss function: 4.840, Average Loss: 4.492, avg. samples / sec: 66634.80
Iteration:   1740, Loss function: 4.610, Average Loss: 4.467, avg. samples / sec: 66378.45
Iteration:   1740, Loss function: 5.904, Average Loss: 4.480, avg. samples / sec: 66581.79
Iteration:   1740, Loss function: 3.631, Average Loss: 4.469, avg. samples / sec: 66553.65
Iteration:   1740, Loss function: 6.278, Average Loss: 4.487, avg. samples / sec: 66410.70
Iteration:   1740, Loss function: 4.206, Average Loss: 4.472, avg. samples / sec: 66448.99
Iteration:   1740, Loss function: 4.670, Average Loss: 4.466, avg. samples / sec: 66479.65
Iteration:   1740, Loss function: 3.924, Average Loss: 4.468, avg. samples / sec: 66515.92
Iteration:   1740, Loss function: 3.744, Average Loss: 4.489, avg. samples / sec: 66540.26
Iteration:   1740, Loss function: 4.163, Average Loss: 4.465, avg. samples / sec: 66572.61
Iteration:   1740, Loss function: 3.859, Average Loss: 4.500, avg. samples / sec: 66414.70
Iteration:   1740, Loss function: 3.893, Average Loss: 4.474, avg. samples / sec: 66521.67
:::MLL 1558651735.404 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558651735.404 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 2.962, Average Loss: 4.484, avg. samples / sec: 66157.71
Iteration:   1760, Loss function: 4.024, Average Loss: 4.446, avg. samples / sec: 66111.87
Iteration:   1760, Loss function: 3.653, Average Loss: 4.451, avg. samples / sec: 66082.42
Iteration:   1760, Loss function: 4.662, Average Loss: 4.470, avg. samples / sec: 66153.73
Iteration:   1760, Loss function: 4.897, Average Loss: 4.453, avg. samples / sec: 66016.23
Iteration:   1760, Loss function: 3.259, Average Loss: 4.458, avg. samples / sec: 66062.25
Iteration:   1760, Loss function: 2.929, Average Loss: 4.461, avg. samples / sec: 65976.43
Iteration:   1760, Loss function: 3.880, Average Loss: 4.462, avg. samples / sec: 66051.04
Iteration:   1760, Loss function: 4.110, Average Loss: 4.469, avg. samples / sec: 66090.81
Iteration:   1760, Loss function: 4.356, Average Loss: 4.477, avg. samples / sec: 66079.53
Iteration:   1760, Loss function: 4.765, Average Loss: 4.494, avg. samples / sec: 66119.34
Iteration:   1760, Loss function: 5.174, Average Loss: 4.492, avg. samples / sec: 66036.34
Iteration:   1760, Loss function: 4.400, Average Loss: 4.488, avg. samples / sec: 65888.76
Iteration:   1760, Loss function: 4.251, Average Loss: 4.477, avg. samples / sec: 66004.11
Iteration:   1760, Loss function: 4.390, Average Loss: 4.473, avg. samples / sec: 66057.70
Iteration:   1760, Loss function: 5.372, Average Loss: 4.466, avg. samples / sec: 65859.11
Iteration:   1760, Loss function: 4.218, Average Loss: 4.475, avg. samples / sec: 66052.68
Iteration:   1760, Loss function: 4.337, Average Loss: 4.475, avg. samples / sec: 65975.34
Iteration:   1760, Loss function: 4.434, Average Loss: 4.495, avg. samples / sec: 66046.77
Iteration:   1760, Loss function: 4.470, Average Loss: 4.492, avg. samples / sec: 66023.07
Iteration:   1760, Loss function: 3.956, Average Loss: 4.481, avg. samples / sec: 66002.72
Iteration:   1760, Loss function: 5.083, Average Loss: 4.461, avg. samples / sec: 66039.74
Iteration:   1760, Loss function: 4.725, Average Loss: 4.464, avg. samples / sec: 66015.68
Iteration:   1760, Loss function: 4.051, Average Loss: 4.462, avg. samples / sec: 65917.85
Iteration:   1760, Loss function: 3.468, Average Loss: 4.454, avg. samples / sec: 65931.82
Iteration:   1760, Loss function: 3.929, Average Loss: 4.470, avg. samples / sec: 65967.78
Iteration:   1760, Loss function: 4.158, Average Loss: 4.467, avg. samples / sec: 66004.30
Iteration:   1760, Loss function: 5.389, Average Loss: 4.476, avg. samples / sec: 66015.09
Iteration:   1760, Loss function: 3.957, Average Loss: 4.435, avg. samples / sec: 65801.39
Iteration:   1760, Loss function: 3.942, Average Loss: 4.427, avg. samples / sec: 65865.14
Iteration:   1780, Loss function: 3.931, Average Loss: 4.459, avg. samples / sec: 66767.93
Iteration:   1780, Loss function: 4.241, Average Loss: 4.464, avg. samples / sec: 66789.99
Iteration:   1780, Loss function: 4.487, Average Loss: 4.472, avg. samples / sec: 66762.90
Iteration:   1780, Loss function: 3.877, Average Loss: 4.447, avg. samples / sec: 66676.55
Iteration:   1780, Loss function: 4.824, Average Loss: 4.486, avg. samples / sec: 66652.33
Iteration:   1780, Loss function: 3.481, Average Loss: 4.450, avg. samples / sec: 66667.84
Iteration:   1780, Loss function: 3.470, Average Loss: 4.453, avg. samples / sec: 66795.85
Iteration:   1780, Loss function: 3.553, Average Loss: 4.481, avg. samples / sec: 66766.35
Iteration:   1780, Loss function: 3.927, Average Loss: 4.460, avg. samples / sec: 66695.70
Iteration:   1780, Loss function: 4.116, Average Loss: 4.469, avg. samples / sec: 66804.14
Iteration:   1780, Loss function: 4.102, Average Loss: 4.471, avg. samples / sec: 66732.87
Iteration:   1780, Loss function: 4.731, Average Loss: 4.427, avg. samples / sec: 66900.39
Iteration:   1780, Loss function: 3.927, Average Loss: 4.492, avg. samples / sec: 66673.83
Iteration:   1780, Loss function: 3.757, Average Loss: 4.468, avg. samples / sec: 66600.89
Iteration:   1780, Loss function: 4.249, Average Loss: 4.478, avg. samples / sec: 66699.52
Iteration:   1780, Loss function: 3.944, Average Loss: 4.472, avg. samples / sec: 66680.14
Iteration:   1780, Loss function: 5.316, Average Loss: 4.458, avg. samples / sec: 66737.49
Iteration:   1780, Loss function: 4.079, Average Loss: 4.493, avg. samples / sec: 66638.24
Iteration:   1780, Loss function: 4.624, Average Loss: 4.461, avg. samples / sec: 66608.00
Iteration:   1780, Loss function: 4.836, Average Loss: 4.436, avg. samples / sec: 66800.22
Iteration:   1780, Loss function: 4.042, Average Loss: 4.449, avg. samples / sec: 66564.56
Iteration:   1780, Loss function: 5.015, Average Loss: 4.473, avg. samples / sec: 66636.16
Iteration:   1780, Loss function: 4.631, Average Loss: 4.492, avg. samples / sec: 66674.50
Iteration:   1780, Loss function: 4.367, Average Loss: 4.461, avg. samples / sec: 66680.93
Iteration:   1780, Loss function: 3.838, Average Loss: 4.464, avg. samples / sec: 66687.49
Iteration:   1780, Loss function: 4.694, Average Loss: 4.466, avg. samples / sec: 66678.72
Iteration:   1780, Loss function: 4.514, Average Loss: 4.486, avg. samples / sec: 66595.92
Iteration:   1780, Loss function: 2.919, Average Loss: 4.443, avg. samples / sec: 66503.71
Iteration:   1780, Loss function: 4.906, Average Loss: 4.468, avg. samples / sec: 66642.59
Iteration:   1780, Loss function: 4.902, Average Loss: 4.489, avg. samples / sec: 66560.78
Iteration:   1800, Loss function: 3.731, Average Loss: 4.459, avg. samples / sec: 66506.94
Iteration:   1800, Loss function: 4.680, Average Loss: 4.482, avg. samples / sec: 66718.97
Iteration:   1800, Loss function: 5.987, Average Loss: 4.462, avg. samples / sec: 66473.38
Iteration:   1800, Loss function: 4.015, Average Loss: 4.449, avg. samples / sec: 66523.99
Iteration:   1800, Loss function: 4.366, Average Loss: 4.448, avg. samples / sec: 66634.14
Iteration:   1800, Loss function: 4.594, Average Loss: 4.479, avg. samples / sec: 66510.11
Iteration:   1800, Loss function: 3.876, Average Loss: 4.468, avg. samples / sec: 66530.87
Iteration:   1800, Loss function: 4.724, Average Loss: 4.463, avg. samples / sec: 66624.03
Iteration:   1800, Loss function: 4.800, Average Loss: 4.458, avg. samples / sec: 66546.11
Iteration:   1800, Loss function: 4.160, Average Loss: 4.471, avg. samples / sec: 66423.41
Iteration:   1800, Loss function: 5.018, Average Loss: 4.435, avg. samples / sec: 66559.84
Iteration:   1800, Loss function: 4.287, Average Loss: 4.446, avg. samples / sec: 66485.08
Iteration:   1800, Loss function: 3.661, Average Loss: 4.495, avg. samples / sec: 66519.85
Iteration:   1800, Loss function: 4.767, Average Loss: 4.472, avg. samples / sec: 66541.80
Iteration:   1800, Loss function: 4.676, Average Loss: 4.488, avg. samples / sec: 66642.37
Iteration:   1800, Loss function: 3.782, Average Loss: 4.458, avg. samples / sec: 66524.93
Iteration:   1800, Loss function: 4.505, Average Loss: 4.468, avg. samples / sec: 66549.69
Iteration:   1800, Loss function: 3.545, Average Loss: 4.455, avg. samples / sec: 66519.60
Iteration:   1800, Loss function: 4.241, Average Loss: 4.451, avg. samples / sec: 66491.26
Iteration:   1800, Loss function: 3.622, Average Loss: 4.472, avg. samples / sec: 66462.85
Iteration:   1800, Loss function: 4.357, Average Loss: 4.485, avg. samples / sec: 66427.16
Iteration:   1800, Loss function: 3.895, Average Loss: 4.472, avg. samples / sec: 66435.68
Iteration:   1800, Loss function: 4.757, Average Loss: 4.463, avg. samples / sec: 66567.64
Iteration:   1800, Loss function: 4.224, Average Loss: 4.423, avg. samples / sec: 66412.17
Iteration:   1800, Loss function: 4.958, Average Loss: 4.453, avg. samples / sec: 66358.10
Iteration:   1800, Loss function: 5.020, Average Loss: 4.465, avg. samples / sec: 66411.29
Iteration:   1800, Loss function: 4.326, Average Loss: 4.445, avg. samples / sec: 66478.40
Iteration:   1800, Loss function: 4.560, Average Loss: 4.493, avg. samples / sec: 66364.79
Iteration:   1800, Loss function: 3.342, Average Loss: 4.489, avg. samples / sec: 66368.82
Iteration:   1800, Loss function: 4.249, Average Loss: 4.465, avg. samples / sec: 66266.96
:::MLL 1558651737.183 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558651737.184 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 3.723, Average Loss: 4.469, avg. samples / sec: 65320.94
Iteration:   1820, Loss function: 4.358, Average Loss: 4.449, avg. samples / sec: 65206.99
Iteration:   1820, Loss function: 4.399, Average Loss: 4.443, avg. samples / sec: 65398.81
Iteration:   1820, Loss function: 4.156, Average Loss: 4.454, avg. samples / sec: 65322.66
Iteration:   1820, Loss function: 3.413, Average Loss: 4.469, avg. samples / sec: 65351.50
Iteration:   1820, Loss function: 5.481, Average Loss: 4.455, avg. samples / sec: 65233.95
Iteration:   1820, Loss function: 3.841, Average Loss: 4.446, avg. samples / sec: 65181.84
Iteration:   1820, Loss function: 4.421, Average Loss: 4.495, avg. samples / sec: 65274.25
Iteration:   1820, Loss function: 4.217, Average Loss: 4.466, avg. samples / sec: 65298.03
Iteration:   1820, Loss function: 4.663, Average Loss: 4.442, avg. samples / sec: 65224.44
Iteration:   1820, Loss function: 4.406, Average Loss: 4.474, avg. samples / sec: 65173.67
Iteration:   1820, Loss function: 4.743, Average Loss: 4.460, avg. samples / sec: 65149.63
Iteration:   1820, Loss function: 4.182, Average Loss: 4.465, avg. samples / sec: 65260.41
Iteration:   1820, Loss function: 4.540, Average Loss: 4.477, avg. samples / sec: 65135.93
Iteration:   1820, Loss function: 4.317, Average Loss: 4.433, avg. samples / sec: 65206.78
Iteration:   1820, Loss function: 4.445, Average Loss: 4.421, avg. samples / sec: 65298.18
Iteration:   1820, Loss function: 6.124, Average Loss: 4.465, avg. samples / sec: 65315.34
Iteration:   1820, Loss function: 4.973, Average Loss: 4.462, avg. samples / sec: 65162.73
Iteration:   1820, Loss function: 3.694, Average Loss: 4.444, avg. samples / sec: 65224.29
Iteration:   1820, Loss function: 4.257, Average Loss: 4.482, avg. samples / sec: 65200.96
Iteration:   1820, Loss function: 2.639, Average Loss: 4.443, avg. samples / sec: 65114.77
Iteration:   1820, Loss function: 4.516, Average Loss: 4.458, avg. samples / sec: 65397.38
Iteration:   1820, Loss function: 4.842, Average Loss: 4.455, avg. samples / sec: 65192.79
Iteration:   1820, Loss function: 4.771, Average Loss: 4.494, avg. samples / sec: 65308.83
Iteration:   1820, Loss function: 4.442, Average Loss: 4.456, avg. samples / sec: 65197.28
Iteration:   1820, Loss function: 4.020, Average Loss: 4.458, avg. samples / sec: 65078.15
Iteration:   1820, Loss function: 3.455, Average Loss: 4.471, avg. samples / sec: 65117.03
Iteration:   1820, Loss function: 5.327, Average Loss: 4.486, avg. samples / sec: 65285.74
Iteration:   1820, Loss function: 4.533, Average Loss: 4.451, avg. samples / sec: 65176.11
Iteration:   1820, Loss function: 3.911, Average Loss: 4.479, avg. samples / sec: 65113.30
Iteration:   1840, Loss function: 4.420, Average Loss: 4.446, avg. samples / sec: 66355.76
Iteration:   1840, Loss function: 4.611, Average Loss: 4.445, avg. samples / sec: 66279.30
Iteration:   1840, Loss function: 5.031, Average Loss: 4.475, avg. samples / sec: 66380.36
Iteration:   1840, Loss function: 4.787, Average Loss: 4.458, avg. samples / sec: 66349.70
Iteration:   1840, Loss function: 4.112, Average Loss: 4.467, avg. samples / sec: 66349.67
Iteration:   1840, Loss function: 4.405, Average Loss: 4.476, avg. samples / sec: 66544.16
Iteration:   1840, Loss function: 4.019, Average Loss: 4.461, avg. samples / sec: 66247.46
Iteration:   1840, Loss function: 3.516, Average Loss: 4.450, avg. samples / sec: 66417.46
Iteration:   1840, Loss function: 4.684, Average Loss: 4.457, avg. samples / sec: 66380.48
Iteration:   1840, Loss function: 4.250, Average Loss: 4.449, avg. samples / sec: 66419.68
Iteration:   1840, Loss function: 5.052, Average Loss: 4.482, avg. samples / sec: 66394.30
Iteration:   1840, Loss function: 4.561, Average Loss: 4.451, avg. samples / sec: 66295.70
Iteration:   1840, Loss function: 4.300, Average Loss: 4.449, avg. samples / sec: 66289.87
Iteration:   1840, Loss function: 3.775, Average Loss: 4.453, avg. samples / sec: 66420.81
Iteration:   1840, Loss function: 5.476, Average Loss: 4.468, avg. samples / sec: 66467.64
Iteration:   1840, Loss function: 4.119, Average Loss: 4.445, avg. samples / sec: 66354.57
Iteration:   1840, Loss function: 3.511, Average Loss: 4.488, avg. samples / sec: 66384.83
Iteration:   1840, Loss function: 2.846, Average Loss: 4.472, avg. samples / sec: 66290.12
Iteration:   1840, Loss function: 3.692, Average Loss: 4.486, avg. samples / sec: 66275.78
Iteration:   1840, Loss function: 4.065, Average Loss: 4.461, avg. samples / sec: 66336.58
Iteration:   1840, Loss function: 4.037, Average Loss: 4.437, avg. samples / sec: 66238.71
Iteration:   1840, Loss function: 4.869, Average Loss: 4.430, avg. samples / sec: 66303.97
Iteration:   1840, Loss function: 3.707, Average Loss: 4.446, avg. samples / sec: 66442.88
Iteration:   1840, Loss function: 6.195, Average Loss: 4.438, avg. samples / sec: 66260.88
Iteration:   1840, Loss function: 5.079, Average Loss: 4.452, avg. samples / sec: 66378.95
Iteration:   1840, Loss function: 4.098, Average Loss: 4.459, avg. samples / sec: 66249.26
Iteration:   1840, Loss function: 4.452, Average Loss: 4.414, avg. samples / sec: 66264.31
Iteration:   1840, Loss function: 3.363, Average Loss: 4.464, avg. samples / sec: 66107.96
Iteration:   1840, Loss function: 5.125, Average Loss: 4.443, avg. samples / sec: 66197.26
Iteration:   1840, Loss function: 4.489, Average Loss: 4.480, avg. samples / sec: 66268.67
Iteration:   1860, Loss function: 3.573, Average Loss: 4.442, avg. samples / sec: 66548.90
Iteration:   1860, Loss function: 4.987, Average Loss: 4.468, avg. samples / sec: 66448.96
Iteration:   1860, Loss function: 2.807, Average Loss: 4.437, avg. samples / sec: 66558.68
Iteration:   1860, Loss function: 3.354, Average Loss: 4.441, avg. samples / sec: 66433.58
Iteration:   1860, Loss function: 3.877, Average Loss: 4.436, avg. samples / sec: 66508.07
Iteration:   1860, Loss function: 3.599, Average Loss: 4.449, avg. samples / sec: 66457.42
Iteration:   1860, Loss function: 3.516, Average Loss: 4.466, avg. samples / sec: 66415.61
Iteration:   1860, Loss function: 3.745, Average Loss: 4.479, avg. samples / sec: 66468.14
Iteration:   1860, Loss function: 4.285, Average Loss: 4.451, avg. samples / sec: 66394.33
Iteration:   1860, Loss function: 4.382, Average Loss: 4.442, avg. samples / sec: 66379.61
Iteration:   1860, Loss function: 4.176, Average Loss: 4.462, avg. samples / sec: 66372.73
Iteration:   1860, Loss function: 3.106, Average Loss: 4.456, avg. samples / sec: 66360.51
Iteration:   1860, Loss function: 4.595, Average Loss: 4.452, avg. samples / sec: 66456.33
Iteration:   1860, Loss function: 5.103, Average Loss: 4.428, avg. samples / sec: 66429.64
Iteration:   1860, Loss function: 5.227, Average Loss: 4.475, avg. samples / sec: 66346.73
Iteration:   1860, Loss function: 4.519, Average Loss: 4.412, avg. samples / sec: 66458.46
Iteration:   1860, Loss function: 4.306, Average Loss: 4.462, avg. samples / sec: 66396.81
Iteration:   1860, Loss function: 4.557, Average Loss: 4.466, avg. samples / sec: 66369.13
Iteration:   1860, Loss function: 4.404, Average Loss: 4.441, avg. samples / sec: 66290.40
Iteration:   1860, Loss function: 4.880, Average Loss: 4.449, avg. samples / sec: 66373.88
Iteration:   1860, Loss function: 4.261, Average Loss: 4.443, avg. samples / sec: 66386.48
Iteration:   1860, Loss function: 4.670, Average Loss: 4.477, avg. samples / sec: 66325.90
Iteration:   1860, Loss function: 3.936, Average Loss: 4.445, avg. samples / sec: 66296.20
Iteration:   1860, Loss function: 3.169, Average Loss: 4.468, avg. samples / sec: 66353.73
Iteration:   1860, Loss function: 3.904, Average Loss: 4.475, avg. samples / sec: 66511.21
Iteration:   1860, Loss function: 4.993, Average Loss: 4.447, avg. samples / sec: 66302.16
Iteration:   1860, Loss function: 3.679, Average Loss: 4.442, avg. samples / sec: 66465.95
Iteration:   1860, Loss function: 4.647, Average Loss: 4.485, avg. samples / sec: 66308.43
Iteration:   1860, Loss function: 4.558, Average Loss: 4.459, avg. samples / sec: 66403.84
Iteration:   1860, Loss function: 5.145, Average Loss: 4.455, avg. samples / sec: 66310.92
Iteration:   1880, Loss function: 4.247, Average Loss: 4.435, avg. samples / sec: 66461.81
Iteration:   1880, Loss function: 3.607, Average Loss: 4.440, avg. samples / sec: 66527.79
Iteration:   1880, Loss function: 4.281, Average Loss: 4.451, avg. samples / sec: 66519.72
Iteration:   1880, Loss function: 3.970, Average Loss: 4.449, avg. samples / sec: 66447.55
Iteration:   1880, Loss function: 3.702, Average Loss: 4.469, avg. samples / sec: 66557.89
Iteration:   1880, Loss function: 3.921, Average Loss: 4.434, avg. samples / sec: 66408.69
Iteration:   1880, Loss function: 4.295, Average Loss: 4.442, avg. samples / sec: 66482.66
Iteration:   1880, Loss function: 4.168, Average Loss: 4.439, avg. samples / sec: 66372.88
Iteration:   1880, Loss function: 4.569, Average Loss: 4.469, avg. samples / sec: 66559.27
Iteration:   1880, Loss function: 6.253, Average Loss: 4.447, avg. samples / sec: 66561.82
Iteration:   1880, Loss function: 4.098, Average Loss: 4.435, avg. samples / sec: 66402.37
Iteration:   1880, Loss function: 5.105, Average Loss: 4.468, avg. samples / sec: 66363.32
Iteration:   1880, Loss function: 4.375, Average Loss: 4.450, avg. samples / sec: 66503.65
Iteration:   1880, Loss function: 3.832, Average Loss: 4.468, avg. samples / sec: 66549.31
Iteration:   1880, Loss function: 4.766, Average Loss: 4.458, avg. samples / sec: 66426.82
Iteration:   1880, Loss function: 3.306, Average Loss: 4.411, avg. samples / sec: 66458.65
Iteration:   1880, Loss function: 4.018, Average Loss: 4.450, avg. samples / sec: 66601.14
Iteration:   1880, Loss function: 5.026, Average Loss: 4.426, avg. samples / sec: 66444.55
Iteration:   1880, Loss function: 4.960, Average Loss: 4.477, avg. samples / sec: 66393.11
Iteration:   1880, Loss function: 5.336, Average Loss: 4.441, avg. samples / sec: 66520.22
Iteration:   1880, Loss function: 3.327, Average Loss: 4.460, avg. samples / sec: 66371.07
Iteration:   1880, Loss function: 3.787, Average Loss: 4.476, avg. samples / sec: 66474.85
Iteration:   1880, Loss function: 4.138, Average Loss: 4.481, avg. samples / sec: 66522.42
Iteration:   1880, Loss function: 3.991, Average Loss: 4.440, avg. samples / sec: 66445.55
Iteration:   1880, Loss function: 4.798, Average Loss: 4.440, avg. samples / sec: 66454.16
Iteration:   1880, Loss function: 4.415, Average Loss: 4.458, avg. samples / sec: 66411.48
Iteration:   1880, Loss function: 4.646, Average Loss: 4.474, avg. samples / sec: 66404.78
Iteration:   1880, Loss function: 3.502, Average Loss: 4.443, avg. samples / sec: 66498.60
Iteration:   1880, Loss function: 4.483, Average Loss: 4.454, avg. samples / sec: 66533.73
Iteration:   1880, Loss function: 4.818, Average Loss: 4.453, avg. samples / sec: 66345.48
:::MLL 1558651738.957 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558651738.958 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 3.267, Average Loss: 4.437, avg. samples / sec: 66159.72
Iteration:   1900, Loss function: 3.030, Average Loss: 4.443, avg. samples / sec: 66030.21
Iteration:   1900, Loss function: 3.371, Average Loss: 4.439, avg. samples / sec: 66101.82
Iteration:   1900, Loss function: 4.008, Average Loss: 4.466, avg. samples / sec: 66031.51
Iteration:   1900, Loss function: 3.553, Average Loss: 4.435, avg. samples / sec: 65950.00
Iteration:   1900, Loss function: 4.512, Average Loss: 4.466, avg. samples / sec: 66025.26
Iteration:   1900, Loss function: 3.854, Average Loss: 4.459, avg. samples / sec: 66067.64
Iteration:   1900, Loss function: 4.547, Average Loss: 4.435, avg. samples / sec: 65983.25
Iteration:   1900, Loss function: 4.724, Average Loss: 4.452, avg. samples / sec: 66027.80
Iteration:   1900, Loss function: 3.237, Average Loss: 4.435, avg. samples / sec: 65967.72
Iteration:   1900, Loss function: 2.641, Average Loss: 4.468, avg. samples / sec: 66083.87
Iteration:   1900, Loss function: 3.852, Average Loss: 4.469, avg. samples / sec: 65937.31
Iteration:   1900, Loss function: 3.921, Average Loss: 4.439, avg. samples / sec: 66090.29
Iteration:   1900, Loss function: 5.076, Average Loss: 4.438, avg. samples / sec: 65953.76
Iteration:   1900, Loss function: 4.164, Average Loss: 4.419, avg. samples / sec: 66015.52
Iteration:   1900, Loss function: 3.458, Average Loss: 4.441, avg. samples / sec: 66051.35
Iteration:   1900, Loss function: 4.138, Average Loss: 4.429, avg. samples / sec: 65968.46
Iteration:   1900, Loss function: 4.116, Average Loss: 4.475, avg. samples / sec: 66014.01
Iteration:   1900, Loss function: 4.477, Average Loss: 4.446, avg. samples / sec: 66034.70
Iteration:   1900, Loss function: 5.622, Average Loss: 4.472, avg. samples / sec: 65996.72
Iteration:   1900, Loss function: 4.323, Average Loss: 4.473, avg. samples / sec: 65993.94
Iteration:   1900, Loss function: 4.763, Average Loss: 4.452, avg. samples / sec: 65873.52
Iteration:   1900, Loss function: 5.002, Average Loss: 4.448, avg. samples / sec: 66034.64
Iteration:   1900, Loss function: 3.966, Average Loss: 4.447, avg. samples / sec: 66048.01
Iteration:   1900, Loss function: 3.943, Average Loss: 4.411, avg. samples / sec: 65924.02
Iteration:   1900, Loss function: 4.891, Average Loss: 4.445, avg. samples / sec: 65904.54
Iteration:   1900, Loss function: 4.429, Average Loss: 4.435, avg. samples / sec: 65795.74
Iteration:   1900, Loss function: 4.896, Average Loss: 4.441, avg. samples / sec: 65851.75
Iteration:   1900, Loss function: 3.314, Average Loss: 4.464, avg. samples / sec: 65850.77
Iteration:   1900, Loss function: 3.449, Average Loss: 4.451, avg. samples / sec: 65858.56
Iteration:   1920, Loss function: 4.477, Average Loss: 4.464, avg. samples / sec: 66557.64
Iteration:   1920, Loss function: 5.220, Average Loss: 4.434, avg. samples / sec: 66562.29
Iteration:   1920, Loss function: 4.375, Average Loss: 4.461, avg. samples / sec: 66493.39
Iteration:   1920, Loss function: 5.896, Average Loss: 4.435, avg. samples / sec: 66525.72
Iteration:   1920, Loss function: 4.477, Average Loss: 4.471, avg. samples / sec: 66566.91
Iteration:   1920, Loss function: 5.636, Average Loss: 4.430, avg. samples / sec: 66491.19
Iteration:   1920, Loss function: 4.781, Average Loss: 4.434, avg. samples / sec: 66394.40
Iteration:   1920, Loss function: 5.748, Average Loss: 4.450, avg. samples / sec: 66549.44
Iteration:   1920, Loss function: 5.730, Average Loss: 4.437, avg. samples / sec: 66599.00
Iteration:   1920, Loss function: 4.491, Average Loss: 4.415, avg. samples / sec: 66476.04
Iteration:   1920, Loss function: 4.348, Average Loss: 4.471, avg. samples / sec: 66477.86
Iteration:   1920, Loss function: 3.760, Average Loss: 4.438, avg. samples / sec: 66344.01
Iteration:   1920, Loss function: 3.835, Average Loss: 4.433, avg. samples / sec: 66563.33
Iteration:   1920, Loss function: 3.273, Average Loss: 4.435, avg. samples / sec: 66470.46
Iteration:   1920, Loss function: 4.924, Average Loss: 4.463, avg. samples / sec: 66377.01
Iteration:   1920, Loss function: 5.605, Average Loss: 4.467, avg. samples / sec: 66423.19
Iteration:   1920, Loss function: 3.663, Average Loss: 4.438, avg. samples / sec: 66340.55
Iteration:   1920, Loss function: 4.419, Average Loss: 4.433, avg. samples / sec: 66406.60
Iteration:   1920, Loss function: 4.453, Average Loss: 4.437, avg. samples / sec: 66456.48
Iteration:   1920, Loss function: 4.186, Average Loss: 4.433, avg. samples / sec: 66376.01
Iteration:   1920, Loss function: 4.724, Average Loss: 4.442, avg. samples / sec: 66496.71
Iteration:   1920, Loss function: 3.505, Average Loss: 4.444, avg. samples / sec: 66566.25
Iteration:   1920, Loss function: 4.916, Average Loss: 4.461, avg. samples / sec: 66540.17
Iteration:   1920, Loss function: 4.008, Average Loss: 4.472, avg. samples / sec: 66404.60
Iteration:   1920, Loss function: 3.721, Average Loss: 4.448, avg. samples / sec: 66347.17
Iteration:   1920, Loss function: 3.701, Average Loss: 4.445, avg. samples / sec: 66420.71
Iteration:   1920, Loss function: 4.848, Average Loss: 4.412, avg. samples / sec: 66469.40
Iteration:   1920, Loss function: 2.988, Average Loss: 4.424, avg. samples / sec: 66351.38
Iteration:   1920, Loss function: 3.642, Average Loss: 4.465, avg. samples / sec: 66317.16
Iteration:   1920, Loss function: 3.355, Average Loss: 4.444, avg. samples / sec: 66381.32
Iteration:   1940, Loss function: 3.041, Average Loss: 4.429, avg. samples / sec: 66782.96
Iteration:   1940, Loss function: 4.441, Average Loss: 4.450, avg. samples / sec: 66636.32
Iteration:   1940, Loss function: 4.031, Average Loss: 4.434, avg. samples / sec: 66554.62
Iteration:   1940, Loss function: 4.210, Average Loss: 4.432, avg. samples / sec: 66615.06
Iteration:   1940, Loss function: 4.307, Average Loss: 4.460, avg. samples / sec: 66482.03
Iteration:   1940, Loss function: 3.759, Average Loss: 4.427, avg. samples / sec: 66528.98
Iteration:   1940, Loss function: 3.738, Average Loss: 4.461, avg. samples / sec: 66724.50
Iteration:   1940, Loss function: 4.778, Average Loss: 4.475, avg. samples / sec: 66673.23
Iteration:   1940, Loss function: 3.490, Average Loss: 4.467, avg. samples / sec: 66522.04
Iteration:   1940, Loss function: 4.600, Average Loss: 4.456, avg. samples / sec: 66613.20
Iteration:   1940, Loss function: 4.091, Average Loss: 4.446, avg. samples / sec: 66663.30
Iteration:   1940, Loss function: 4.355, Average Loss: 4.453, avg. samples / sec: 66481.88
Iteration:   1940, Loss function: 4.308, Average Loss: 4.432, avg. samples / sec: 66595.41
Iteration:   1940, Loss function: 4.257, Average Loss: 4.431, avg. samples / sec: 66563.27
Iteration:   1940, Loss function: 4.224, Average Loss: 4.429, avg. samples / sec: 66477.30
Iteration:   1940, Loss function: 3.971, Average Loss: 4.434, avg. samples / sec: 66531.03
Iteration:   1940, Loss function: 3.641, Average Loss: 4.429, avg. samples / sec: 66470.96
Iteration:   1940, Loss function: 5.120, Average Loss: 4.436, avg. samples / sec: 66547.96
Iteration:   1940, Loss function: 5.589, Average Loss: 4.423, avg. samples / sec: 66602.72
Iteration:   1940, Loss function: 5.704, Average Loss: 4.412, avg. samples / sec: 66575.62
Iteration:   1940, Loss function: 5.416, Average Loss: 4.433, avg. samples / sec: 66466.45
Iteration:   1940, Loss function: 3.819, Average Loss: 4.440, avg. samples / sec: 66613.54
Iteration:   1940, Loss function: 3.021, Average Loss: 4.465, avg. samples / sec: 66453.82
Iteration:   1940, Loss function: 4.460, Average Loss: 4.443, avg. samples / sec: 66507.98
Iteration:   1940, Loss function: 3.614, Average Loss: 4.416, avg. samples / sec: 66431.33
Iteration:   1940, Loss function: 4.680, Average Loss: 4.427, avg. samples / sec: 66469.80
Iteration:   1940, Loss function: 5.332, Average Loss: 4.461, avg. samples / sec: 66499.26
Iteration:   1940, Loss function: 4.040, Average Loss: 4.444, avg. samples / sec: 66451.16
Iteration:   1940, Loss function: 4.404, Average Loss: 4.436, avg. samples / sec: 66490.16
Iteration:   1940, Loss function: 3.640, Average Loss: 4.462, avg. samples / sec: 66362.69
:::MLL 1558651740.728 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558651740.729 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.428, Average Loss: 4.428, avg. samples / sec: 66390.24
Iteration:   1960, Loss function: 5.215, Average Loss: 4.429, avg. samples / sec: 66374.10
Iteration:   1960, Loss function: 4.938, Average Loss: 4.442, avg. samples / sec: 66464.32
Iteration:   1960, Loss function: 3.550, Average Loss: 4.465, avg. samples / sec: 66328.56
Iteration:   1960, Loss function: 5.374, Average Loss: 4.436, avg. samples / sec: 66375.13
Iteration:   1960, Loss function: 4.753, Average Loss: 4.443, avg. samples / sec: 66281.11
Iteration:   1960, Loss function: 3.304, Average Loss: 4.422, avg. samples / sec: 66112.52
Iteration:   1960, Loss function: 3.617, Average Loss: 4.455, avg. samples / sec: 66262.75
Iteration:   1960, Loss function: 3.833, Average Loss: 4.454, avg. samples / sec: 66218.63
Iteration:   1960, Loss function: 3.543, Average Loss: 4.452, avg. samples / sec: 66181.19
Iteration:   1960, Loss function: 4.014, Average Loss: 4.420, avg. samples / sec: 66175.69
Iteration:   1960, Loss function: 3.451, Average Loss: 4.409, avg. samples / sec: 66311.42
Iteration:   1960, Loss function: 3.885, Average Loss: 4.462, avg. samples / sec: 66339.83
Iteration:   1960, Loss function: 4.666, Average Loss: 4.421, avg. samples / sec: 66298.88
Iteration:   1960, Loss function: 4.356, Average Loss: 4.428, avg. samples / sec: 66161.40
Iteration:   1960, Loss function: 3.937, Average Loss: 4.427, avg. samples / sec: 66214.81
Iteration:   1960, Loss function: 5.120, Average Loss: 4.434, avg. samples / sec: 66231.08
Iteration:   1960, Loss function: 4.157, Average Loss: 4.442, avg. samples / sec: 66095.40
Iteration:   1960, Loss function: 5.812, Average Loss: 4.430, avg. samples / sec: 66199.72
Iteration:   1960, Loss function: 5.439, Average Loss: 4.459, avg. samples / sec: 66320.75
Iteration:   1960, Loss function: 4.642, Average Loss: 4.441, avg. samples / sec: 66353.63
Iteration:   1960, Loss function: 4.307, Average Loss: 4.431, avg. samples / sec: 66280.02
Iteration:   1960, Loss function: 3.651, Average Loss: 4.432, avg. samples / sec: 66357.10
Iteration:   1960, Loss function: 4.646, Average Loss: 4.471, avg. samples / sec: 66136.44
Iteration:   1960, Loss function: 4.437, Average Loss: 4.460, avg. samples / sec: 66122.47
Iteration:   1960, Loss function: 4.400, Average Loss: 4.410, avg. samples / sec: 66250.23
Iteration:   1960, Loss function: 4.900, Average Loss: 4.437, avg. samples / sec: 66218.48
Iteration:   1960, Loss function: 2.924, Average Loss: 4.455, avg. samples / sec: 66295.86
Iteration:   1960, Loss function: 4.876, Average Loss: 4.425, avg. samples / sec: 66131.53
Iteration:   1960, Loss function: 4.198, Average Loss: 4.425, avg. samples / sec: 65870.62
Iteration:   1980, Loss function: 4.971, Average Loss: 4.437, avg. samples / sec: 66091.87
Iteration:   1980, Loss function: 4.279, Average Loss: 4.429, avg. samples / sec: 66184.05
Iteration:   1980, Loss function: 3.888, Average Loss: 4.449, avg. samples / sec: 66149.88
Iteration:   1980, Loss function: 3.570, Average Loss: 4.448, avg. samples / sec: 66162.05
Iteration:   1980, Loss function: 4.294, Average Loss: 4.431, avg. samples / sec: 66023.72
Iteration:   1980, Loss function: 4.643, Average Loss: 4.426, avg. samples / sec: 66167.49
Iteration:   1980, Loss function: 4.036, Average Loss: 4.428, avg. samples / sec: 65995.49
Iteration:   1980, Loss function: 5.916, Average Loss: 4.426, avg. samples / sec: 66167.52
Iteration:   1980, Loss function: 3.724, Average Loss: 4.450, avg. samples / sec: 66111.96
Iteration:   1980, Loss function: 3.431, Average Loss: 4.437, avg. samples / sec: 66164.91
Iteration:   1980, Loss function: 5.617, Average Loss: 4.409, avg. samples / sec: 66213.87
Iteration:   1980, Loss function: 3.123, Average Loss: 4.466, avg. samples / sec: 66187.60
Iteration:   1980, Loss function: 3.849, Average Loss: 4.435, avg. samples / sec: 66020.10
Iteration:   1980, Loss function: 4.160, Average Loss: 4.467, avg. samples / sec: 65991.29
Iteration:   1980, Loss function: 4.086, Average Loss: 4.436, avg. samples / sec: 66049.15
Iteration:   1980, Loss function: 4.571, Average Loss: 4.416, avg. samples / sec: 66081.42
Iteration:   1980, Loss function: 4.271, Average Loss: 4.412, avg. samples / sec: 66052.19
Iteration:   1980, Loss function: 4.362, Average Loss: 4.436, avg. samples / sec: 66109.04
Iteration:   1980, Loss function: 3.861, Average Loss: 4.417, avg. samples / sec: 66013.82
Iteration:   1980, Loss function: 3.970, Average Loss: 4.454, avg. samples / sec: 66104.76
Iteration:   1980, Loss function: 4.155, Average Loss: 4.459, avg. samples / sec: 66016.76
Iteration:   1980, Loss function: 4.533, Average Loss: 4.433, avg. samples / sec: 66065.72
Iteration:   1980, Loss function: 5.072, Average Loss: 4.433, avg. samples / sec: 66103.99
Iteration:   1980, Loss function: 3.789, Average Loss: 4.409, avg. samples / sec: 66000.16
Iteration:   1980, Loss function: 4.159, Average Loss: 4.433, avg. samples / sec: 66021.00
Iteration:   1980, Loss function: 4.989, Average Loss: 4.452, avg. samples / sec: 66159.63
Iteration:   1980, Loss function: 3.995, Average Loss: 4.454, avg. samples / sec: 66024.65
Iteration:   1980, Loss function: 4.026, Average Loss: 4.420, avg. samples / sec: 66272.94
Iteration:   1980, Loss function: 4.810, Average Loss: 4.425, avg. samples / sec: 65993.54
Iteration:   1980, Loss function: 5.160, Average Loss: 4.422, avg. samples / sec: 66148.17
Iteration:   2000, Loss function: 4.079, Average Loss: 4.430, avg. samples / sec: 66423.72
Iteration:   2000, Loss function: 3.104, Average Loss: 4.429, avg. samples / sec: 66422.47
Iteration:   2000, Loss function: 3.269, Average Loss: 4.409, avg. samples / sec: 66450.22
Iteration:   2000, Loss function: 5.677, Average Loss: 4.415, avg. samples / sec: 66412.14
Iteration:   2000, Loss function: 3.543, Average Loss: 4.444, avg. samples / sec: 66295.67
Iteration:   2000, Loss function: 3.708, Average Loss: 4.408, avg. samples / sec: 66321.56
Iteration:   2000, Loss function: 4.515, Average Loss: 4.464, avg. samples / sec: 66337.67
Iteration:   2000, Loss function: 4.120, Average Loss: 4.428, avg. samples / sec: 66253.72
Iteration:   2000, Loss function: 3.522, Average Loss: 4.417, avg. samples / sec: 66452.38
Iteration:   2000, Loss function: 5.062, Average Loss: 4.445, avg. samples / sec: 66248.36
Iteration:   2000, Loss function: 4.552, Average Loss: 4.446, avg. samples / sec: 66431.20
Iteration:   2000, Loss function: 4.330, Average Loss: 4.449, avg. samples / sec: 66303.56
Iteration:   2000, Loss function: 4.322, Average Loss: 4.433, avg. samples / sec: 66298.66
Iteration:   2000, Loss function: 3.558, Average Loss: 4.428, avg. samples / sec: 66273.07
Iteration:   2000, Loss function: 4.550, Average Loss: 4.459, avg. samples / sec: 66276.34
Iteration:   2000, Loss function: 3.992, Average Loss: 4.426, avg. samples / sec: 66401.69
Iteration:   2000, Loss function: 4.405, Average Loss: 4.437, avg. samples / sec: 66205.07
Iteration:   2000, Loss function: 3.406, Average Loss: 4.401, avg. samples / sec: 66395.43
Iteration:   2000, Loss function: 4.475, Average Loss: 4.431, avg. samples / sec: 66254.15
Iteration:   2000, Loss function: 4.246, Average Loss: 4.419, avg. samples / sec: 66427.88
Iteration:   2000, Loss function: 4.133, Average Loss: 4.455, avg. samples / sec: 66317.66
Iteration:   2000, Loss function: 5.473, Average Loss: 4.420, avg. samples / sec: 66416.83
Iteration:   2000, Loss function: 5.049, Average Loss: 4.432, avg. samples / sec: 66257.95
Iteration:   2000, Loss function: 2.628, Average Loss: 4.450, avg. samples / sec: 66286.84
Iteration:   2000, Loss function: 4.959, Average Loss: 4.410, avg. samples / sec: 66229.15
Iteration:   2000, Loss function: 4.766, Average Loss: 4.429, avg. samples / sec: 66312.48
Iteration:   2000, Loss function: 4.814, Average Loss: 4.419, avg. samples / sec: 66140.35
Iteration:   2000, Loss function: 3.505, Average Loss: 4.432, avg. samples / sec: 66259.61
Iteration:   2000, Loss function: 4.682, Average Loss: 4.413, avg. samples / sec: 66080.06
Iteration:   2000, Loss function: 4.171, Average Loss: 4.450, avg. samples / sec: 66228.25
Iteration:   2020, Loss function: 5.440, Average Loss: 4.397, avg. samples / sec: 66743.84
Iteration:   2020, Loss function: 3.858, Average Loss: 4.436, avg. samples / sec: 66638.27
Iteration:   2020, Loss function: 4.155, Average Loss: 4.427, avg. samples / sec: 66659.99
Iteration:   2020, Loss function: 4.017, Average Loss: 4.436, avg. samples / sec: 66641.67
Iteration:   2020, Loss function: 4.131, Average Loss: 4.427, avg. samples / sec: 66514.42
Iteration:   2020, Loss function: 4.059, Average Loss: 4.417, avg. samples / sec: 66579.93
Iteration:   2020, Loss function: 6.244, Average Loss: 4.422, avg. samples / sec: 66753.13
Iteration:   2020, Loss function: 4.675, Average Loss: 4.460, avg. samples / sec: 66595.95
Iteration:   2020, Loss function: 3.654, Average Loss: 4.435, avg. samples / sec: 66635.50
Iteration:   2020, Loss function: 4.497, Average Loss: 4.421, avg. samples / sec: 66577.83
Iteration:   2020, Loss function: 4.647, Average Loss: 4.408, avg. samples / sec: 66509.64
Iteration:   2020, Loss function: 4.824, Average Loss: 4.406, avg. samples / sec: 66702.68
Iteration:   2020, Loss function: 4.704, Average Loss: 4.410, avg. samples / sec: 66581.92
Iteration:   2020, Loss function: 3.493, Average Loss: 4.423, avg. samples / sec: 66468.58
Iteration:   2020, Loss function: 4.145, Average Loss: 4.448, avg. samples / sec: 66674.81
Iteration:   2020, Loss function: 3.855, Average Loss: 4.430, avg. samples / sec: 66562.76
Iteration:   2020, Loss function: 4.950, Average Loss: 4.457, avg. samples / sec: 66655.16
Iteration:   2020, Loss function: 4.057, Average Loss: 4.419, avg. samples / sec: 66618.65
Iteration:   2020, Loss function: 4.405, Average Loss: 4.427, avg. samples / sec: 66715.18
Iteration:   2020, Loss function: 4.979, Average Loss: 4.425, avg. samples / sec: 66659.17
Iteration:   2020, Loss function: 3.422, Average Loss: 4.414, avg. samples / sec: 66539.82
Iteration:   2020, Loss function: 4.071, Average Loss: 4.440, avg. samples / sec: 66526.10
Iteration:   2020, Loss function: 4.991, Average Loss: 4.407, avg. samples / sec: 66480.94
Iteration:   2020, Loss function: 3.974, Average Loss: 4.446, avg. samples / sec: 66486.49
Iteration:   2020, Loss function: 4.679, Average Loss: 4.442, avg. samples / sec: 66700.72
Iteration:   2020, Loss function: 3.335, Average Loss: 4.410, avg. samples / sec: 66693.30
Iteration:   2020, Loss function: 3.522, Average Loss: 4.458, avg. samples / sec: 66510.84
Iteration:   2020, Loss function: 4.390, Average Loss: 4.426, avg. samples / sec: 66514.82
Iteration:   2020, Loss function: 3.833, Average Loss: 4.413, avg. samples / sec: 66550.35
Iteration:   2020, Loss function: 4.729, Average Loss: 4.428, avg. samples / sec: 66458.52
:::MLL 1558651742.503 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558651742.503 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 4.355, Average Loss: 4.414, avg. samples / sec: 66344.23
Iteration:   2040, Loss function: 3.677, Average Loss: 4.430, avg. samples / sec: 66175.57
Iteration:   2040, Loss function: 3.623, Average Loss: 4.429, avg. samples / sec: 66241.95
Iteration:   2040, Loss function: 5.754, Average Loss: 4.453, avg. samples / sec: 66380.64
Iteration:   2040, Loss function: 4.170, Average Loss: 4.422, avg. samples / sec: 66516.27
Iteration:   2040, Loss function: 4.113, Average Loss: 4.408, avg. samples / sec: 66207.22
Iteration:   2040, Loss function: 3.894, Average Loss: 4.439, avg. samples / sec: 66305.34
Iteration:   2040, Loss function: 4.799, Average Loss: 4.401, avg. samples / sec: 66240.17
Iteration:   2040, Loss function: 4.923, Average Loss: 4.395, avg. samples / sec: 66114.75
Iteration:   2040, Loss function: 5.104, Average Loss: 4.413, avg. samples / sec: 66231.05
Iteration:   2040, Loss function: 4.909, Average Loss: 4.423, avg. samples / sec: 66163.02
Iteration:   2040, Loss function: 3.275, Average Loss: 4.396, avg. samples / sec: 66232.14
Iteration:   2040, Loss function: 3.553, Average Loss: 4.410, avg. samples / sec: 66299.82
Iteration:   2040, Loss function: 4.740, Average Loss: 4.458, avg. samples / sec: 66190.77
Iteration:   2040, Loss function: 5.279, Average Loss: 4.407, avg. samples / sec: 66296.73
Iteration:   2040, Loss function: 4.789, Average Loss: 4.422, avg. samples / sec: 66230.86
Iteration:   2040, Loss function: 4.721, Average Loss: 4.430, avg. samples / sec: 66147.74
Iteration:   2040, Loss function: 3.431, Average Loss: 4.426, avg. samples / sec: 66119.84
Iteration:   2040, Loss function: 5.189, Average Loss: 4.420, avg. samples / sec: 66176.56
Iteration:   2040, Loss function: 5.448, Average Loss: 4.439, avg. samples / sec: 66255.99
Iteration:   2040, Loss function: 2.738, Average Loss: 4.404, avg. samples / sec: 66137.56
Iteration:   2040, Loss function: 4.731, Average Loss: 4.424, avg. samples / sec: 66147.02
Iteration:   2040, Loss function: 6.127, Average Loss: 4.423, avg. samples / sec: 66147.21
Iteration:   2040, Loss function: 4.287, Average Loss: 4.422, avg. samples / sec: 66236.03
Iteration:   2040, Loss function: 4.878, Average Loss: 4.409, avg. samples / sec: 66211.20
Iteration:   2040, Loss function: 4.143, Average Loss: 4.417, avg. samples / sec: 66125.70
Iteration:   2040, Loss function: 4.680, Average Loss: 4.408, avg. samples / sec: 66230.80
Iteration:   2040, Loss function: 4.645, Average Loss: 4.451, avg. samples / sec: 66095.25
Iteration:   2040, Loss function: 3.345, Average Loss: 4.442, avg. samples / sec: 66140.47
Iteration:   2040, Loss function: 4.730, Average Loss: 4.444, avg. samples / sec: 66053.61
Iteration:   2060, Loss function: 4.460, Average Loss: 4.410, avg. samples / sec: 66498.28
Iteration:   2060, Loss function: 4.655, Average Loss: 4.428, avg. samples / sec: 66424.35
Iteration:   2060, Loss function: 3.121, Average Loss: 4.410, avg. samples / sec: 66314.26
Iteration:   2060, Loss function: 5.122, Average Loss: 4.404, avg. samples / sec: 66421.68
Iteration:   2060, Loss function: 5.085, Average Loss: 4.421, avg. samples / sec: 66485.58
Iteration:   2060, Loss function: 4.410, Average Loss: 4.451, avg. samples / sec: 66388.74
Iteration:   2060, Loss function: 5.272, Average Loss: 4.418, avg. samples / sec: 66425.41
Iteration:   2060, Loss function: 3.958, Average Loss: 4.425, avg. samples / sec: 66440.79
Iteration:   2060, Loss function: 5.197, Average Loss: 4.406, avg. samples / sec: 66401.19
Iteration:   2060, Loss function: 4.976, Average Loss: 4.404, avg. samples / sec: 66525.78
Iteration:   2060, Loss function: 3.308, Average Loss: 4.418, avg. samples / sec: 66341.64
Iteration:   2060, Loss function: 3.893, Average Loss: 4.420, avg. samples / sec: 66427.07
Iteration:   2060, Loss function: 4.726, Average Loss: 4.419, avg. samples / sec: 66490.00
Iteration:   2060, Loss function: 3.315, Average Loss: 4.413, avg. samples / sec: 66375.17
Iteration:   2060, Loss function: 4.492, Average Loss: 4.404, avg. samples / sec: 66376.57
Iteration:   2060, Loss function: 4.060, Average Loss: 4.454, avg. samples / sec: 66343.23
Iteration:   2060, Loss function: 3.630, Average Loss: 4.402, avg. samples / sec: 66437.62
Iteration:   2060, Loss function: 4.642, Average Loss: 4.428, avg. samples / sec: 66298.26
Iteration:   2060, Loss function: 4.055, Average Loss: 4.409, avg. samples / sec: 66434.40
Iteration:   2060, Loss function: 5.883, Average Loss: 4.446, avg. samples / sec: 66515.20
Iteration:   2060, Loss function: 4.161, Average Loss: 4.433, avg. samples / sec: 66392.61
Iteration:   2060, Loss function: 3.552, Average Loss: 4.410, avg. samples / sec: 66427.01
Iteration:   2060, Loss function: 4.181, Average Loss: 4.402, avg. samples / sec: 66253.87
Iteration:   2060, Loss function: 5.238, Average Loss: 4.438, avg. samples / sec: 66447.21
Iteration:   2060, Loss function: 5.061, Average Loss: 4.393, avg. samples / sec: 66263.72
Iteration:   2060, Loss function: 4.647, Average Loss: 4.444, avg. samples / sec: 66415.14
Iteration:   2060, Loss function: 4.614, Average Loss: 4.424, avg. samples / sec: 66346.92
Iteration:   2060, Loss function: 4.211, Average Loss: 4.438, avg. samples / sec: 66187.41
Iteration:   2060, Loss function: 4.946, Average Loss: 4.396, avg. samples / sec: 66150.53
Iteration:   2060, Loss function: 3.540, Average Loss: 4.420, avg. samples / sec: 66244.34
Iteration:   2080, Loss function: 4.483, Average Loss: 4.446, avg. samples / sec: 66542.62
Iteration:   2080, Loss function: 3.534, Average Loss: 4.407, avg. samples / sec: 66499.48
Iteration:   2080, Loss function: 6.155, Average Loss: 4.428, avg. samples / sec: 66355.66
Iteration:   2080, Loss function: 4.497, Average Loss: 4.398, avg. samples / sec: 66368.73
Iteration:   2080, Loss function: 3.543, Average Loss: 4.406, avg. samples / sec: 66342.08
Iteration:   2080, Loss function: 5.527, Average Loss: 4.425, avg. samples / sec: 66391.99
Iteration:   2080, Loss function: 4.402, Average Loss: 4.414, avg. samples / sec: 66369.63
Iteration:   2080, Loss function: 4.701, Average Loss: 4.397, avg. samples / sec: 66521.17
Iteration:   2080, Loss function: 3.626, Average Loss: 4.417, avg. samples / sec: 66413.11
Iteration:   2080, Loss function: 5.528, Average Loss: 4.446, avg. samples / sec: 66332.05
Iteration:   2080, Loss function: 3.685, Average Loss: 4.414, avg. samples / sec: 66346.70
Iteration:   2080, Loss function: 3.970, Average Loss: 4.397, avg. samples / sec: 66416.77
Iteration:   2080, Loss function: 4.333, Average Loss: 4.395, avg. samples / sec: 66600.17
Iteration:   2080, Loss function: 4.486, Average Loss: 4.432, avg. samples / sec: 66499.82
Iteration:   2080, Loss function: 4.216, Average Loss: 4.402, avg. samples / sec: 66397.37
Iteration:   2080, Loss function: 4.976, Average Loss: 4.407, avg. samples / sec: 66434.37
Iteration:   2080, Loss function: 4.101, Average Loss: 4.409, avg. samples / sec: 66229.03
Iteration:   2080, Loss function: 3.361, Average Loss: 4.391, avg. samples / sec: 66457.92
Iteration:   2080, Loss function: 3.108, Average Loss: 4.419, avg. samples / sec: 66330.18
Iteration:   2080, Loss function: 3.614, Average Loss: 4.401, avg. samples / sec: 66317.79
Iteration:   2080, Loss function: 3.852, Average Loss: 4.410, avg. samples / sec: 66377.64
Iteration:   2080, Loss function: 3.740, Average Loss: 4.441, avg. samples / sec: 66372.10
Iteration:   2080, Loss function: 4.328, Average Loss: 4.423, avg. samples / sec: 66347.85
Iteration:   2080, Loss function: 3.898, Average Loss: 4.418, avg. samples / sec: 66450.65
Iteration:   2080, Loss function: 3.793, Average Loss: 4.419, avg. samples / sec: 66318.63
Iteration:   2080, Loss function: 3.386, Average Loss: 4.435, avg. samples / sec: 66482.19
Iteration:   2080, Loss function: 4.215, Average Loss: 4.441, avg. samples / sec: 66395.68
Iteration:   2080, Loss function: 3.239, Average Loss: 4.399, avg. samples / sec: 66258.73
Iteration:   2080, Loss function: 4.595, Average Loss: 4.411, avg. samples / sec: 66504.18
Iteration:   2080, Loss function: 4.290, Average Loss: 4.432, avg. samples / sec: 66194.56
:::MLL 1558651744.278 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558651744.278 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 3.367, Average Loss: 4.422, avg. samples / sec: 65971.67
Iteration:   2100, Loss function: 4.103, Average Loss: 4.399, avg. samples / sec: 66010.42
Iteration:   2100, Loss function: 4.370, Average Loss: 4.394, avg. samples / sec: 65986.25
Iteration:   2100, Loss function: 4.155, Average Loss: 4.397, avg. samples / sec: 65907.40
Iteration:   2100, Loss function: 4.232, Average Loss: 4.383, avg. samples / sec: 66008.25
Iteration:   2100, Loss function: 4.551, Average Loss: 4.408, avg. samples / sec: 65964.26
Iteration:   2100, Loss function: 4.361, Average Loss: 4.397, avg. samples / sec: 66053.95
Iteration:   2100, Loss function: 3.647, Average Loss: 4.408, avg. samples / sec: 65986.16
Iteration:   2100, Loss function: 4.257, Average Loss: 4.422, avg. samples / sec: 65877.33
Iteration:   2100, Loss function: 3.524, Average Loss: 4.433, avg. samples / sec: 66024.71
Iteration:   2100, Loss function: 2.928, Average Loss: 4.402, avg. samples / sec: 65898.81
Iteration:   2100, Loss function: 4.004, Average Loss: 4.441, avg. samples / sec: 65928.86
Iteration:   2100, Loss function: 4.104, Average Loss: 4.441, avg. samples / sec: 65809.66
Iteration:   2100, Loss function: 4.133, Average Loss: 4.414, avg. samples / sec: 65906.97
Iteration:   2100, Loss function: 4.938, Average Loss: 4.413, avg. samples / sec: 65980.72
Iteration:   2100, Loss function: 4.325, Average Loss: 4.399, avg. samples / sec: 65864.46
Iteration:   2100, Loss function: 4.647, Average Loss: 4.403, avg. samples / sec: 65980.04
Iteration:   2100, Loss function: 5.190, Average Loss: 4.423, avg. samples / sec: 65890.05
Iteration:   2100, Loss function: 4.731, Average Loss: 4.401, avg. samples / sec: 65865.33
Iteration:   2100, Loss function: 4.113, Average Loss: 4.411, avg. samples / sec: 65968.30
Iteration:   2100, Loss function: 4.665, Average Loss: 4.393, avg. samples / sec: 65919.15
Iteration:   2100, Loss function: 4.388, Average Loss: 4.391, avg. samples / sec: 65835.73
Iteration:   2100, Loss function: 3.412, Average Loss: 4.423, avg. samples / sec: 65973.77
Iteration:   2100, Loss function: 3.591, Average Loss: 4.400, avg. samples / sec: 65888.92
Iteration:   2100, Loss function: 5.260, Average Loss: 4.437, avg. samples / sec: 65907.80
Iteration:   2100, Loss function: 3.245, Average Loss: 4.409, avg. samples / sec: 65904.69
Iteration:   2100, Loss function: 4.493, Average Loss: 4.406, avg. samples / sec: 65769.88
Iteration:   2100, Loss function: 2.683, Average Loss: 4.390, avg. samples / sec: 65773.17
Iteration:   2100, Loss function: 4.026, Average Loss: 4.427, avg. samples / sec: 66010.48
Iteration:   2100, Loss function: 4.493, Average Loss: 4.423, avg. samples / sec: 65808.89
Iteration:   2120, Loss function: 5.068, Average Loss: 4.439, avg. samples / sec: 66251.29
Iteration:   2120, Loss function: 4.238, Average Loss: 4.393, avg. samples / sec: 66167.96
Iteration:   2120, Loss function: 4.515, Average Loss: 4.409, avg. samples / sec: 66233.54
Iteration:   2120, Loss function: 5.657, Average Loss: 4.421, avg. samples / sec: 66416.89
Iteration:   2120, Loss function: 4.134, Average Loss: 4.385, avg. samples / sec: 66274.62
Iteration:   2120, Loss function: 3.182, Average Loss: 4.403, avg. samples / sec: 66173.67
Iteration:   2120, Loss function: 4.661, Average Loss: 4.390, avg. samples / sec: 66265.56
Iteration:   2120, Loss function: 4.454, Average Loss: 4.395, avg. samples / sec: 66216.58
Iteration:   2120, Loss function: 2.976, Average Loss: 4.398, avg. samples / sec: 66187.63
Iteration:   2120, Loss function: 4.139, Average Loss: 4.393, avg. samples / sec: 66105.42
Iteration:   2120, Loss function: 4.648, Average Loss: 4.389, avg. samples / sec: 66352.32
Iteration:   2120, Loss function: 4.217, Average Loss: 4.402, avg. samples / sec: 66155.90
Iteration:   2120, Loss function: 4.466, Average Loss: 4.375, avg. samples / sec: 66110.44
Iteration:   2120, Loss function: 4.181, Average Loss: 4.394, avg. samples / sec: 66170.66
Iteration:   2120, Loss function: 4.737, Average Loss: 4.416, avg. samples / sec: 66160.47
Iteration:   2120, Loss function: 4.436, Average Loss: 4.419, avg. samples / sec: 66188.22
Iteration:   2120, Loss function: 5.308, Average Loss: 4.402, avg. samples / sec: 66278.80
Iteration:   2120, Loss function: 3.736, Average Loss: 4.398, avg. samples / sec: 66163.61
Iteration:   2120, Loss function: 3.892, Average Loss: 4.431, avg. samples / sec: 66116.15
Iteration:   2120, Loss function: 4.907, Average Loss: 4.390, avg. samples / sec: 66052.65
Iteration:   2120, Loss function: 4.944, Average Loss: 4.416, avg. samples / sec: 66112.05
Iteration:   2120, Loss function: 5.863, Average Loss: 4.424, avg. samples / sec: 66020.72
Iteration:   2120, Loss function: 4.639, Average Loss: 4.432, avg. samples / sec: 66214.43
Iteration:   2120, Loss function: 3.656, Average Loss: 4.403, avg. samples / sec: 66231.27
Iteration:   2120, Loss function: 3.455, Average Loss: 4.419, avg. samples / sec: 66202.46
Iteration:   2120, Loss function: 4.383, Average Loss: 4.388, avg. samples / sec: 66070.70
Iteration:   2120, Loss function: 4.879, Average Loss: 4.436, avg. samples / sec: 66013.60
Iteration:   2120, Loss function: 4.636, Average Loss: 4.423, avg. samples / sec: 66023.50
Iteration:   2120, Loss function: 5.051, Average Loss: 4.395, avg. samples / sec: 65949.53
Iteration:   2120, Loss function: 5.301, Average Loss: 4.404, avg. samples / sec: 65923.00
Iteration:   2140, Loss function: 3.355, Average Loss: 4.402, avg. samples / sec: 66722.35
Iteration:   2140, Loss function: 5.263, Average Loss: 4.416, avg. samples / sec: 66663.58
Iteration:   2140, Loss function: 3.453, Average Loss: 4.428, avg. samples / sec: 66721.21
Iteration:   2140, Loss function: 4.273, Average Loss: 4.413, avg. samples / sec: 66604.57
Iteration:   2140, Loss function: 4.048, Average Loss: 4.389, avg. samples / sec: 66539.22
Iteration:   2140, Loss function: 3.568, Average Loss: 4.411, avg. samples / sec: 66561.41
Iteration:   2140, Loss function: 3.940, Average Loss: 4.382, avg. samples / sec: 66463.91
Iteration:   2140, Loss function: 4.429, Average Loss: 4.403, avg. samples / sec: 66810.32
Iteration:   2140, Loss function: 3.516, Average Loss: 4.437, avg. samples / sec: 66422.19
Iteration:   2140, Loss function: 3.742, Average Loss: 4.396, avg. samples / sec: 66455.51
Iteration:   2140, Loss function: 3.652, Average Loss: 4.377, avg. samples / sec: 66524.46
Iteration:   2140, Loss function: 5.444, Average Loss: 4.401, avg. samples / sec: 66462.69
Iteration:   2140, Loss function: 4.362, Average Loss: 4.392, avg. samples / sec: 66632.13
Iteration:   2140, Loss function: 4.276, Average Loss: 4.409, avg. samples / sec: 66412.42
Iteration:   2140, Loss function: 4.817, Average Loss: 4.422, avg. samples / sec: 66517.33
Iteration:   2140, Loss function: 3.934, Average Loss: 4.389, avg. samples / sec: 66513.69
Iteration:   2140, Loss function: 4.716, Average Loss: 4.420, avg. samples / sec: 66631.40
Iteration:   2140, Loss function: 4.736, Average Loss: 4.396, avg. samples / sec: 66441.60
Iteration:   2140, Loss function: 4.327, Average Loss: 4.398, avg. samples / sec: 66388.33
Iteration:   2140, Loss function: 5.742, Average Loss: 4.389, avg. samples / sec: 66388.74
Iteration:   2140, Loss function: 4.264, Average Loss: 4.419, avg. samples / sec: 66377.95
Iteration:   2140, Loss function: 5.372, Average Loss: 4.396, avg. samples / sec: 66427.66
Iteration:   2140, Loss function: 3.678, Average Loss: 4.426, avg. samples / sec: 66439.63
Iteration:   2140, Loss function: 5.185, Average Loss: 4.404, avg. samples / sec: 66474.51
Iteration:   2140, Loss function: 5.094, Average Loss: 4.386, avg. samples / sec: 66371.79
Iteration:   2140, Loss function: 3.951, Average Loss: 4.396, avg. samples / sec: 66589.34
Iteration:   2140, Loss function: 4.795, Average Loss: 4.389, avg. samples / sec: 66350.42
Iteration:   2140, Loss function: 4.326, Average Loss: 4.396, avg. samples / sec: 66319.85
Iteration:   2140, Loss function: 5.747, Average Loss: 4.430, avg. samples / sec: 66381.01
Iteration:   2140, Loss function: 4.454, Average Loss: 4.418, avg. samples / sec: 66463.85
Iteration:   2160, Loss function: 3.675, Average Loss: 4.402, avg. samples / sec: 66684.65
Iteration:   2160, Loss function: 4.771, Average Loss: 4.383, avg. samples / sec: 66602.37
Iteration:   2160, Loss function: 4.409, Average Loss: 4.396, avg. samples / sec: 66598.75
Iteration:   2160, Loss function: 3.962, Average Loss: 4.401, avg. samples / sec: 66592.58
Iteration:   2160, Loss function: 3.005, Average Loss: 4.416, avg. samples / sec: 66441.07
Iteration:   2160, Loss function: 5.335, Average Loss: 4.411, avg. samples / sec: 66551.67
Iteration:   2160, Loss function: 3.692, Average Loss: 4.384, avg. samples / sec: 66714.17
Iteration:   2160, Loss function: 4.982, Average Loss: 4.391, avg. samples / sec: 66646.28
Iteration:   2160, Loss function: 3.647, Average Loss: 4.394, avg. samples / sec: 66717.71
Iteration:   2160, Loss function: 3.232, Average Loss: 4.385, avg. samples / sec: 66652.30
Iteration:   2160, Loss function: 3.261, Average Loss: 4.416, avg. samples / sec: 66616.19
Iteration:   2160, Loss function: 4.582, Average Loss: 4.422, avg. samples / sec: 66602.09
Iteration:   2160, Loss function: 4.065, Average Loss: 4.393, avg. samples / sec: 66364.98
Iteration:   2160, Loss function: 3.014, Average Loss: 4.383, avg. samples / sec: 66674.53
Iteration:   2160, Loss function: 4.545, Average Loss: 4.433, avg. samples / sec: 66516.64
Iteration:   2160, Loss function: 3.432, Average Loss: 4.420, avg. samples / sec: 66436.24
Iteration:   2160, Loss function: 2.896, Average Loss: 4.383, avg. samples / sec: 66554.87
Iteration:   2160, Loss function: 4.732, Average Loss: 4.381, avg. samples / sec: 66485.33
Iteration:   2160, Loss function: 4.821, Average Loss: 4.412, avg. samples / sec: 66576.25
Iteration:   2160, Loss function: 3.840, Average Loss: 4.418, avg. samples / sec: 66671.22
Iteration:   2160, Loss function: 4.320, Average Loss: 4.401, avg. samples / sec: 66494.71
Iteration:   2160, Loss function: 3.933, Average Loss: 4.404, avg. samples / sec: 66435.99
Iteration:   2160, Loss function: 3.864, Average Loss: 4.393, avg. samples / sec: 66553.81
Iteration:   2160, Loss function: 4.432, Average Loss: 4.375, avg. samples / sec: 66431.67
Iteration:   2160, Loss function: 4.102, Average Loss: 4.388, avg. samples / sec: 66560.85
Iteration:   2160, Loss function: 4.429, Average Loss: 4.425, avg. samples / sec: 66526.41
Iteration:   2160, Loss function: 4.343, Average Loss: 4.394, avg. samples / sec: 66556.98
Iteration:   2160, Loss function: 4.160, Average Loss: 4.385, avg. samples / sec: 66436.21
Iteration:   2160, Loss function: 3.933, Average Loss: 4.404, avg. samples / sec: 66527.32
Iteration:   2160, Loss function: 6.110, Average Loss: 4.436, avg. samples / sec: 66612.73
:::MLL 1558651746.051 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558651746.051 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 4.841, Average Loss: 4.379, avg. samples / sec: 66203.05
Iteration:   2180, Loss function: 4.731, Average Loss: 4.397, avg. samples / sec: 66269.36
Iteration:   2180, Loss function: 3.454, Average Loss: 4.395, avg. samples / sec: 66134.58
Iteration:   2180, Loss function: 4.299, Average Loss: 4.373, avg. samples / sec: 66148.76
Iteration:   2180, Loss function: 2.980, Average Loss: 4.381, avg. samples / sec: 66105.14
Iteration:   2180, Loss function: 3.408, Average Loss: 4.407, avg. samples / sec: 66216.11
Iteration:   2180, Loss function: 3.750, Average Loss: 4.394, avg. samples / sec: 66132.53
Iteration:   2180, Loss function: 4.398, Average Loss: 4.417, avg. samples / sec: 66264.22
Iteration:   2180, Loss function: 5.042, Average Loss: 4.417, avg. samples / sec: 66128.83
Iteration:   2180, Loss function: 3.613, Average Loss: 4.392, avg. samples / sec: 66195.40
Iteration:   2180, Loss function: 3.803, Average Loss: 4.411, avg. samples / sec: 66050.86
Iteration:   2180, Loss function: 4.021, Average Loss: 4.430, avg. samples / sec: 66220.94
Iteration:   2180, Loss function: 3.824, Average Loss: 4.388, avg. samples / sec: 66197.39
Iteration:   2180, Loss function: 4.534, Average Loss: 4.400, avg. samples / sec: 66206.41
Iteration:   2180, Loss function: 4.561, Average Loss: 4.391, avg. samples / sec: 66045.75
Iteration:   2180, Loss function: 3.243, Average Loss: 4.368, avg. samples / sec: 66152.27
Iteration:   2180, Loss function: 3.626, Average Loss: 4.401, avg. samples / sec: 66012.74
Iteration:   2180, Loss function: 4.721, Average Loss: 4.409, avg. samples / sec: 66106.53
Iteration:   2180, Loss function: 4.312, Average Loss: 4.384, avg. samples / sec: 66104.05
Iteration:   2180, Loss function: 4.917, Average Loss: 4.427, avg. samples / sec: 66070.49
Iteration:   2180, Loss function: 4.388, Average Loss: 4.379, avg. samples / sec: 66161.96
Iteration:   2180, Loss function: 3.871, Average Loss: 4.394, avg. samples / sec: 65943.24
Iteration:   2180, Loss function: 3.272, Average Loss: 4.385, avg. samples / sec: 66024.61
Iteration:   2180, Loss function: 4.421, Average Loss: 4.387, avg. samples / sec: 66102.90
Iteration:   2180, Loss function: 3.488, Average Loss: 4.406, avg. samples / sec: 66028.20
Iteration:   2180, Loss function: 5.407, Average Loss: 4.380, avg. samples / sec: 66058.16
Iteration:   2180, Loss function: 4.532, Average Loss: 4.410, avg. samples / sec: 66061.23
Iteration:   2180, Loss function: 4.001, Average Loss: 4.382, avg. samples / sec: 66069.93
Iteration:   2180, Loss function: 2.227, Average Loss: 4.398, avg. samples / sec: 65914.31
Iteration:   2180, Loss function: 5.108, Average Loss: 4.377, avg. samples / sec: 65848.46
Iteration:   2200, Loss function: 4.927, Average Loss: 4.388, avg. samples / sec: 66504.72
Iteration:   2200, Loss function: 4.642, Average Loss: 4.398, avg. samples / sec: 66419.99
Iteration:   2200, Loss function: 4.228, Average Loss: 4.410, avg. samples / sec: 66487.77
Iteration:   2200, Loss function: 4.599, Average Loss: 4.390, avg. samples / sec: 66537.12
Iteration:   2200, Loss function: 4.808, Average Loss: 4.404, avg. samples / sec: 66504.31
Iteration:   2200, Loss function: 4.692, Average Loss: 4.379, avg. samples / sec: 66545.01
Iteration:   2200, Loss function: 3.527, Average Loss: 4.369, avg. samples / sec: 66380.82
Iteration:   2200, Loss function: 3.784, Average Loss: 4.384, avg. samples / sec: 66480.12
Iteration:   2200, Loss function: 3.686, Average Loss: 4.383, avg. samples / sec: 66461.06
Iteration:   2200, Loss function: 3.575, Average Loss: 4.393, avg. samples / sec: 66324.87
Iteration:   2200, Loss function: 5.258, Average Loss: 4.380, avg. samples / sec: 66508.67
Iteration:   2200, Loss function: 5.161, Average Loss: 4.412, avg. samples / sec: 66333.27
Iteration:   2200, Loss function: 4.323, Average Loss: 4.396, avg. samples / sec: 66433.96
Iteration:   2200, Loss function: 4.028, Average Loss: 4.420, avg. samples / sec: 66441.35
Iteration:   2200, Loss function: 3.810, Average Loss: 4.381, avg. samples / sec: 66461.18
Iteration:   2200, Loss function: 4.542, Average Loss: 4.365, avg. samples / sec: 66412.14
Iteration:   2200, Loss function: 4.039, Average Loss: 4.385, avg. samples / sec: 66457.02
Iteration:   2200, Loss function: 4.489, Average Loss: 4.412, avg. samples / sec: 66317.29
Iteration:   2200, Loss function: 5.159, Average Loss: 4.378, avg. samples / sec: 66263.94
Iteration:   2200, Loss function: 4.408, Average Loss: 4.429, avg. samples / sec: 66364.19
Iteration:   2200, Loss function: 3.160, Average Loss: 4.382, avg. samples / sec: 66358.73
Iteration:   2200, Loss function: 5.096, Average Loss: 4.392, avg. samples / sec: 66273.50
Iteration:   2200, Loss function: 3.860, Average Loss: 4.404, avg. samples / sec: 66419.87
Iteration:   2200, Loss function: 3.545, Average Loss: 4.372, avg. samples / sec: 66275.78
Iteration:   2200, Loss function: 3.817, Average Loss: 4.401, avg. samples / sec: 66381.01
Iteration:   2200, Loss function: 3.247, Average Loss: 4.403, avg. samples / sec: 66249.17
Iteration:   2200, Loss function: 2.610, Average Loss: 4.392, avg. samples / sec: 66308.49
Iteration:   2200, Loss function: 3.027, Average Loss: 4.390, avg. samples / sec: 66409.16
Iteration:   2200, Loss function: 5.078, Average Loss: 4.376, avg. samples / sec: 66305.06
Iteration:   2200, Loss function: 5.117, Average Loss: 4.374, avg. samples / sec: 66401.65
Iteration:   2220, Loss function: 4.106, Average Loss: 4.404, avg. samples / sec: 66520.76
Iteration:   2220, Loss function: 4.354, Average Loss: 4.394, avg. samples / sec: 66515.45
Iteration:   2220, Loss function: 4.505, Average Loss: 4.383, avg. samples / sec: 66395.24
Iteration:   2220, Loss function: 4.582, Average Loss: 4.416, avg. samples / sec: 66556.92
Iteration:   2220, Loss function: 3.092, Average Loss: 4.369, avg. samples / sec: 66696.62
Iteration:   2220, Loss function: 5.628, Average Loss: 4.365, avg. samples / sec: 66438.12
Iteration:   2220, Loss function: 5.839, Average Loss: 4.387, avg. samples / sec: 66434.80
Iteration:   2220, Loss function: 3.412, Average Loss: 4.385, avg. samples / sec: 66510.62
Iteration:   2220, Loss function: 1.803, Average Loss: 4.360, avg. samples / sec: 66495.40
Iteration:   2220, Loss function: 5.280, Average Loss: 4.408, avg. samples / sec: 66476.20
Iteration:   2220, Loss function: 4.586, Average Loss: 4.385, avg. samples / sec: 66419.12
Iteration:   2220, Loss function: 5.618, Average Loss: 4.397, avg. samples / sec: 66456.55
Iteration:   2220, Loss function: 4.888, Average Loss: 4.376, avg. samples / sec: 66424.44
Iteration:   2220, Loss function: 5.791, Average Loss: 4.382, avg. samples / sec: 66470.21
Iteration:   2220, Loss function: 4.770, Average Loss: 4.393, avg. samples / sec: 66522.83
Iteration:   2220, Loss function: 4.982, Average Loss: 4.396, avg. samples / sec: 66325.09
Iteration:   2220, Loss function: 3.945, Average Loss: 4.371, avg. samples / sec: 66583.08
Iteration:   2220, Loss function: 4.911, Average Loss: 4.375, avg. samples / sec: 66364.04
Iteration:   2220, Loss function: 4.163, Average Loss: 4.379, avg. samples / sec: 66470.90
Iteration:   2220, Loss function: 2.126, Average Loss: 4.368, avg. samples / sec: 66472.94
Iteration:   2220, Loss function: 4.020, Average Loss: 4.402, avg. samples / sec: 66467.45
Iteration:   2220, Loss function: 3.857, Average Loss: 4.411, avg. samples / sec: 66437.00
Iteration:   2220, Loss function: 3.789, Average Loss: 4.388, avg. samples / sec: 66502.61
Iteration:   2220, Loss function: 3.540, Average Loss: 4.393, avg. samples / sec: 66494.08
Iteration:   2220, Loss function: 5.018, Average Loss: 4.379, avg. samples / sec: 66367.10
Iteration:   2220, Loss function: 5.696, Average Loss: 4.382, avg. samples / sec: 66393.30
Iteration:   2220, Loss function: 2.901, Average Loss: 4.396, avg. samples / sec: 66436.34
Iteration:   2220, Loss function: 4.367, Average Loss: 4.400, avg. samples / sec: 66419.52
Iteration:   2220, Loss function: 4.183, Average Loss: 4.418, avg. samples / sec: 66374.79
Iteration:   2220, Loss function: 4.656, Average Loss: 4.400, avg. samples / sec: 66253.56
:::MLL 1558651747.822 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558651747.822 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 3.845, Average Loss: 4.403, avg. samples / sec: 66550.95
Iteration:   2240, Loss function: 5.284, Average Loss: 4.386, avg. samples / sec: 66476.86
Iteration:   2240, Loss function: 3.132, Average Loss: 4.394, avg. samples / sec: 66559.43
Iteration:   2240, Loss function: 4.842, Average Loss: 4.400, avg. samples / sec: 66574.68
Iteration:   2240, Loss function: 4.828, Average Loss: 4.361, avg. samples / sec: 66459.84
Iteration:   2240, Loss function: 4.378, Average Loss: 4.388, avg. samples / sec: 66648.70
Iteration:   2240, Loss function: 2.475, Average Loss: 4.370, avg. samples / sec: 66483.54
Iteration:   2240, Loss function: 4.180, Average Loss: 4.403, avg. samples / sec: 66332.08
Iteration:   2240, Loss function: 3.898, Average Loss: 4.387, avg. samples / sec: 66407.22
Iteration:   2240, Loss function: 5.018, Average Loss: 4.360, avg. samples / sec: 66521.98
Iteration:   2240, Loss function: 4.418, Average Loss: 4.355, avg. samples / sec: 66458.21
Iteration:   2240, Loss function: 4.024, Average Loss: 4.361, avg. samples / sec: 66398.49
Iteration:   2240, Loss function: 3.615, Average Loss: 4.378, avg. samples / sec: 66436.68
Iteration:   2240, Loss function: 5.023, Average Loss: 4.385, avg. samples / sec: 66563.55
Iteration:   2240, Loss function: 3.765, Average Loss: 4.396, avg. samples / sec: 66469.11
Iteration:   2240, Loss function: 4.798, Average Loss: 4.376, avg. samples / sec: 66339.55
Iteration:   2240, Loss function: 3.577, Average Loss: 4.382, avg. samples / sec: 66359.26
Iteration:   2240, Loss function: 4.398, Average Loss: 4.405, avg. samples / sec: 66486.96
Iteration:   2240, Loss function: 3.660, Average Loss: 4.376, avg. samples / sec: 66513.72
Iteration:   2240, Loss function: 3.978, Average Loss: 4.365, avg. samples / sec: 66437.06
Iteration:   2240, Loss function: 4.079, Average Loss: 4.410, avg. samples / sec: 66310.83
Iteration:   2240, Loss function: 3.253, Average Loss: 4.380, avg. samples / sec: 66460.37
Iteration:   2240, Loss function: 3.535, Average Loss: 4.372, avg. samples / sec: 66427.54
Iteration:   2240, Loss function: 4.934, Average Loss: 4.371, avg. samples / sec: 66404.72
Iteration:   2240, Loss function: 4.395, Average Loss: 4.415, avg. samples / sec: 66488.62
Iteration:   2240, Loss function: 3.845, Average Loss: 4.387, avg. samples / sec: 66427.76
Iteration:   2240, Loss function: 4.181, Average Loss: 4.373, avg. samples / sec: 66421.56
Iteration:   2240, Loss function: 3.403, Average Loss: 4.377, avg. samples / sec: 66315.45
Iteration:   2240, Loss function: 3.603, Average Loss: 4.394, avg. samples / sec: 66427.57
Iteration:   2240, Loss function: 4.442, Average Loss: 4.386, avg. samples / sec: 66285.72
Iteration:   2260, Loss function: 4.257, Average Loss: 4.395, avg. samples / sec: 66110.63
Iteration:   2260, Loss function: 5.694, Average Loss: 4.372, avg. samples / sec: 66233.60
Iteration:   2260, Loss function: 3.302, Average Loss: 4.385, avg. samples / sec: 66151.87
Iteration:   2260, Loss function: 4.309, Average Loss: 4.398, avg. samples / sec: 66133.92
Iteration:   2260, Loss function: 4.258, Average Loss: 4.381, avg. samples / sec: 66049.86
Iteration:   2260, Loss function: 4.443, Average Loss: 4.372, avg. samples / sec: 66206.31
Iteration:   2260, Loss function: 4.530, Average Loss: 4.371, avg. samples / sec: 66218.45
Iteration:   2260, Loss function: 4.765, Average Loss: 4.355, avg. samples / sec: 66132.00
Iteration:   2260, Loss function: 4.347, Average Loss: 4.401, avg. samples / sec: 66198.07
Iteration:   2260, Loss function: 4.014, Average Loss: 4.388, avg. samples / sec: 66143.20
Iteration:   2260, Loss function: 4.668, Average Loss: 4.401, avg. samples / sec: 66154.63
Iteration:   2260, Loss function: 4.887, Average Loss: 4.359, avg. samples / sec: 66148.33
Iteration:   2260, Loss function: 4.630, Average Loss: 4.368, avg. samples / sec: 66155.41
Iteration:   2260, Loss function: 4.335, Average Loss: 4.379, avg. samples / sec: 66123.93
Iteration:   2260, Loss function: 5.104, Average Loss: 4.375, avg. samples / sec: 66086.97
Iteration:   2260, Loss function: 3.773, Average Loss: 4.356, avg. samples / sec: 66008.90
Iteration:   2260, Loss function: 4.129, Average Loss: 4.385, avg. samples / sec: 65996.45
Iteration:   2260, Loss function: 3.593, Average Loss: 4.410, avg. samples / sec: 66123.40
Iteration:   2260, Loss function: 4.038, Average Loss: 4.392, avg. samples / sec: 65922.91
Iteration:   2260, Loss function: 4.890, Average Loss: 4.369, avg. samples / sec: 66144.17
Iteration:   2260, Loss function: 4.527, Average Loss: 4.376, avg. samples / sec: 66086.78
Iteration:   2260, Loss function: 2.539, Average Loss: 4.348, avg. samples / sec: 66000.87
Iteration:   2260, Loss function: 4.446, Average Loss: 4.382, avg. samples / sec: 66128.21
Iteration:   2260, Loss function: 3.545, Average Loss: 4.357, avg. samples / sec: 65993.29
Iteration:   2260, Loss function: 4.838, Average Loss: 4.397, avg. samples / sec: 65938.30
Iteration:   2260, Loss function: 4.880, Average Loss: 4.389, avg. samples / sec: 66147.40
Iteration:   2260, Loss function: 3.155, Average Loss: 4.371, avg. samples / sec: 65953.33
Iteration:   2260, Loss function: 3.931, Average Loss: 4.374, avg. samples / sec: 65944.63
Iteration:   2260, Loss function: 4.296, Average Loss: 4.384, avg. samples / sec: 66087.53
Iteration:   2260, Loss function: 4.242, Average Loss: 4.371, avg. samples / sec: 66022.48
Iteration:   2280, Loss function: 4.234, Average Loss: 4.377, avg. samples / sec: 66141.16
Iteration:   2280, Loss function: 4.884, Average Loss: 4.363, avg. samples / sec: 66191.76
Iteration:   2280, Loss function: 4.287, Average Loss: 4.389, avg. samples / sec: 65987.55
Iteration:   2280, Loss function: 3.887, Average Loss: 4.395, avg. samples / sec: 65932.16
Iteration:   2280, Loss function: 4.576, Average Loss: 4.377, avg. samples / sec: 66099.87
Iteration:   2280, Loss function: 4.871, Average Loss: 4.397, avg. samples / sec: 65993.63
Iteration:   2280, Loss function: 4.232, Average Loss: 4.347, avg. samples / sec: 65990.82
Iteration:   2280, Loss function: 4.187, Average Loss: 4.374, avg. samples / sec: 66057.11
Iteration:   2280, Loss function: 3.308, Average Loss: 4.376, avg. samples / sec: 65964.32
Iteration:   2280, Loss function: 3.958, Average Loss: 4.404, avg. samples / sec: 66071.26
Iteration:   2280, Loss function: 4.564, Average Loss: 4.365, avg. samples / sec: 66027.18
Iteration:   2280, Loss function: 4.222, Average Loss: 4.365, avg. samples / sec: 65963.24
Iteration:   2280, Loss function: 3.491, Average Loss: 4.356, avg. samples / sec: 66028.23
Iteration:   2280, Loss function: 4.335, Average Loss: 4.376, avg. samples / sec: 65920.07
Iteration:   2280, Loss function: 3.635, Average Loss: 4.386, avg. samples / sec: 65935.34
Iteration:   2280, Loss function: 3.440, Average Loss: 4.355, avg. samples / sec: 65956.57
Iteration:   2280, Loss function: 4.049, Average Loss: 4.343, avg. samples / sec: 66042.96
Iteration:   2280, Loss function: 3.683, Average Loss: 4.367, avg. samples / sec: 66070.58
Iteration:   2280, Loss function: 4.257, Average Loss: 4.368, avg. samples / sec: 65857.20
Iteration:   2280, Loss function: 3.234, Average Loss: 4.397, avg. samples / sec: 65947.90
Iteration:   2280, Loss function: 3.859, Average Loss: 4.366, avg. samples / sec: 65871.21
Iteration:   2280, Loss function: 4.376, Average Loss: 4.357, avg. samples / sec: 66008.87
Iteration:   2280, Loss function: 4.935, Average Loss: 4.390, avg. samples / sec: 65980.75
Iteration:   2280, Loss function: 2.737, Average Loss: 4.365, avg. samples / sec: 66045.56
Iteration:   2280, Loss function: 3.769, Average Loss: 4.392, avg. samples / sec: 66000.31
Iteration:   2280, Loss function: 5.689, Average Loss: 4.384, avg. samples / sec: 65959.44
Iteration:   2280, Loss function: 4.050, Average Loss: 4.382, avg. samples / sec: 66014.96
Iteration:   2280, Loss function: 5.355, Average Loss: 4.377, avg. samples / sec: 65915.76
Iteration:   2280, Loss function: 5.322, Average Loss: 4.368, avg. samples / sec: 66050.11
Iteration:   2280, Loss function: 4.082, Average Loss: 4.370, avg. samples / sec: 65833.70
:::MLL 1558651749.004 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.77 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.57s)
DONE (t=3.12s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.15040
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.28588
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.14543
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.15931
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.24068
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.16957
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24817
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26274
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06802
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.27805
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.39973
Current AP: 0.15040 AP goal: 0.23000
:::MLL 1558651753.472 eval_accuracy: {"value": 0.1504037465363433, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558651753.771 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558651753.777 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558651753.777 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 3.625, Average Loss: 4.347, avg. samples / sec: 6275.99
Iteration:   2300, Loss function: 3.584, Average Loss: 4.357, avg. samples / sec: 6277.11
Iteration:   2300, Loss function: 4.461, Average Loss: 4.373, avg. samples / sec: 6275.49
Iteration:   2300, Loss function: 3.639, Average Loss: 4.376, avg. samples / sec: 6275.25
Iteration:   2300, Loss function: 4.050, Average Loss: 4.371, avg. samples / sec: 6275.30
Iteration:   2300, Loss function: 4.374, Average Loss: 4.383, avg. samples / sec: 6277.05
Iteration:   2300, Loss function: 4.662, Average Loss: 4.367, avg. samples / sec: 6277.74
Iteration:   2300, Loss function: 4.462, Average Loss: 4.394, avg. samples / sec: 6275.67
Iteration:   2300, Loss function: 4.226, Average Loss: 4.366, avg. samples / sec: 6275.63
Iteration:   2300, Loss function: 3.920, Average Loss: 4.352, avg. samples / sec: 6275.30
Iteration:   2300, Loss function: 3.827, Average Loss: 4.363, avg. samples / sec: 6275.71
Iteration:   2300, Loss function: 3.987, Average Loss: 4.368, avg. samples / sec: 6276.53
Iteration:   2300, Loss function: 4.009, Average Loss: 4.358, avg. samples / sec: 6275.79
Iteration:   2300, Loss function: 5.023, Average Loss: 4.363, avg. samples / sec: 6274.95
Iteration:   2300, Loss function: 6.236, Average Loss: 4.391, avg. samples / sec: 6275.88
Iteration:   2300, Loss function: 5.494, Average Loss: 4.388, avg. samples / sec: 6275.83
Iteration:   2300, Loss function: 4.487, Average Loss: 4.391, avg. samples / sec: 6274.46
Iteration:   2300, Loss function: 4.465, Average Loss: 4.381, avg. samples / sec: 6276.13
Iteration:   2300, Loss function: 3.567, Average Loss: 4.341, avg. samples / sec: 6275.14
Iteration:   2300, Loss function: 2.992, Average Loss: 4.359, avg. samples / sec: 6274.77
Iteration:   2300, Loss function: 4.032, Average Loss: 4.370, avg. samples / sec: 6274.89
Iteration:   2300, Loss function: 3.750, Average Loss: 4.372, avg. samples / sec: 6274.12
Iteration:   2300, Loss function: 4.336, Average Loss: 4.368, avg. samples / sec: 6274.63
Iteration:   2300, Loss function: 4.381, Average Loss: 4.373, avg. samples / sec: 6273.25
Iteration:   2300, Loss function: 3.960, Average Loss: 4.340, avg. samples / sec: 6274.80
Iteration:   2300, Loss function: 4.032, Average Loss: 4.395, avg. samples / sec: 6273.76
Iteration:   2300, Loss function: 3.881, Average Loss: 4.385, avg. samples / sec: 6273.94
Iteration:   2300, Loss function: 4.166, Average Loss: 4.373, avg. samples / sec: 6275.10
Iteration:   2300, Loss function: 2.808, Average Loss: 4.384, avg. samples / sec: 6273.25
Iteration:   2300, Loss function: 4.449, Average Loss: 4.360, avg. samples / sec: 6272.14
:::MLL 1558651754.451 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558651754.452 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 5.593, Average Loss: 4.355, avg. samples / sec: 65648.86
Iteration:   2320, Loss function: 4.244, Average Loss: 4.351, avg. samples / sec: 65478.39
Iteration:   2320, Loss function: 5.090, Average Loss: 4.342, avg. samples / sec: 65411.86
Iteration:   2320, Loss function: 3.979, Average Loss: 4.371, avg. samples / sec: 65430.02
Iteration:   2320, Loss function: 5.334, Average Loss: 4.369, avg. samples / sec: 65568.29
Iteration:   2320, Loss function: 4.000, Average Loss: 4.378, avg. samples / sec: 65655.07
Iteration:   2320, Loss function: 3.613, Average Loss: 4.367, avg. samples / sec: 65518.82
Iteration:   2320, Loss function: 4.120, Average Loss: 4.378, avg. samples / sec: 65487.09
Iteration:   2320, Loss function: 4.736, Average Loss: 4.384, avg. samples / sec: 65482.65
Iteration:   2320, Loss function: 2.987, Average Loss: 4.351, avg. samples / sec: 65449.59
Iteration:   2320, Loss function: 3.385, Average Loss: 4.387, avg. samples / sec: 65420.03
Iteration:   2320, Loss function: 4.313, Average Loss: 4.378, avg. samples / sec: 65604.55
Iteration:   2320, Loss function: 4.946, Average Loss: 4.354, avg. samples / sec: 65449.08
Iteration:   2320, Loss function: 2.839, Average Loss: 4.359, avg. samples / sec: 65423.46
Iteration:   2320, Loss function: 4.772, Average Loss: 4.358, avg. samples / sec: 65418.03
Iteration:   2320, Loss function: 5.089, Average Loss: 4.365, avg. samples / sec: 65370.48
Iteration:   2320, Loss function: 3.941, Average Loss: 4.362, avg. samples / sec: 65405.91
Iteration:   2320, Loss function: 4.381, Average Loss: 4.391, avg. samples / sec: 65500.88
Iteration:   2320, Loss function: 5.886, Average Loss: 4.393, avg. samples / sec: 65420.36
Iteration:   2320, Loss function: 4.487, Average Loss: 4.361, avg. samples / sec: 65460.87
Iteration:   2320, Loss function: 3.667, Average Loss: 4.366, avg. samples / sec: 65310.22
Iteration:   2320, Loss function: 3.708, Average Loss: 4.360, avg. samples / sec: 65349.98
Iteration:   2320, Loss function: 5.166, Average Loss: 4.352, avg. samples / sec: 65565.97
Iteration:   2320, Loss function: 4.780, Average Loss: 4.383, avg. samples / sec: 65344.71
Iteration:   2320, Loss function: 3.971, Average Loss: 4.367, avg. samples / sec: 65403.76
Iteration:   2320, Loss function: 4.428, Average Loss: 4.379, avg. samples / sec: 65264.34
Iteration:   2320, Loss function: 4.959, Average Loss: 4.344, avg. samples / sec: 65383.58
Iteration:   2320, Loss function: 4.175, Average Loss: 4.335, avg. samples / sec: 65328.93
Iteration:   2320, Loss function: 4.234, Average Loss: 4.371, avg. samples / sec: 65208.02
Iteration:   2320, Loss function: 3.232, Average Loss: 4.386, avg. samples / sec: 65461.84
Iteration:   2340, Loss function: 4.738, Average Loss: 4.334, avg. samples / sec: 66401.40
Iteration:   2340, Loss function: 3.268, Average Loss: 4.356, avg. samples / sec: 66247.05
Iteration:   2340, Loss function: 4.718, Average Loss: 4.365, avg. samples / sec: 66113.66
Iteration:   2340, Loss function: 4.302, Average Loss: 4.347, avg. samples / sec: 66256.24
Iteration:   2340, Loss function: 4.099, Average Loss: 4.375, avg. samples / sec: 66141.31
Iteration:   2340, Loss function: 4.150, Average Loss: 4.352, avg. samples / sec: 66124.06
Iteration:   2340, Loss function: 4.579, Average Loss: 4.348, avg. samples / sec: 65954.87
Iteration:   2340, Loss function: 3.991, Average Loss: 4.334, avg. samples / sec: 66024.92
Iteration:   2340, Loss function: 3.770, Average Loss: 4.344, avg. samples / sec: 66101.94
Iteration:   2340, Loss function: 3.706, Average Loss: 4.354, avg. samples / sec: 66181.19
Iteration:   2340, Loss function: 4.509, Average Loss: 4.369, avg. samples / sec: 66260.26
Iteration:   2340, Loss function: 3.958, Average Loss: 4.386, avg. samples / sec: 66168.55
Iteration:   2340, Loss function: 3.302, Average Loss: 4.382, avg. samples / sec: 66262.47
Iteration:   2340, Loss function: 4.397, Average Loss: 4.376, avg. samples / sec: 66079.50
Iteration:   2340, Loss function: 3.739, Average Loss: 4.380, avg. samples / sec: 66179.17
Iteration:   2340, Loss function: 5.731, Average Loss: 4.386, avg. samples / sec: 66138.89
Iteration:   2340, Loss function: 4.469, Average Loss: 4.361, avg. samples / sec: 66208.74
Iteration:   2340, Loss function: 4.314, Average Loss: 4.375, avg. samples / sec: 66070.52
Iteration:   2340, Loss function: 5.265, Average Loss: 4.364, avg. samples / sec: 65985.29
Iteration:   2340, Loss function: 3.772, Average Loss: 4.355, avg. samples / sec: 66092.89
Iteration:   2340, Loss function: 3.791, Average Loss: 4.377, avg. samples / sec: 66186.66
Iteration:   2340, Loss function: 3.485, Average Loss: 4.340, avg. samples / sec: 65894.49
Iteration:   2340, Loss function: 3.044, Average Loss: 4.352, avg. samples / sec: 66072.84
Iteration:   2340, Loss function: 3.262, Average Loss: 4.364, avg. samples / sec: 66065.13
Iteration:   2340, Loss function: 5.296, Average Loss: 4.378, avg. samples / sec: 65968.40
Iteration:   2340, Loss function: 4.569, Average Loss: 4.359, avg. samples / sec: 66051.41
Iteration:   2340, Loss function: 3.685, Average Loss: 4.380, avg. samples / sec: 65967.87
Iteration:   2340, Loss function: 5.073, Average Loss: 4.346, avg. samples / sec: 66082.45
Iteration:   2340, Loss function: 4.123, Average Loss: 4.355, avg. samples / sec: 65962.10
Iteration:   2340, Loss function: 3.866, Average Loss: 4.360, avg. samples / sec: 65842.37
Iteration:   2360, Loss function: 4.874, Average Loss: 4.357, avg. samples / sec: 64060.50
Iteration:   2360, Loss function: 3.696, Average Loss: 4.326, avg. samples / sec: 64055.17
Iteration:   2360, Loss function: 4.236, Average Loss: 4.356, avg. samples / sec: 64092.72
Iteration:   2360, Loss function: 4.825, Average Loss: 4.385, avg. samples / sec: 64042.51
Iteration:   2360, Loss function: 3.379, Average Loss: 4.385, avg. samples / sec: 64056.98
Iteration:   2360, Loss function: 5.380, Average Loss: 4.356, avg. samples / sec: 64269.82
Iteration:   2360, Loss function: 3.807, Average Loss: 4.361, avg. samples / sec: 63963.65
Iteration:   2360, Loss function: 4.819, Average Loss: 4.344, avg. samples / sec: 63991.12
Iteration:   2360, Loss function: 4.583, Average Loss: 4.371, avg. samples / sec: 64098.29
Iteration:   2360, Loss function: 4.649, Average Loss: 4.372, avg. samples / sec: 64008.51
Iteration:   2360, Loss function: 3.484, Average Loss: 4.350, avg. samples / sec: 64196.40
Iteration:   2360, Loss function: 4.647, Average Loss: 4.353, avg. samples / sec: 64084.24
Iteration:   2360, Loss function: 3.619, Average Loss: 4.329, avg. samples / sec: 63859.02
Iteration:   2360, Loss function: 4.321, Average Loss: 4.362, avg. samples / sec: 64038.32
Iteration:   2360, Loss function: 3.676, Average Loss: 4.340, avg. samples / sec: 64033.26
Iteration:   2360, Loss function: 4.063, Average Loss: 4.346, avg. samples / sec: 63905.12
Iteration:   2360, Loss function: 3.060, Average Loss: 4.352, avg. samples / sec: 63958.77
Iteration:   2360, Loss function: 5.595, Average Loss: 4.344, avg. samples / sec: 63898.92
Iteration:   2360, Loss function: 4.418, Average Loss: 4.361, avg. samples / sec: 63962.43
Iteration:   2360, Loss function: 3.608, Average Loss: 4.370, avg. samples / sec: 63996.99
Iteration:   2360, Loss function: 3.805, Average Loss: 4.349, avg. samples / sec: 63994.73
Iteration:   2360, Loss function: 4.176, Average Loss: 4.343, avg. samples / sec: 64091.91
Iteration:   2360, Loss function: 4.229, Average Loss: 4.372, avg. samples / sec: 63949.40
Iteration:   2360, Loss function: 4.129, Average Loss: 4.376, avg. samples / sec: 63932.69
Iteration:   2360, Loss function: 3.451, Average Loss: 4.358, avg. samples / sec: 63957.44
Iteration:   2360, Loss function: 4.771, Average Loss: 4.375, avg. samples / sec: 64021.01
Iteration:   2360, Loss function: 4.366, Average Loss: 4.369, avg. samples / sec: 63849.99
Iteration:   2360, Loss function: 4.404, Average Loss: 4.371, avg. samples / sec: 63928.66
Iteration:   2360, Loss function: 4.341, Average Loss: 4.347, avg. samples / sec: 63907.23
Iteration:   2360, Loss function: 4.185, Average Loss: 4.334, avg. samples / sec: 63831.92
:::MLL 1558651756.251 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558651756.252 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 4.807, Average Loss: 4.356, avg. samples / sec: 65889.04
Iteration:   2380, Loss function: 4.459, Average Loss: 4.365, avg. samples / sec: 65912.21
Iteration:   2380, Loss function: 3.868, Average Loss: 4.364, avg. samples / sec: 65861.36
Iteration:   2380, Loss function: 3.537, Average Loss: 4.325, avg. samples / sec: 65773.44
Iteration:   2380, Loss function: 4.212, Average Loss: 4.341, avg. samples / sec: 65821.70
Iteration:   2380, Loss function: 2.346, Average Loss: 4.350, avg. samples / sec: 65742.61
Iteration:   2380, Loss function: 4.262, Average Loss: 4.373, avg. samples / sec: 65796.14
Iteration:   2380, Loss function: 5.173, Average Loss: 4.357, avg. samples / sec: 65883.19
Iteration:   2380, Loss function: 4.064, Average Loss: 4.333, avg. samples / sec: 65996.11
Iteration:   2380, Loss function: 5.639, Average Loss: 4.339, avg. samples / sec: 65845.11
Iteration:   2380, Loss function: 4.288, Average Loss: 4.351, avg. samples / sec: 65892.18
Iteration:   2380, Loss function: 4.876, Average Loss: 4.352, avg. samples / sec: 65723.26
Iteration:   2380, Loss function: 5.215, Average Loss: 4.338, avg. samples / sec: 65850.62
Iteration:   2380, Loss function: 3.055, Average Loss: 4.371, avg. samples / sec: 65761.01
Iteration:   2380, Loss function: 3.598, Average Loss: 4.346, avg. samples / sec: 65798.63
Iteration:   2380, Loss function: 4.868, Average Loss: 4.369, avg. samples / sec: 65842.12
Iteration:   2380, Loss function: 4.374, Average Loss: 4.344, avg. samples / sec: 65766.17
Iteration:   2380, Loss function: 4.632, Average Loss: 4.352, avg. samples / sec: 65730.65
Iteration:   2380, Loss function: 3.524, Average Loss: 4.369, avg. samples / sec: 65804.43
Iteration:   2380, Loss function: 4.387, Average Loss: 4.350, avg. samples / sec: 65717.56
Iteration:   2380, Loss function: 3.081, Average Loss: 4.352, avg. samples / sec: 65658.90
Iteration:   2380, Loss function: 4.118, Average Loss: 4.340, avg. samples / sec: 65856.09
Iteration:   2380, Loss function: 3.532, Average Loss: 4.362, avg. samples / sec: 65737.09
Iteration:   2380, Loss function: 4.044, Average Loss: 4.330, avg. samples / sec: 65708.92
Iteration:   2380, Loss function: 4.690, Average Loss: 4.378, avg. samples / sec: 65647.03
Iteration:   2380, Loss function: 4.697, Average Loss: 4.365, avg. samples / sec: 65766.72
Iteration:   2380, Loss function: 3.458, Average Loss: 4.351, avg. samples / sec: 65693.67
Iteration:   2380, Loss function: 4.788, Average Loss: 4.368, avg. samples / sec: 65691.89
Iteration:   2380, Loss function: 4.422, Average Loss: 4.369, avg. samples / sec: 65655.41
Iteration:   2380, Loss function: 4.674, Average Loss: 4.343, avg. samples / sec: 65596.86
Iteration:   2400, Loss function: 3.727, Average Loss: 4.328, avg. samples / sec: 65825.49
Iteration:   2400, Loss function: 3.965, Average Loss: 4.322, avg. samples / sec: 65768.16
Iteration:   2400, Loss function: 4.332, Average Loss: 4.338, avg. samples / sec: 65841.23
Iteration:   2400, Loss function: 4.081, Average Loss: 4.351, avg. samples / sec: 65716.40
Iteration:   2400, Loss function: 4.029, Average Loss: 4.369, avg. samples / sec: 65773.51
Iteration:   2400, Loss function: 3.891, Average Loss: 4.343, avg. samples / sec: 66047.95
Iteration:   2400, Loss function: 3.150, Average Loss: 4.338, avg. samples / sec: 65830.44
Iteration:   2400, Loss function: 4.200, Average Loss: 4.350, avg. samples / sec: 65772.74
Iteration:   2400, Loss function: 3.968, Average Loss: 4.368, avg. samples / sec: 65774.30
Iteration:   2400, Loss function: 5.478, Average Loss: 4.329, avg. samples / sec: 65715.72
Iteration:   2400, Loss function: 3.366, Average Loss: 4.353, avg. samples / sec: 65688.46
Iteration:   2400, Loss function: 3.631, Average Loss: 4.362, avg. samples / sec: 65946.36
Iteration:   2400, Loss function: 3.170, Average Loss: 4.352, avg. samples / sec: 65695.35
Iteration:   2400, Loss function: 3.795, Average Loss: 4.353, avg. samples / sec: 65817.00
Iteration:   2400, Loss function: 5.706, Average Loss: 4.363, avg. samples / sec: 65667.19
Iteration:   2400, Loss function: 3.637, Average Loss: 4.363, avg. samples / sec: 65780.41
Iteration:   2400, Loss function: 3.321, Average Loss: 4.331, avg. samples / sec: 65793.50
Iteration:   2400, Loss function: 3.850, Average Loss: 4.342, avg. samples / sec: 65765.49
Iteration:   2400, Loss function: 3.024, Average Loss: 4.342, avg. samples / sec: 65752.39
Iteration:   2400, Loss function: 3.872, Average Loss: 4.338, avg. samples / sec: 65624.10
Iteration:   2400, Loss function: 5.189, Average Loss: 4.354, avg. samples / sec: 65670.06
Iteration:   2400, Loss function: 3.928, Average Loss: 4.350, avg. samples / sec: 65750.83
Iteration:   2400, Loss function: 3.962, Average Loss: 4.360, avg. samples / sec: 65863.36
Iteration:   2400, Loss function: 4.138, Average Loss: 4.347, avg. samples / sec: 65812.64
Iteration:   2400, Loss function: 3.235, Average Loss: 4.359, avg. samples / sec: 65587.27
Iteration:   2400, Loss function: 4.551, Average Loss: 4.366, avg. samples / sec: 65662.87
Iteration:   2400, Loss function: 3.277, Average Loss: 4.336, avg. samples / sec: 65692.47
Iteration:   2400, Loss function: 3.466, Average Loss: 4.376, avg. samples / sec: 65701.35
Iteration:   2400, Loss function: 4.327, Average Loss: 4.347, avg. samples / sec: 65647.73
Iteration:   2400, Loss function: 4.504, Average Loss: 4.360, avg. samples / sec: 65605.83
Iteration:   2420, Loss function: 4.086, Average Loss: 4.327, avg. samples / sec: 66036.31
Iteration:   2420, Loss function: 5.011, Average Loss: 4.318, avg. samples / sec: 66057.85
Iteration:   2420, Loss function: 4.387, Average Loss: 4.341, avg. samples / sec: 66152.74
Iteration:   2420, Loss function: 5.017, Average Loss: 4.323, avg. samples / sec: 66078.73
Iteration:   2420, Loss function: 5.660, Average Loss: 4.351, avg. samples / sec: 66124.89
Iteration:   2420, Loss function: 3.839, Average Loss: 4.345, avg. samples / sec: 65972.07
Iteration:   2420, Loss function: 7.387, Average Loss: 4.340, avg. samples / sec: 66235.88
Iteration:   2420, Loss function: 4.834, Average Loss: 4.344, avg. samples / sec: 66087.93
Iteration:   2420, Loss function: 3.866, Average Loss: 4.336, avg. samples / sec: 66049.80
Iteration:   2420, Loss function: 4.801, Average Loss: 4.331, avg. samples / sec: 65966.36
Iteration:   2420, Loss function: 4.682, Average Loss: 4.349, avg. samples / sec: 65994.87
Iteration:   2420, Loss function: 4.679, Average Loss: 4.334, avg. samples / sec: 65923.90
Iteration:   2420, Loss function: 4.196, Average Loss: 4.361, avg. samples / sec: 65922.88
Iteration:   2420, Loss function: 4.881, Average Loss: 4.332, avg. samples / sec: 66079.29
Iteration:   2420, Loss function: 3.165, Average Loss: 4.345, avg. samples / sec: 66016.42
Iteration:   2420, Loss function: 3.458, Average Loss: 4.352, avg. samples / sec: 66017.62
Iteration:   2420, Loss function: 3.965, Average Loss: 4.347, avg. samples / sec: 65984.95
Iteration:   2420, Loss function: 4.141, Average Loss: 4.354, avg. samples / sec: 66078.05
Iteration:   2420, Loss function: 4.153, Average Loss: 4.342, avg. samples / sec: 66074.45
Iteration:   2420, Loss function: 3.838, Average Loss: 4.344, avg. samples / sec: 65985.66
Iteration:   2420, Loss function: 3.290, Average Loss: 4.360, avg. samples / sec: 66093.51
Iteration:   2420, Loss function: 3.502, Average Loss: 4.331, avg. samples / sec: 66104.05
Iteration:   2420, Loss function: 3.926, Average Loss: 4.366, avg. samples / sec: 65929.11
Iteration:   2420, Loss function: 5.052, Average Loss: 4.330, avg. samples / sec: 65978.16
Iteration:   2420, Loss function: 3.052, Average Loss: 4.358, avg. samples / sec: 65980.10
Iteration:   2420, Loss function: 4.255, Average Loss: 4.351, avg. samples / sec: 65938.33
Iteration:   2420, Loss function: 4.277, Average Loss: 4.354, avg. samples / sec: 66180.85
Iteration:   2420, Loss function: 5.607, Average Loss: 4.360, avg. samples / sec: 65973.03
Iteration:   2420, Loss function: 4.079, Average Loss: 4.342, avg. samples / sec: 65817.77
Iteration:   2420, Loss function: 4.426, Average Loss: 4.370, avg. samples / sec: 66006.28
Iteration:   2440, Loss function: 4.437, Average Loss: 4.321, avg. samples / sec: 65703.10
Iteration:   2440, Loss function: 3.686, Average Loss: 4.356, avg. samples / sec: 65787.35
Iteration:   2440, Loss function: 4.806, Average Loss: 4.341, avg. samples / sec: 65714.31
Iteration:   2440, Loss function: 3.168, Average Loss: 4.330, avg. samples / sec: 65739.20
Iteration:   2440, Loss function: 4.430, Average Loss: 4.345, avg. samples / sec: 65754.60
Iteration:   2440, Loss function: 5.063, Average Loss: 4.317, avg. samples / sec: 65597.41
Iteration:   2440, Loss function: 2.428, Average Loss: 4.342, avg. samples / sec: 65747.36
Iteration:   2440, Loss function: 5.101, Average Loss: 4.362, avg. samples / sec: 65769.98
Iteration:   2440, Loss function: 4.261, Average Loss: 4.318, avg. samples / sec: 65650.30
Iteration:   2440, Loss function: 5.177, Average Loss: 4.353, avg. samples / sec: 65711.89
Iteration:   2440, Loss function: 4.526, Average Loss: 4.340, avg. samples / sec: 65647.76
Iteration:   2440, Loss function: 5.105, Average Loss: 4.339, avg. samples / sec: 65617.75
Iteration:   2440, Loss function: 4.422, Average Loss: 4.339, avg. samples / sec: 65676.22
Iteration:   2440, Loss function: 3.945, Average Loss: 4.331, avg. samples / sec: 65652.84
Iteration:   2440, Loss function: 3.192, Average Loss: 4.327, avg. samples / sec: 65649.08
Iteration:   2440, Loss function: 4.163, Average Loss: 4.346, avg. samples / sec: 65660.24
Iteration:   2440, Loss function: 3.875, Average Loss: 4.352, avg. samples / sec: 65702.06
Iteration:   2440, Loss function: 4.735, Average Loss: 4.339, avg. samples / sec: 65636.33
Iteration:   2440, Loss function: 4.057, Average Loss: 4.357, avg. samples / sec: 65739.82
Iteration:   2440, Loss function: 4.738, Average Loss: 4.330, avg. samples / sec: 65658.35
Iteration:   2440, Loss function: 5.284, Average Loss: 4.371, avg. samples / sec: 65764.24
Iteration:   2440, Loss function: 4.678, Average Loss: 4.338, avg. samples / sec: 65724.09
Iteration:   2440, Loss function: 3.666, Average Loss: 4.343, avg. samples / sec: 65575.73
Iteration:   2440, Loss function: 4.729, Average Loss: 4.326, avg. samples / sec: 65563.65
Iteration:   2440, Loss function: 3.325, Average Loss: 4.351, avg. samples / sec: 65670.86
Iteration:   2440, Loss function: 4.039, Average Loss: 4.342, avg. samples / sec: 65555.91
Iteration:   2440, Loss function: 4.547, Average Loss: 4.347, avg. samples / sec: 65619.12
Iteration:   2440, Loss function: 4.663, Average Loss: 4.355, avg. samples / sec: 65568.60
Iteration:   2440, Loss function: 4.824, Average Loss: 4.327, avg. samples / sec: 65572.93
Iteration:   2440, Loss function: 3.421, Average Loss: 4.334, avg. samples / sec: 65463.43
:::MLL 1558651758.041 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558651758.041 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 3.845, Average Loss: 4.337, avg. samples / sec: 65485.84
Iteration:   2460, Loss function: 3.252, Average Loss: 4.343, avg. samples / sec: 65508.31
Iteration:   2460, Loss function: 3.533, Average Loss: 4.361, avg. samples / sec: 65435.67
Iteration:   2460, Loss function: 3.822, Average Loss: 4.347, avg. samples / sec: 65461.81
Iteration:   2460, Loss function: 2.991, Average Loss: 4.311, avg. samples / sec: 65426.20
Iteration:   2460, Loss function: 3.859, Average Loss: 4.320, avg. samples / sec: 65556.43
Iteration:   2460, Loss function: 3.983, Average Loss: 4.340, avg. samples / sec: 65410.89
Iteration:   2460, Loss function: 3.387, Average Loss: 4.350, avg. samples / sec: 65349.47
Iteration:   2460, Loss function: 3.996, Average Loss: 4.314, avg. samples / sec: 65400.45
Iteration:   2460, Loss function: 4.480, Average Loss: 4.348, avg. samples / sec: 65593.25
Iteration:   2460, Loss function: 3.391, Average Loss: 4.364, avg. samples / sec: 65485.30
Iteration:   2460, Loss function: 3.459, Average Loss: 4.323, avg. samples / sec: 65440.96
Iteration:   2460, Loss function: 4.395, Average Loss: 4.320, avg. samples / sec: 65236.82
Iteration:   2460, Loss function: 2.774, Average Loss: 4.332, avg. samples / sec: 65442.39
Iteration:   2460, Loss function: 4.683, Average Loss: 4.326, avg. samples / sec: 65413.96
Iteration:   2460, Loss function: 4.696, Average Loss: 4.345, avg. samples / sec: 65478.24
Iteration:   2460, Loss function: 4.294, Average Loss: 4.332, avg. samples / sec: 65548.89
Iteration:   2460, Loss function: 5.373, Average Loss: 4.348, avg. samples / sec: 65414.63
Iteration:   2460, Loss function: 3.871, Average Loss: 4.320, avg. samples / sec: 65421.79
Iteration:   2460, Loss function: 4.087, Average Loss: 4.337, avg. samples / sec: 65389.43
Iteration:   2460, Loss function: 4.040, Average Loss: 4.339, avg. samples / sec: 65466.77
Iteration:   2460, Loss function: 5.256, Average Loss: 4.337, avg. samples / sec: 65270.47
Iteration:   2460, Loss function: 6.104, Average Loss: 4.331, avg. samples / sec: 65317.03
Iteration:   2460, Loss function: 4.444, Average Loss: 4.328, avg. samples / sec: 65254.52
Iteration:   2460, Loss function: 4.951, Average Loss: 4.323, avg. samples / sec: 65489.80
Iteration:   2460, Loss function: 4.110, Average Loss: 4.338, avg. samples / sec: 65267.63
Iteration:   2460, Loss function: 3.777, Average Loss: 4.330, avg. samples / sec: 65314.43
Iteration:   2460, Loss function: 4.430, Average Loss: 4.344, avg. samples / sec: 65349.89
Iteration:   2460, Loss function: 5.656, Average Loss: 4.353, avg. samples / sec: 65313.58
Iteration:   2460, Loss function: 4.678, Average Loss: 4.349, avg. samples / sec: 65354.20
Iteration:   2480, Loss function: 4.918, Average Loss: 4.346, avg. samples / sec: 66024.15
Iteration:   2480, Loss function: 4.194, Average Loss: 4.335, avg. samples / sec: 66110.84
Iteration:   2480, Loss function: 4.508, Average Loss: 4.345, avg. samples / sec: 65952.47
Iteration:   2480, Loss function: 5.228, Average Loss: 4.344, avg. samples / sec: 65978.80
Iteration:   2480, Loss function: 3.891, Average Loss: 4.316, avg. samples / sec: 66040.52
Iteration:   2480, Loss function: 4.246, Average Loss: 4.314, avg. samples / sec: 66008.44
Iteration:   2480, Loss function: 3.688, Average Loss: 4.333, avg. samples / sec: 66055.56
Iteration:   2480, Loss function: 5.243, Average Loss: 4.330, avg. samples / sec: 65889.50
Iteration:   2480, Loss function: 4.515, Average Loss: 4.313, avg. samples / sec: 65954.81
Iteration:   2480, Loss function: 4.300, Average Loss: 4.342, avg. samples / sec: 66116.61
Iteration:   2480, Loss function: 3.904, Average Loss: 4.319, avg. samples / sec: 65919.89
Iteration:   2480, Loss function: 4.558, Average Loss: 4.305, avg. samples / sec: 65893.38
Iteration:   2480, Loss function: 4.340, Average Loss: 4.359, avg. samples / sec: 65883.96
Iteration:   2480, Loss function: 4.317, Average Loss: 4.332, avg. samples / sec: 65972.26
Iteration:   2480, Loss function: 2.170, Average Loss: 4.319, avg. samples / sec: 65907.22
Iteration:   2480, Loss function: 3.789, Average Loss: 4.334, avg. samples / sec: 65981.99
Iteration:   2480, Loss function: 4.387, Average Loss: 4.320, avg. samples / sec: 66000.90
Iteration:   2480, Loss function: 3.556, Average Loss: 4.343, avg. samples / sec: 65934.85
Iteration:   2480, Loss function: 4.814, Average Loss: 4.325, avg. samples / sec: 65896.86
Iteration:   2480, Loss function: 4.554, Average Loss: 4.341, avg. samples / sec: 65796.44
Iteration:   2480, Loss function: 4.963, Average Loss: 4.322, avg. samples / sec: 65973.43
Iteration:   2480, Loss function: 5.163, Average Loss: 4.330, avg. samples / sec: 65815.07
Iteration:   2480, Loss function: 3.920, Average Loss: 4.345, avg. samples / sec: 66052.77
Iteration:   2480, Loss function: 4.286, Average Loss: 4.330, avg. samples / sec: 65950.12
Iteration:   2480, Loss function: 4.251, Average Loss: 4.330, avg. samples / sec: 65873.79
Iteration:   2480, Loss function: 4.021, Average Loss: 4.354, avg. samples / sec: 65969.26
Iteration:   2480, Loss function: 4.093, Average Loss: 4.346, avg. samples / sec: 65862.53
Iteration:   2480, Loss function: 4.600, Average Loss: 4.334, avg. samples / sec: 65872.22
Iteration:   2480, Loss function: 3.259, Average Loss: 4.324, avg. samples / sec: 65788.55
Iteration:   2480, Loss function: 3.707, Average Loss: 4.356, avg. samples / sec: 65713.27
Iteration:   2500, Loss function: 4.509, Average Loss: 4.328, avg. samples / sec: 65898.03
Iteration:   2500, Loss function: 3.732, Average Loss: 4.299, avg. samples / sec: 65922.32
Iteration:   2500, Loss function: 3.498, Average Loss: 4.328, avg. samples / sec: 65849.60
Iteration:   2500, Loss function: 3.735, Average Loss: 4.337, avg. samples / sec: 65967.75
Iteration:   2500, Loss function: 2.797, Average Loss: 4.306, avg. samples / sec: 65860.00
Iteration:   2500, Loss function: 5.597, Average Loss: 4.320, avg. samples / sec: 65916.71
Iteration:   2500, Loss function: 3.596, Average Loss: 4.355, avg. samples / sec: 65871.61
Iteration:   2500, Loss function: 3.438, Average Loss: 4.315, avg. samples / sec: 65840.34
Iteration:   2500, Loss function: 3.635, Average Loss: 4.338, avg. samples / sec: 65738.44
Iteration:   2500, Loss function: 3.514, Average Loss: 4.324, avg. samples / sec: 65861.88
Iteration:   2500, Loss function: 3.514, Average Loss: 4.319, avg. samples / sec: 65864.22
Iteration:   2500, Loss function: 4.204, Average Loss: 4.342, avg. samples / sec: 65754.57
Iteration:   2500, Loss function: 5.137, Average Loss: 4.309, avg. samples / sec: 65763.47
Iteration:   2500, Loss function: 3.938, Average Loss: 4.321, avg. samples / sec: 65874.90
Iteration:   2500, Loss function: 2.856, Average Loss: 4.343, avg. samples / sec: 65834.68
Iteration:   2500, Loss function: 3.127, Average Loss: 4.344, avg. samples / sec: 65742.55
Iteration:   2500, Loss function: 3.989, Average Loss: 4.313, avg. samples / sec: 65717.65
Iteration:   2500, Loss function: 3.738, Average Loss: 4.329, avg. samples / sec: 65896.34
Iteration:   2500, Loss function: 3.790, Average Loss: 4.340, avg. samples / sec: 65857.11
Iteration:   2500, Loss function: 4.006, Average Loss: 4.332, avg. samples / sec: 65785.39
Iteration:   2500, Loss function: 4.476, Average Loss: 4.342, avg. samples / sec: 65670.95
Iteration:   2500, Loss function: 3.762, Average Loss: 4.351, avg. samples / sec: 65863.11
Iteration:   2500, Loss function: 3.320, Average Loss: 4.336, avg. samples / sec: 65866.74
Iteration:   2500, Loss function: 3.854, Average Loss: 4.332, avg. samples / sec: 65816.36
Iteration:   2500, Loss function: 2.775, Average Loss: 4.318, avg. samples / sec: 65961.91
Iteration:   2500, Loss function: 3.904, Average Loss: 4.325, avg. samples / sec: 65657.86
Iteration:   2500, Loss function: 4.593, Average Loss: 4.348, avg. samples / sec: 65932.41
Iteration:   2500, Loss function: 3.659, Average Loss: 4.325, avg. samples / sec: 65815.34
Iteration:   2500, Loss function: 3.689, Average Loss: 4.322, avg. samples / sec: 65745.58
Iteration:   2500, Loss function: 3.181, Average Loss: 4.316, avg. samples / sec: 65600.61
:::MLL 1558651759.835 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558651759.835 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 3.692, Average Loss: 4.296, avg. samples / sec: 64888.26
Iteration:   2520, Loss function: 4.057, Average Loss: 4.327, avg. samples / sec: 64874.22
Iteration:   2520, Loss function: 3.517, Average Loss: 4.332, avg. samples / sec: 65051.20
Iteration:   2520, Loss function: 3.620, Average Loss: 4.352, avg. samples / sec: 64938.14
Iteration:   2520, Loss function: 4.528, Average Loss: 4.331, avg. samples / sec: 64922.85
Iteration:   2520, Loss function: 3.627, Average Loss: 4.319, avg. samples / sec: 65085.33
Iteration:   2520, Loss function: 3.648, Average Loss: 4.324, avg. samples / sec: 64856.04
Iteration:   2520, Loss function: 4.030, Average Loss: 4.304, avg. samples / sec: 64848.64
Iteration:   2520, Loss function: 3.149, Average Loss: 4.306, avg. samples / sec: 64893.43
Iteration:   2520, Loss function: 3.813, Average Loss: 4.316, avg. samples / sec: 64864.10
Iteration:   2520, Loss function: 5.268, Average Loss: 4.336, avg. samples / sec: 64981.76
Iteration:   2520, Loss function: 3.693, Average Loss: 4.338, avg. samples / sec: 64962.26
Iteration:   2520, Loss function: 4.670, Average Loss: 4.313, avg. samples / sec: 64914.42
Iteration:   2520, Loss function: 4.401, Average Loss: 4.304, avg. samples / sec: 64907.42
Iteration:   2520, Loss function: 4.965, Average Loss: 4.331, avg. samples / sec: 64803.88
Iteration:   2520, Loss function: 3.745, Average Loss: 4.320, avg. samples / sec: 65024.34
Iteration:   2520, Loss function: 5.482, Average Loss: 4.337, avg. samples / sec: 64881.93
Iteration:   2520, Loss function: 3.146, Average Loss: 4.315, avg. samples / sec: 64957.35
Iteration:   2520, Loss function: 3.703, Average Loss: 4.324, avg. samples / sec: 64918.99
Iteration:   2520, Loss function: 4.710, Average Loss: 4.325, avg. samples / sec: 64929.58
Iteration:   2520, Loss function: 3.358, Average Loss: 4.308, avg. samples / sec: 64866.52
Iteration:   2520, Loss function: 5.232, Average Loss: 4.338, avg. samples / sec: 64868.37
Iteration:   2520, Loss function: 4.926, Average Loss: 4.342, avg. samples / sec: 64893.40
Iteration:   2520, Loss function: 4.667, Average Loss: 4.328, avg. samples / sec: 64871.45
Iteration:   2520, Loss function: 3.690, Average Loss: 4.347, avg. samples / sec: 64867.54
Iteration:   2520, Loss function: 4.615, Average Loss: 4.313, avg. samples / sec: 64770.11
Iteration:   2520, Loss function: 3.810, Average Loss: 4.318, avg. samples / sec: 64727.75
Iteration:   2520, Loss function: 3.277, Average Loss: 4.336, avg. samples / sec: 64802.99
Iteration:   2520, Loss function: 3.861, Average Loss: 4.313, avg. samples / sec: 65011.68
Iteration:   2520, Loss function: 5.029, Average Loss: 4.315, avg. samples / sec: 64914.78
Iteration:   2540, Loss function: 3.572, Average Loss: 4.324, avg. samples / sec: 65889.62
Iteration:   2540, Loss function: 3.705, Average Loss: 4.297, avg. samples / sec: 65835.54
Iteration:   2540, Loss function: 3.012, Average Loss: 4.344, avg. samples / sec: 65767.34
Iteration:   2540, Loss function: 5.536, Average Loss: 4.330, avg. samples / sec: 65839.60
Iteration:   2540, Loss function: 4.136, Average Loss: 4.319, avg. samples / sec: 65747.05
Iteration:   2540, Loss function: 3.883, Average Loss: 4.324, avg. samples / sec: 65714.16
Iteration:   2540, Loss function: 4.945, Average Loss: 4.334, avg. samples / sec: 65799.95
Iteration:   2540, Loss function: 3.781, Average Loss: 4.302, avg. samples / sec: 65756.50
Iteration:   2540, Loss function: 3.605, Average Loss: 4.290, avg. samples / sec: 65695.04
Iteration:   2540, Loss function: 3.651, Average Loss: 4.331, avg. samples / sec: 65784.77
Iteration:   2540, Loss function: 4.740, Average Loss: 4.304, avg. samples / sec: 65869.14
Iteration:   2540, Loss function: 3.934, Average Loss: 4.323, avg. samples / sec: 65792.91
Iteration:   2540, Loss function: 3.202, Average Loss: 4.312, avg. samples / sec: 65797.95
Iteration:   2540, Loss function: 3.331, Average Loss: 4.326, avg. samples / sec: 65745.86
Iteration:   2540, Loss function: 4.109, Average Loss: 4.322, avg. samples / sec: 65870.25
Iteration:   2540, Loss function: 4.006, Average Loss: 4.310, avg. samples / sec: 65721.91
Iteration:   2540, Loss function: 3.710, Average Loss: 4.335, avg. samples / sec: 65852.31
Iteration:   2540, Loss function: 4.955, Average Loss: 4.335, avg. samples / sec: 65884.14
Iteration:   2540, Loss function: 3.097, Average Loss: 4.301, avg. samples / sec: 65909.31
Iteration:   2540, Loss function: 2.962, Average Loss: 4.316, avg. samples / sec: 65765.43
Iteration:   2540, Loss function: 4.278, Average Loss: 4.309, avg. samples / sec: 65809.23
Iteration:   2540, Loss function: 4.544, Average Loss: 4.325, avg. samples / sec: 65593.96
Iteration:   2540, Loss function: 4.255, Average Loss: 4.315, avg. samples / sec: 65813.44
Iteration:   2540, Loss function: 4.658, Average Loss: 4.332, avg. samples / sec: 65761.04
Iteration:   2540, Loss function: 4.583, Average Loss: 4.309, avg. samples / sec: 65839.82
Iteration:   2540, Loss function: 4.708, Average Loss: 4.305, avg. samples / sec: 65646.97
Iteration:   2540, Loss function: 4.174, Average Loss: 4.345, avg. samples / sec: 65754.11
Iteration:   2540, Loss function: 4.787, Average Loss: 4.308, avg. samples / sec: 65628.38
Iteration:   2540, Loss function: 3.538, Average Loss: 4.317, avg. samples / sec: 65542.52
Iteration:   2540, Loss function: 4.438, Average Loss: 4.323, avg. samples / sec: 65601.13
Iteration:   2560, Loss function: 3.204, Average Loss: 4.310, avg. samples / sec: 66053.49
Iteration:   2560, Loss function: 3.566, Average Loss: 4.285, avg. samples / sec: 66034.20
Iteration:   2560, Loss function: 3.096, Average Loss: 4.310, avg. samples / sec: 66072.69
Iteration:   2560, Loss function: 3.896, Average Loss: 4.317, avg. samples / sec: 65933.49
Iteration:   2560, Loss function: 3.167, Average Loss: 4.319, avg. samples / sec: 66017.41
Iteration:   2560, Loss function: 4.203, Average Loss: 4.313, avg. samples / sec: 65793.25
Iteration:   2560, Loss function: 4.014, Average Loss: 4.338, avg. samples / sec: 65881.18
Iteration:   2560, Loss function: 4.196, Average Loss: 4.322, avg. samples / sec: 65967.25
Iteration:   2560, Loss function: 3.031, Average Loss: 4.293, avg. samples / sec: 65928.86
Iteration:   2560, Loss function: 3.782, Average Loss: 4.327, avg. samples / sec: 65886.42
Iteration:   2560, Loss function: 4.748, Average Loss: 4.332, avg. samples / sec: 65902.07
Iteration:   2560, Loss function: 4.000, Average Loss: 4.320, avg. samples / sec: 66009.40
Iteration:   2560, Loss function: 3.680, Average Loss: 4.305, avg. samples / sec: 65977.48
Iteration:   2560, Loss function: 3.736, Average Loss: 4.305, avg. samples / sec: 66003.96
Iteration:   2560, Loss function: 4.437, Average Loss: 4.346, avg. samples / sec: 66021.46
Iteration:   2560, Loss function: 4.338, Average Loss: 4.299, avg. samples / sec: 65995.58
Iteration:   2560, Loss function: 4.359, Average Loss: 4.292, avg. samples / sec: 65787.66
Iteration:   2560, Loss function: 4.696, Average Loss: 4.309, avg. samples / sec: 65960.74
Iteration:   2560, Loss function: 3.256, Average Loss: 4.302, avg. samples / sec: 66024.34
Iteration:   2560, Loss function: 5.282, Average Loss: 4.300, avg. samples / sec: 65891.07
Iteration:   2560, Loss function: 5.348, Average Loss: 4.328, avg. samples / sec: 65945.00
Iteration:   2560, Loss function: 4.873, Average Loss: 4.296, avg. samples / sec: 65890.09
Iteration:   2560, Loss function: 4.906, Average Loss: 4.299, avg. samples / sec: 65825.52
Iteration:   2560, Loss function: 3.922, Average Loss: 4.323, avg. samples / sec: 65870.04
Iteration:   2560, Loss function: 3.231, Average Loss: 4.319, avg. samples / sec: 66000.96
Iteration:   2560, Loss function: 3.195, Average Loss: 4.323, avg. samples / sec: 65764.27
Iteration:   2560, Loss function: 3.729, Average Loss: 4.315, avg. samples / sec: 65843.82
Iteration:   2560, Loss function: 2.768, Average Loss: 4.325, avg. samples / sec: 65816.66
Iteration:   2560, Loss function: 4.064, Average Loss: 4.316, avg. samples / sec: 65899.45
Iteration:   2560, Loss function: 3.118, Average Loss: 4.309, avg. samples / sec: 65744.36
Iteration:   2580, Loss function: 5.584, Average Loss: 4.290, avg. samples / sec: 66206.72
Iteration:   2580, Loss function: 3.701, Average Loss: 4.313, avg. samples / sec: 66010.36
Iteration:   2580, Loss function: 4.077, Average Loss: 4.305, avg. samples / sec: 66143.95
Iteration:   2580, Loss function: 4.230, Average Loss: 4.307, avg. samples / sec: 65872.16
Iteration:   2580, Loss function: 4.697, Average Loss: 4.304, avg. samples / sec: 65932.47
Iteration:   2580, Loss function: 3.577, Average Loss: 4.331, avg. samples / sec: 66026.38
Iteration:   2580, Loss function: 4.118, Average Loss: 4.298, avg. samples / sec: 66192.79
Iteration:   2580, Loss function: 3.677, Average Loss: 4.292, avg. samples / sec: 66077.24
Iteration:   2580, Loss function: 3.443, Average Loss: 4.301, avg. samples / sec: 66064.11
Iteration:   2580, Loss function: 4.520, Average Loss: 4.316, avg. samples / sec: 66095.40
Iteration:   2580, Loss function: 4.339, Average Loss: 4.307, avg. samples / sec: 65941.51
Iteration:   2580, Loss function: 3.622, Average Loss: 4.289, avg. samples / sec: 66047.70
Iteration:   2580, Loss function: 4.628, Average Loss: 4.302, avg. samples / sec: 66044.60
Iteration:   2580, Loss function: 3.927, Average Loss: 4.318, avg. samples / sec: 66091.59
Iteration:   2580, Loss function: 4.874, Average Loss: 4.331, avg. samples / sec: 65929.85
Iteration:   2580, Loss function: 3.093, Average Loss: 4.325, avg. samples / sec: 66113.39
Iteration:   2580, Loss function: 3.278, Average Loss: 4.279, avg. samples / sec: 65825.64
Iteration:   2580, Loss function: 4.688, Average Loss: 4.320, avg. samples / sec: 66052.22
Iteration:   2580, Loss function: 3.756, Average Loss: 4.320, avg. samples / sec: 65948.39
Iteration:   2580, Loss function: 2.579, Average Loss: 4.307, avg. samples / sec: 65892.61
Iteration:   2580, Loss function: 3.806, Average Loss: 4.321, avg. samples / sec: 65939.69
Iteration:   2580, Loss function: 4.736, Average Loss: 4.302, avg. samples / sec: 65959.35
Iteration:   2580, Loss function: 5.248, Average Loss: 4.299, avg. samples / sec: 65959.60
Iteration:   2580, Loss function: 3.522, Average Loss: 4.288, avg. samples / sec: 65883.77
Iteration:   2580, Loss function: 3.534, Average Loss: 4.302, avg. samples / sec: 66097.70
Iteration:   2580, Loss function: 3.437, Average Loss: 4.315, avg. samples / sec: 65925.93
Iteration:   2580, Loss function: 5.185, Average Loss: 4.292, avg. samples / sec: 65996.01
Iteration:   2580, Loss function: 2.456, Average Loss: 4.300, avg. samples / sec: 65919.18
Iteration:   2580, Loss function: 2.995, Average Loss: 4.324, avg. samples / sec: 65924.11
Iteration:   2580, Loss function: 4.521, Average Loss: 4.342, avg. samples / sec: 65812.18
:::MLL 1558651761.622 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558651761.623 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 3.522, Average Loss: 4.315, avg. samples / sec: 65180.66
Iteration:   2600, Loss function: 3.358, Average Loss: 4.286, avg. samples / sec: 64973.55
Iteration:   2600, Loss function: 3.206, Average Loss: 4.288, avg. samples / sec: 65144.21
Iteration:   2600, Loss function: 4.090, Average Loss: 4.300, avg. samples / sec: 65185.79
Iteration:   2600, Loss function: 4.397, Average Loss: 4.270, avg. samples / sec: 65146.35
Iteration:   2600, Loss function: 4.042, Average Loss: 4.298, avg. samples / sec: 65089.99
Iteration:   2600, Loss function: 4.824, Average Loss: 4.297, avg. samples / sec: 65147.10
Iteration:   2600, Loss function: 4.717, Average Loss: 4.316, avg. samples / sec: 65084.19
Iteration:   2600, Loss function: 3.706, Average Loss: 4.307, avg. samples / sec: 65024.28
Iteration:   2600, Loss function: 5.169, Average Loss: 4.333, avg. samples / sec: 65081.90
Iteration:   2600, Loss function: 3.309, Average Loss: 4.296, avg. samples / sec: 65011.32
Iteration:   2600, Loss function: 3.972, Average Loss: 4.328, avg. samples / sec: 65012.37
Iteration:   2600, Loss function: 2.558, Average Loss: 4.289, avg. samples / sec: 64970.98
Iteration:   2600, Loss function: 3.217, Average Loss: 4.299, avg. samples / sec: 65025.33
Iteration:   2600, Loss function: 3.266, Average Loss: 4.293, avg. samples / sec: 65026.08
Iteration:   2600, Loss function: 3.410, Average Loss: 4.283, avg. samples / sec: 65106.56
Iteration:   2600, Loss function: 4.075, Average Loss: 4.312, avg. samples / sec: 65120.22
Iteration:   2600, Loss function: 4.658, Average Loss: 4.316, avg. samples / sec: 65159.99
Iteration:   2600, Loss function: 4.112, Average Loss: 4.287, avg. samples / sec: 65002.29
Iteration:   2600, Loss function: 4.550, Average Loss: 4.319, avg. samples / sec: 65030.31
Iteration:   2600, Loss function: 3.983, Average Loss: 4.296, avg. samples / sec: 65119.19
Iteration:   2600, Loss function: 3.470, Average Loss: 4.313, avg. samples / sec: 65043.40
Iteration:   2600, Loss function: 3.453, Average Loss: 4.296, avg. samples / sec: 65053.87
Iteration:   2600, Loss function: 4.438, Average Loss: 4.288, avg. samples / sec: 65047.21
Iteration:   2600, Loss function: 4.178, Average Loss: 4.305, avg. samples / sec: 64912.02
Iteration:   2600, Loss function: 3.755, Average Loss: 4.292, avg. samples / sec: 64942.30
Iteration:   2600, Loss function: 4.704, Average Loss: 4.296, avg. samples / sec: 64999.39
Iteration:   2600, Loss function: 4.420, Average Loss: 4.344, avg. samples / sec: 65124.43
Iteration:   2600, Loss function: 2.953, Average Loss: 4.309, avg. samples / sec: 64867.89
Iteration:   2600, Loss function: 3.100, Average Loss: 4.314, avg. samples / sec: 64880.59
Iteration:   2620, Loss function: 4.177, Average Loss: 4.308, avg. samples / sec: 66293.27
Iteration:   2620, Loss function: 4.058, Average Loss: 4.300, avg. samples / sec: 66064.57
Iteration:   2620, Loss function: 4.045, Average Loss: 4.295, avg. samples / sec: 66085.51
Iteration:   2620, Loss function: 5.032, Average Loss: 4.294, avg. samples / sec: 66072.59
Iteration:   2620, Loss function: 3.731, Average Loss: 4.311, avg. samples / sec: 66089.51
Iteration:   2620, Loss function: 3.433, Average Loss: 4.305, avg. samples / sec: 66009.80
Iteration:   2620, Loss function: 2.432, Average Loss: 4.288, avg. samples / sec: 66160.00
Iteration:   2620, Loss function: 3.582, Average Loss: 4.337, avg. samples / sec: 66171.09
Iteration:   2620, Loss function: 2.867, Average Loss: 4.298, avg. samples / sec: 65971.89
Iteration:   2620, Loss function: 3.726, Average Loss: 4.282, avg. samples / sec: 65918.41
Iteration:   2620, Loss function: 2.644, Average Loss: 4.267, avg. samples / sec: 65943.18
Iteration:   2620, Loss function: 3.650, Average Loss: 4.296, avg. samples / sec: 65888.30
Iteration:   2620, Loss function: 4.011, Average Loss: 4.315, avg. samples / sec: 66017.13
Iteration:   2620, Loss function: 4.087, Average Loss: 4.282, avg. samples / sec: 66010.76
Iteration:   2620, Loss function: 3.910, Average Loss: 4.305, avg. samples / sec: 65988.50
Iteration:   2620, Loss function: 4.426, Average Loss: 4.286, avg. samples / sec: 65868.68
Iteration:   2620, Loss function: 5.063, Average Loss: 4.294, avg. samples / sec: 65936.79
Iteration:   2620, Loss function: 4.538, Average Loss: 4.284, avg. samples / sec: 66030.58
Iteration:   2620, Loss function: 2.975, Average Loss: 4.285, avg. samples / sec: 66025.29
Iteration:   2620, Loss function: 3.408, Average Loss: 4.296, avg. samples / sec: 65997.62
Iteration:   2620, Loss function: 4.234, Average Loss: 4.326, avg. samples / sec: 65932.75
Iteration:   2620, Loss function: 4.240, Average Loss: 4.287, avg. samples / sec: 66014.44
Iteration:   2620, Loss function: 2.971, Average Loss: 4.323, avg. samples / sec: 65906.32
Iteration:   2620, Loss function: 3.912, Average Loss: 4.306, avg. samples / sec: 66087.71
Iteration:   2620, Loss function: 3.015, Average Loss: 4.301, avg. samples / sec: 65943.33
Iteration:   2620, Loss function: 3.958, Average Loss: 4.277, avg. samples / sec: 65944.75
Iteration:   2620, Loss function: 4.650, Average Loss: 4.291, avg. samples / sec: 65921.65
Iteration:   2620, Loss function: 3.285, Average Loss: 4.314, avg. samples / sec: 65766.45
Iteration:   2620, Loss function: 3.908, Average Loss: 4.283, avg. samples / sec: 65901.79
Iteration:   2620, Loss function: 3.981, Average Loss: 4.295, avg. samples / sec: 65854.71
Iteration:   2640, Loss function: 3.358, Average Loss: 4.284, avg. samples / sec: 65462.33
Iteration:   2640, Loss function: 4.222, Average Loss: 4.294, avg. samples / sec: 65330.57
Iteration:   2640, Loss function: 4.982, Average Loss: 4.286, avg. samples / sec: 65398.90
Iteration:   2640, Loss function: 4.376, Average Loss: 4.290, avg. samples / sec: 65335.56
Iteration:   2640, Loss function: 3.128, Average Loss: 4.263, avg. samples / sec: 65376.72
Iteration:   2640, Loss function: 4.839, Average Loss: 4.338, avg. samples / sec: 65331.20
Iteration:   2640, Loss function: 4.132, Average Loss: 4.296, avg. samples / sec: 65342.38
Iteration:   2640, Loss function: 3.645, Average Loss: 4.298, avg. samples / sec: 65474.74
Iteration:   2640, Loss function: 4.453, Average Loss: 4.292, avg. samples / sec: 65377.21
Iteration:   2640, Loss function: 3.004, Average Loss: 4.278, avg. samples / sec: 65365.11
Iteration:   2640, Loss function: 4.757, Average Loss: 4.290, avg. samples / sec: 65290.70
Iteration:   2640, Loss function: 3.345, Average Loss: 4.295, avg. samples / sec: 65295.21
Iteration:   2640, Loss function: 4.297, Average Loss: 4.318, avg. samples / sec: 65407.46
Iteration:   2640, Loss function: 3.818, Average Loss: 4.282, avg. samples / sec: 65454.94
Iteration:   2640, Loss function: 4.672, Average Loss: 4.304, avg. samples / sec: 65213.81
Iteration:   2640, Loss function: 4.579, Average Loss: 4.326, avg. samples / sec: 65390.10
Iteration:   2640, Loss function: 3.767, Average Loss: 4.312, avg. samples / sec: 65353.41
Iteration:   2640, Loss function: 3.640, Average Loss: 4.289, avg. samples / sec: 65335.53
Iteration:   2640, Loss function: 4.402, Average Loss: 4.287, avg. samples / sec: 65379.15
Iteration:   2640, Loss function: 3.456, Average Loss: 4.299, avg. samples / sec: 65437.22
Iteration:   2640, Loss function: 3.640, Average Loss: 4.294, avg. samples / sec: 65440.20
Iteration:   2640, Loss function: 6.545, Average Loss: 4.277, avg. samples / sec: 65370.78
Iteration:   2640, Loss function: 4.189, Average Loss: 4.310, avg. samples / sec: 65390.01
Iteration:   2640, Loss function: 4.494, Average Loss: 4.306, avg. samples / sec: 65213.30
Iteration:   2640, Loss function: 4.689, Average Loss: 4.281, avg. samples / sec: 65291.88
Iteration:   2640, Loss function: 4.156, Average Loss: 4.304, avg. samples / sec: 65237.90
Iteration:   2640, Loss function: 3.772, Average Loss: 4.282, avg. samples / sec: 65238.39
Iteration:   2640, Loss function: 4.535, Average Loss: 4.288, avg. samples / sec: 65263.34
Iteration:   2640, Loss function: 3.321, Average Loss: 4.280, avg. samples / sec: 65116.34
Iteration:   2640, Loss function: 3.912, Average Loss: 4.277, avg. samples / sec: 65135.27
:::MLL 1558651763.418 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558651763.418 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 4.359, Average Loss: 4.288, avg. samples / sec: 65606.51
Iteration:   2660, Loss function: 4.079, Average Loss: 4.279, avg. samples / sec: 65546.24
Iteration:   2660, Loss function: 3.943, Average Loss: 4.282, avg. samples / sec: 65564.23
Iteration:   2660, Loss function: 3.647, Average Loss: 4.304, avg. samples / sec: 65640.39
Iteration:   2660, Loss function: 4.423, Average Loss: 4.283, avg. samples / sec: 65695.20
Iteration:   2660, Loss function: 5.179, Average Loss: 4.282, avg. samples / sec: 65615.06
Iteration:   2660, Loss function: 3.728, Average Loss: 4.269, avg. samples / sec: 65635.47
Iteration:   2660, Loss function: 2.678, Average Loss: 4.276, avg. samples / sec: 65567.22
Iteration:   2660, Loss function: 4.397, Average Loss: 4.262, avg. samples / sec: 65490.38
Iteration:   2660, Loss function: 4.096, Average Loss: 4.300, avg. samples / sec: 65536.09
Iteration:   2660, Loss function: 4.253, Average Loss: 4.292, avg. samples / sec: 65441.72
Iteration:   2660, Loss function: 4.550, Average Loss: 4.297, avg. samples / sec: 65547.49
Iteration:   2660, Loss function: 3.939, Average Loss: 4.320, avg. samples / sec: 65528.26
Iteration:   2660, Loss function: 4.707, Average Loss: 4.273, avg. samples / sec: 65658.56
Iteration:   2660, Loss function: 4.122, Average Loss: 4.281, avg. samples / sec: 65407.07
Iteration:   2660, Loss function: 4.095, Average Loss: 4.305, avg. samples / sec: 65556.85
Iteration:   2660, Loss function: 4.815, Average Loss: 4.290, avg. samples / sec: 65458.26
Iteration:   2660, Loss function: 3.883, Average Loss: 4.288, avg. samples / sec: 65449.93
Iteration:   2660, Loss function: 4.201, Average Loss: 4.332, avg. samples / sec: 65459.41
Iteration:   2660, Loss function: 3.551, Average Loss: 4.280, avg. samples / sec: 65502.22
Iteration:   2660, Loss function: 2.980, Average Loss: 4.312, avg. samples / sec: 65473.95
Iteration:   2660, Loss function: 3.060, Average Loss: 4.292, avg. samples / sec: 65432.00
Iteration:   2660, Loss function: 3.666, Average Loss: 4.285, avg. samples / sec: 65600.28
Iteration:   2660, Loss function: 4.112, Average Loss: 4.288, avg. samples / sec: 65494.73
Iteration:   2660, Loss function: 5.618, Average Loss: 4.290, avg. samples / sec: 65473.64
Iteration:   2660, Loss function: 4.489, Average Loss: 4.271, avg. samples / sec: 65588.28
Iteration:   2660, Loss function: 3.808, Average Loss: 4.304, avg. samples / sec: 65465.55
Iteration:   2660, Loss function: 5.028, Average Loss: 4.269, avg. samples / sec: 65356.92
Iteration:   2660, Loss function: 3.872, Average Loss: 4.298, avg. samples / sec: 65462.36
Iteration:   2660, Loss function: 4.197, Average Loss: 4.279, avg. samples / sec: 65617.84
Iteration:   2680, Loss function: 3.337, Average Loss: 4.287, avg. samples / sec: 65898.44
Iteration:   2680, Loss function: 4.123, Average Loss: 4.282, avg. samples / sec: 65727.77
Iteration:   2680, Loss function: 4.808, Average Loss: 4.284, avg. samples / sec: 65906.54
Iteration:   2680, Loss function: 4.819, Average Loss: 4.307, avg. samples / sec: 65853.26
Iteration:   2680, Loss function: 5.152, Average Loss: 4.283, avg. samples / sec: 65861.97
Iteration:   2680, Loss function: 3.870, Average Loss: 4.273, avg. samples / sec: 65824.90
Iteration:   2680, Loss function: 3.556, Average Loss: 4.293, avg. samples / sec: 65805.78
Iteration:   2680, Loss function: 4.834, Average Loss: 4.294, avg. samples / sec: 65744.75
Iteration:   2680, Loss function: 3.164, Average Loss: 4.273, avg. samples / sec: 65653.45
Iteration:   2680, Loss function: 3.488, Average Loss: 4.314, avg. samples / sec: 65757.61
Iteration:   2680, Loss function: 3.582, Average Loss: 4.275, avg. samples / sec: 65751.63
Iteration:   2680, Loss function: 4.158, Average Loss: 4.272, avg. samples / sec: 65698.81
Iteration:   2680, Loss function: 3.112, Average Loss: 4.269, avg. samples / sec: 65751.50
Iteration:   2680, Loss function: 3.779, Average Loss: 4.266, avg. samples / sec: 65884.05
Iteration:   2680, Loss function: 2.628, Average Loss: 4.284, avg. samples / sec: 65790.18
Iteration:   2680, Loss function: 4.455, Average Loss: 4.322, avg. samples / sec: 65750.24
Iteration:   2680, Loss function: 4.619, Average Loss: 4.294, avg. samples / sec: 65719.61
Iteration:   2680, Loss function: 4.918, Average Loss: 4.277, avg. samples / sec: 65619.67
Iteration:   2680, Loss function: 3.532, Average Loss: 4.289, avg. samples / sec: 65911.66
Iteration:   2680, Loss function: 4.146, Average Loss: 4.279, avg. samples / sec: 65599.91
Iteration:   2680, Loss function: 4.168, Average Loss: 4.287, avg. samples / sec: 65748.07
Iteration:   2680, Loss function: 4.161, Average Loss: 4.288, avg. samples / sec: 65721.30
Iteration:   2680, Loss function: 5.032, Average Loss: 4.298, avg. samples / sec: 65818.35
Iteration:   2680, Loss function: 4.206, Average Loss: 4.258, avg. samples / sec: 65639.39
Iteration:   2680, Loss function: 4.734, Average Loss: 4.296, avg. samples / sec: 65561.15
Iteration:   2680, Loss function: 4.847, Average Loss: 4.276, avg. samples / sec: 65877.30
Iteration:   2680, Loss function: 3.225, Average Loss: 4.283, avg. samples / sec: 65732.12
Iteration:   2680, Loss function: 3.586, Average Loss: 4.268, avg. samples / sec: 65591.82
Iteration:   2680, Loss function: 3.423, Average Loss: 4.268, avg. samples / sec: 65713.18
Iteration:   2680, Loss function: 4.715, Average Loss: 4.276, avg. samples / sec: 65519.21
Iteration:   2700, Loss function: 4.826, Average Loss: 4.266, avg. samples / sec: 66062.47
Iteration:   2700, Loss function: 5.140, Average Loss: 4.284, avg. samples / sec: 65989.37
Iteration:   2700, Loss function: 4.180, Average Loss: 4.282, avg. samples / sec: 65877.58
Iteration:   2700, Loss function: 3.643, Average Loss: 4.271, avg. samples / sec: 65985.57
Iteration:   2700, Loss function: 3.761, Average Loss: 4.309, avg. samples / sec: 65928.46
Iteration:   2700, Loss function: 4.683, Average Loss: 4.302, avg. samples / sec: 65888.11
Iteration:   2700, Loss function: 4.492, Average Loss: 4.290, avg. samples / sec: 65988.94
Iteration:   2700, Loss function: 4.255, Average Loss: 4.256, avg. samples / sec: 66016.42
Iteration:   2700, Loss function: 4.149, Average Loss: 4.267, avg. samples / sec: 65952.19
Iteration:   2700, Loss function: 3.201, Average Loss: 4.295, avg. samples / sec: 65983.81
Iteration:   2700, Loss function: 3.242, Average Loss: 4.269, avg. samples / sec: 66075.78
Iteration:   2700, Loss function: 2.825, Average Loss: 4.283, avg. samples / sec: 65969.79
Iteration:   2700, Loss function: 4.513, Average Loss: 4.284, avg. samples / sec: 65822.87
Iteration:   2700, Loss function: 3.895, Average Loss: 4.263, avg. samples / sec: 65918.50
Iteration:   2700, Loss function: 4.324, Average Loss: 4.283, avg. samples / sec: 65721.97
Iteration:   2700, Loss function: 3.236, Average Loss: 4.286, avg. samples / sec: 65892.06
Iteration:   2700, Loss function: 3.602, Average Loss: 4.290, avg. samples / sec: 65847.60
Iteration:   2700, Loss function: 3.723, Average Loss: 4.260, avg. samples / sec: 66021.21
Iteration:   2700, Loss function: 4.880, Average Loss: 4.271, avg. samples / sec: 65841.39
Iteration:   2700, Loss function: 4.391, Average Loss: 4.268, avg. samples / sec: 65971.08
Iteration:   2700, Loss function: 3.813, Average Loss: 4.278, avg. samples / sec: 65857.72
Iteration:   2700, Loss function: 3.994, Average Loss: 4.287, avg. samples / sec: 65808.49
Iteration:   2700, Loss function: 4.754, Average Loss: 4.279, avg. samples / sec: 65899.91
Iteration:   2700, Loss function: 3.618, Average Loss: 4.270, avg. samples / sec: 65839.54
Iteration:   2700, Loss function: 4.260, Average Loss: 4.284, avg. samples / sec: 65852.92
Iteration:   2700, Loss function: 3.669, Average Loss: 4.316, avg. samples / sec: 65856.71
Iteration:   2700, Loss function: 3.833, Average Loss: 4.272, avg. samples / sec: 65914.86
Iteration:   2700, Loss function: 4.265, Average Loss: 4.279, avg. samples / sec: 65870.78
Iteration:   2700, Loss function: 5.149, Average Loss: 4.283, avg. samples / sec: 65733.93
Iteration:   2700, Loss function: 3.666, Average Loss: 4.289, avg. samples / sec: 65837.94
Iteration:   2720, Loss function: 3.751, Average Loss: 4.276, avg. samples / sec: 65900.28
Iteration:   2720, Loss function: 3.274, Average Loss: 4.267, avg. samples / sec: 65921.40
Iteration:   2720, Loss function: 3.442, Average Loss: 4.265, avg. samples / sec: 65794.69
Iteration:   2720, Loss function: 4.572, Average Loss: 4.264, avg. samples / sec: 65998.39
Iteration:   2720, Loss function: 4.414, Average Loss: 4.256, avg. samples / sec: 65914.52
Iteration:   2720, Loss function: 3.264, Average Loss: 4.279, avg. samples / sec: 65986.81
Iteration:   2720, Loss function: 3.233, Average Loss: 4.277, avg. samples / sec: 66004.82
Iteration:   2720, Loss function: 4.361, Average Loss: 4.284, avg. samples / sec: 65863.76
Iteration:   2720, Loss function: 4.483, Average Loss: 4.289, avg. samples / sec: 65960.24
Iteration:   2720, Loss function: 3.878, Average Loss: 4.263, avg. samples / sec: 65877.73
Iteration:   2720, Loss function: 4.274, Average Loss: 4.281, avg. samples / sec: 65894.65
Iteration:   2720, Loss function: 4.426, Average Loss: 4.275, avg. samples / sec: 65955.80
Iteration:   2720, Loss function: 3.898, Average Loss: 4.309, avg. samples / sec: 65856.80
Iteration:   2720, Loss function: 3.497, Average Loss: 4.273, avg. samples / sec: 65892.46
Iteration:   2720, Loss function: 4.621, Average Loss: 4.283, avg. samples / sec: 65833.79
Iteration:   2720, Loss function: 4.353, Average Loss: 4.263, avg. samples / sec: 65909.90
Iteration:   2720, Loss function: 4.875, Average Loss: 4.267, avg. samples / sec: 65892.61
Iteration:   2720, Loss function: 5.185, Average Loss: 4.314, avg. samples / sec: 65925.75
Iteration:   2720, Loss function: 5.166, Average Loss: 4.285, avg. samples / sec: 65915.91
Iteration:   2720, Loss function: 4.019, Average Loss: 4.259, avg. samples / sec: 65832.96
Iteration:   2720, Loss function: 3.878, Average Loss: 4.267, avg. samples / sec: 65903.30
Iteration:   2720, Loss function: 4.119, Average Loss: 4.300, avg. samples / sec: 65780.35
Iteration:   2720, Loss function: 4.548, Average Loss: 4.281, avg. samples / sec: 65820.29
Iteration:   2720, Loss function: 3.701, Average Loss: 4.285, avg. samples / sec: 65956.85
Iteration:   2720, Loss function: 4.313, Average Loss: 4.269, avg. samples / sec: 65879.40
Iteration:   2720, Loss function: 4.283, Average Loss: 4.275, avg. samples / sec: 65874.90
Iteration:   2720, Loss function: 3.013, Average Loss: 4.290, avg. samples / sec: 65711.22
Iteration:   2720, Loss function: 4.486, Average Loss: 4.281, avg. samples / sec: 65838.22
Iteration:   2720, Loss function: 5.005, Average Loss: 4.270, avg. samples / sec: 65677.59
Iteration:   2720, Loss function: 3.201, Average Loss: 4.284, avg. samples / sec: 65751.99
:::MLL 1558651765.205 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558651765.206 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 3.599, Average Loss: 4.281, avg. samples / sec: 66042.96
Iteration:   2740, Loss function: 3.013, Average Loss: 4.249, avg. samples / sec: 65806.89
Iteration:   2740, Loss function: 2.703, Average Loss: 4.260, avg. samples / sec: 65778.97
Iteration:   2740, Loss function: 5.130, Average Loss: 4.276, avg. samples / sec: 65802.80
Iteration:   2740, Loss function: 3.387, Average Loss: 4.268, avg. samples / sec: 65880.44
Iteration:   2740, Loss function: 3.938, Average Loss: 4.259, avg. samples / sec: 65752.48
Iteration:   2740, Loss function: 3.324, Average Loss: 4.269, avg. samples / sec: 65779.37
Iteration:   2740, Loss function: 3.961, Average Loss: 4.280, avg. samples / sec: 65870.68
Iteration:   2740, Loss function: 4.217, Average Loss: 4.272, avg. samples / sec: 65751.35
Iteration:   2740, Loss function: 4.136, Average Loss: 4.276, avg. samples / sec: 65977.57
Iteration:   2740, Loss function: 3.904, Average Loss: 4.283, avg. samples / sec: 65727.18
Iteration:   2740, Loss function: 4.617, Average Loss: 4.303, avg. samples / sec: 65774.06
Iteration:   2740, Loss function: 3.935, Average Loss: 4.309, avg. samples / sec: 65815.46
Iteration:   2740, Loss function: 3.790, Average Loss: 4.291, avg. samples / sec: 65817.12
Iteration:   2740, Loss function: 3.578, Average Loss: 4.252, avg. samples / sec: 65737.36
Iteration:   2740, Loss function: 4.436, Average Loss: 4.266, avg. samples / sec: 65760.37
Iteration:   2740, Loss function: 3.715, Average Loss: 4.272, avg. samples / sec: 65681.66
Iteration:   2740, Loss function: 4.427, Average Loss: 4.265, avg. samples / sec: 65952.10
Iteration:   2740, Loss function: 3.477, Average Loss: 4.276, avg. samples / sec: 65648.74
Iteration:   2740, Loss function: 5.804, Average Loss: 4.274, avg. samples / sec: 65765.80
Iteration:   2740, Loss function: 3.152, Average Loss: 4.256, avg. samples / sec: 65663.91
Iteration:   2740, Loss function: 3.687, Average Loss: 4.253, avg. samples / sec: 65773.29
Iteration:   2740, Loss function: 5.618, Average Loss: 4.285, avg. samples / sec: 65856.46
Iteration:   2740, Loss function: 3.798, Average Loss: 4.268, avg. samples / sec: 65838.31
Iteration:   2740, Loss function: 3.133, Average Loss: 4.276, avg. samples / sec: 65763.53
Iteration:   2740, Loss function: 2.284, Average Loss: 4.271, avg. samples / sec: 65677.75
Iteration:   2740, Loss function: 3.902, Average Loss: 4.282, avg. samples / sec: 65698.17
Iteration:   2740, Loss function: 3.892, Average Loss: 4.266, avg. samples / sec: 65698.54
Iteration:   2740, Loss function: 4.454, Average Loss: 4.260, avg. samples / sec: 65760.83
Iteration:   2740, Loss function: 3.505, Average Loss: 4.256, avg. samples / sec: 65651.80
Iteration:   2760, Loss function: 3.230, Average Loss: 4.243, avg. samples / sec: 66102.35
Iteration:   2760, Loss function: 3.081, Average Loss: 4.254, avg. samples / sec: 66129.42
Iteration:   2760, Loss function: 3.851, Average Loss: 4.269, avg. samples / sec: 66084.34
Iteration:   2760, Loss function: 3.717, Average Loss: 4.257, avg. samples / sec: 66089.54
Iteration:   2760, Loss function: 4.588, Average Loss: 4.265, avg. samples / sec: 66128.65
Iteration:   2760, Loss function: 5.739, Average Loss: 4.298, avg. samples / sec: 66079.22
Iteration:   2760, Loss function: 3.551, Average Loss: 4.296, avg. samples / sec: 66062.59
Iteration:   2760, Loss function: 3.077, Average Loss: 4.274, avg. samples / sec: 66089.05
Iteration:   2760, Loss function: 4.399, Average Loss: 4.272, avg. samples / sec: 66147.58
Iteration:   2760, Loss function: 3.315, Average Loss: 4.261, avg. samples / sec: 66085.02
Iteration:   2760, Loss function: 4.590, Average Loss: 4.263, avg. samples / sec: 66002.16
Iteration:   2760, Loss function: 4.527, Average Loss: 4.263, avg. samples / sec: 66127.28
Iteration:   2760, Loss function: 3.616, Average Loss: 4.255, avg. samples / sec: 66168.92
Iteration:   2760, Loss function: 3.556, Average Loss: 4.260, avg. samples / sec: 66070.43
Iteration:   2760, Loss function: 5.092, Average Loss: 4.253, avg. samples / sec: 66093.01
Iteration:   2760, Loss function: 4.907, Average Loss: 4.264, avg. samples / sec: 66136.59
Iteration:   2760, Loss function: 4.017, Average Loss: 4.262, avg. samples / sec: 65953.02
Iteration:   2760, Loss function: 4.587, Average Loss: 4.274, avg. samples / sec: 66058.19
Iteration:   2760, Loss function: 3.138, Average Loss: 4.255, avg. samples / sec: 66126.20
Iteration:   2760, Loss function: 3.378, Average Loss: 4.261, avg. samples / sec: 66080.84
Iteration:   2760, Loss function: 3.870, Average Loss: 4.251, avg. samples / sec: 66048.84
Iteration:   2760, Loss function: 3.857, Average Loss: 4.247, avg. samples / sec: 66011.69
Iteration:   2760, Loss function: 3.000, Average Loss: 4.269, avg. samples / sec: 66020.19
Iteration:   2760, Loss function: 3.343, Average Loss: 4.277, avg. samples / sec: 66041.57
Iteration:   2760, Loss function: 3.821, Average Loss: 4.280, avg. samples / sec: 65936.08
Iteration:   2760, Loss function: 3.757, Average Loss: 4.269, avg. samples / sec: 65980.44
Iteration:   2760, Loss function: 4.529, Average Loss: 4.271, avg. samples / sec: 65928.46
Iteration:   2760, Loss function: 3.804, Average Loss: 4.282, avg. samples / sec: 65879.83
Iteration:   2760, Loss function: 3.085, Average Loss: 4.274, avg. samples / sec: 65869.11
Iteration:   2760, Loss function: 4.569, Average Loss: 4.288, avg. samples / sec: 65747.91
Iteration:   2780, Loss function: 3.990, Average Loss: 4.262, avg. samples / sec: 66049.90
Iteration:   2780, Loss function: 3.968, Average Loss: 4.273, avg. samples / sec: 66089.60
Iteration:   2780, Loss function: 4.431, Average Loss: 4.249, avg. samples / sec: 65960.12
Iteration:   2780, Loss function: 5.255, Average Loss: 4.245, avg. samples / sec: 65954.26
Iteration:   2780, Loss function: 4.851, Average Loss: 4.251, avg. samples / sec: 66152.64
Iteration:   2780, Loss function: 5.690, Average Loss: 4.261, avg. samples / sec: 66077.24
Iteration:   2780, Loss function: 5.202, Average Loss: 4.276, avg. samples / sec: 66279.67
Iteration:   2780, Loss function: 6.100, Average Loss: 4.265, avg. samples / sec: 66233.01
Iteration:   2780, Loss function: 4.300, Average Loss: 4.259, avg. samples / sec: 65932.66
Iteration:   2780, Loss function: 4.467, Average Loss: 4.263, avg. samples / sec: 66193.88
Iteration:   2780, Loss function: 4.012, Average Loss: 4.257, avg. samples / sec: 66037.64
Iteration:   2780, Loss function: 3.487, Average Loss: 4.293, avg. samples / sec: 65993.23
Iteration:   2780, Loss function: 4.211, Average Loss: 4.266, avg. samples / sec: 66071.17
Iteration:   2780, Loss function: 3.991, Average Loss: 4.266, avg. samples / sec: 65994.53
Iteration:   2780, Loss function: 4.149, Average Loss: 4.275, avg. samples / sec: 66096.95
Iteration:   2780, Loss function: 3.642, Average Loss: 4.264, avg. samples / sec: 65945.34
Iteration:   2780, Loss function: 4.893, Average Loss: 4.256, avg. samples / sec: 66054.38
Iteration:   2780, Loss function: 5.223, Average Loss: 4.261, avg. samples / sec: 65990.36
Iteration:   2780, Loss function: 3.537, Average Loss: 4.251, avg. samples / sec: 66005.91
Iteration:   2780, Loss function: 3.398, Average Loss: 4.246, avg. samples / sec: 66001.14
Iteration:   2780, Loss function: 4.107, Average Loss: 4.260, avg. samples / sec: 66011.22
Iteration:   2780, Loss function: 3.539, Average Loss: 4.260, avg. samples / sec: 66033.90
Iteration:   2780, Loss function: 4.043, Average Loss: 4.277, avg. samples / sec: 66068.16
Iteration:   2780, Loss function: 4.243, Average Loss: 4.273, avg. samples / sec: 66139.05
Iteration:   2780, Loss function: 5.198, Average Loss: 4.270, avg. samples / sec: 65997.78
Iteration:   2780, Loss function: 3.945, Average Loss: 4.246, avg. samples / sec: 66001.18
Iteration:   2780, Loss function: 4.360, Average Loss: 4.287, avg. samples / sec: 66154.66
Iteration:   2780, Loss function: 3.789, Average Loss: 4.294, avg. samples / sec: 65912.24
Iteration:   2780, Loss function: 5.030, Average Loss: 4.250, avg. samples / sec: 65892.98
Iteration:   2780, Loss function: 3.443, Average Loss: 4.239, avg. samples / sec: 65902.60
:::MLL 1558651766.989 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558651766.990 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 3.000, Average Loss: 4.252, avg. samples / sec: 65841.60
Iteration:   2800, Loss function: 4.566, Average Loss: 4.256, avg. samples / sec: 65646.17
Iteration:   2800, Loss function: 4.097, Average Loss: 4.258, avg. samples / sec: 65697.25
Iteration:   2800, Loss function: 4.365, Average Loss: 4.259, avg. samples / sec: 65718.51
Iteration:   2800, Loss function: 4.284, Average Loss: 4.268, avg. samples / sec: 65666.12
Iteration:   2800, Loss function: 5.230, Average Loss: 4.256, avg. samples / sec: 65717.84
Iteration:   2800, Loss function: 3.673, Average Loss: 4.266, avg. samples / sec: 65684.36
Iteration:   2800, Loss function: 4.886, Average Loss: 4.286, avg. samples / sec: 65687.97
Iteration:   2800, Loss function: 5.098, Average Loss: 4.267, avg. samples / sec: 65721.48
Iteration:   2800, Loss function: 3.194, Average Loss: 4.242, avg. samples / sec: 65732.79
Iteration:   2800, Loss function: 3.819, Average Loss: 4.240, avg. samples / sec: 65570.73
Iteration:   2800, Loss function: 3.251, Average Loss: 4.271, avg. samples / sec: 65686.99
Iteration:   2800, Loss function: 3.027, Average Loss: 4.248, avg. samples / sec: 65666.61
Iteration:   2800, Loss function: 3.713, Average Loss: 4.258, avg. samples / sec: 65650.67
Iteration:   2800, Loss function: 5.684, Average Loss: 4.291, avg. samples / sec: 65714.25
Iteration:   2800, Loss function: 4.108, Average Loss: 4.261, avg. samples / sec: 65579.24
Iteration:   2800, Loss function: 3.452, Average Loss: 4.244, avg. samples / sec: 65642.47
Iteration:   2800, Loss function: 3.504, Average Loss: 4.249, avg. samples / sec: 65613.47
Iteration:   2800, Loss function: 4.903, Average Loss: 4.243, avg. samples / sec: 65521.28
Iteration:   2800, Loss function: 3.270, Average Loss: 4.247, avg. samples / sec: 65623.40
Iteration:   2800, Loss function: 3.796, Average Loss: 4.248, avg. samples / sec: 65515.10
Iteration:   2800, Loss function: 2.296, Average Loss: 4.267, avg. samples / sec: 65472.91
Iteration:   2800, Loss function: 5.277, Average Loss: 4.259, avg. samples / sec: 65603.21
Iteration:   2800, Loss function: 4.999, Average Loss: 4.239, avg. samples / sec: 65694.86
Iteration:   2800, Loss function: 3.376, Average Loss: 4.233, avg. samples / sec: 65723.05
Iteration:   2800, Loss function: 3.688, Average Loss: 4.248, avg. samples / sec: 65503.35
Iteration:   2800, Loss function: 4.843, Average Loss: 4.269, avg. samples / sec: 65538.35
Iteration:   2800, Loss function: 4.087, Average Loss: 4.268, avg. samples / sec: 65579.92
Iteration:   2800, Loss function: 4.801, Average Loss: 4.259, avg. samples / sec: 65490.38
Iteration:   2800, Loss function: 4.659, Average Loss: 4.280, avg. samples / sec: 65505.23
Iteration:   2820, Loss function: 4.945, Average Loss: 4.255, avg. samples / sec: 65977.20
Iteration:   2820, Loss function: 5.000, Average Loss: 4.263, avg. samples / sec: 66036.80
Iteration:   2820, Loss function: 3.581, Average Loss: 4.246, avg. samples / sec: 65644.00
Iteration:   2820, Loss function: 3.752, Average Loss: 4.250, avg. samples / sec: 65811.84
Iteration:   2820, Loss function: 5.251, Average Loss: 4.271, avg. samples / sec: 65782.56
Iteration:   2820, Loss function: 4.807, Average Loss: 4.274, avg. samples / sec: 66074.86
Iteration:   2820, Loss function: 3.286, Average Loss: 4.239, avg. samples / sec: 65835.17
Iteration:   2820, Loss function: 2.538, Average Loss: 4.245, avg. samples / sec: 65676.52
Iteration:   2820, Loss function: 4.011, Average Loss: 4.244, avg. samples / sec: 65878.60
Iteration:   2820, Loss function: 3.957, Average Loss: 4.250, avg. samples / sec: 65828.44
Iteration:   2820, Loss function: 3.603, Average Loss: 4.285, avg. samples / sec: 65842.99
Iteration:   2820, Loss function: 4.804, Average Loss: 4.248, avg. samples / sec: 65874.99
Iteration:   2820, Loss function: 4.522, Average Loss: 4.238, avg. samples / sec: 65786.37
Iteration:   2820, Loss function: 3.477, Average Loss: 4.280, avg. samples / sec: 65746.90
Iteration:   2820, Loss function: 4.388, Average Loss: 4.237, avg. samples / sec: 65821.34
Iteration:   2820, Loss function: 3.112, Average Loss: 4.241, avg. samples / sec: 65785.17
Iteration:   2820, Loss function: 4.437, Average Loss: 4.255, avg. samples / sec: 65670.13
Iteration:   2820, Loss function: 3.877, Average Loss: 4.255, avg. samples / sec: 65786.25
Iteration:   2820, Loss function: 4.376, Average Loss: 4.248, avg. samples / sec: 65797.86
Iteration:   2820, Loss function: 4.552, Average Loss: 4.238, avg. samples / sec: 65839.08
Iteration:   2820, Loss function: 3.616, Average Loss: 4.249, avg. samples / sec: 65628.29
Iteration:   2820, Loss function: 4.794, Average Loss: 4.261, avg. samples / sec: 65711.59
Iteration:   2820, Loss function: 3.384, Average Loss: 4.262, avg. samples / sec: 65821.43
Iteration:   2820, Loss function: 3.311, Average Loss: 4.232, avg. samples / sec: 65795.49
Iteration:   2820, Loss function: 4.089, Average Loss: 4.266, avg. samples / sec: 65700.01
Iteration:   2820, Loss function: 3.877, Average Loss: 4.267, avg. samples / sec: 65671.29
Iteration:   2820, Loss function: 5.276, Average Loss: 4.262, avg. samples / sec: 65815.96
Iteration:   2820, Loss function: 4.781, Average Loss: 4.240, avg. samples / sec: 65724.58
Iteration:   2820, Loss function: 4.006, Average Loss: 4.254, avg. samples / sec: 65828.41
Iteration:   2820, Loss function: 3.645, Average Loss: 4.238, avg. samples / sec: 65747.82
Iteration:   2840, Loss function: 5.276, Average Loss: 4.232, avg. samples / sec: 65937.04
Iteration:   2840, Loss function: 3.765, Average Loss: 4.237, avg. samples / sec: 65900.53
Iteration:   2840, Loss function: 4.980, Average Loss: 4.240, avg. samples / sec: 65928.00
Iteration:   2840, Loss function: 3.641, Average Loss: 4.256, avg. samples / sec: 65831.05
Iteration:   2840, Loss function: 3.553, Average Loss: 4.250, avg. samples / sec: 65969.85
Iteration:   2840, Loss function: 5.004, Average Loss: 4.266, avg. samples / sec: 65868.74
Iteration:   2840, Loss function: 2.914, Average Loss: 4.240, avg. samples / sec: 65856.25
Iteration:   2840, Loss function: 4.757, Average Loss: 4.277, avg. samples / sec: 65882.51
Iteration:   2840, Loss function: 3.390, Average Loss: 4.256, avg. samples / sec: 65968.74
Iteration:   2840, Loss function: 3.984, Average Loss: 4.223, avg. samples / sec: 65995.21
Iteration:   2840, Loss function: 4.785, Average Loss: 4.250, avg. samples / sec: 65953.76
Iteration:   2840, Loss function: 4.887, Average Loss: 4.240, avg. samples / sec: 65918.96
Iteration:   2840, Loss function: 4.839, Average Loss: 4.229, avg. samples / sec: 65900.22
Iteration:   2840, Loss function: 3.802, Average Loss: 4.234, avg. samples / sec: 65880.51
Iteration:   2840, Loss function: 4.401, Average Loss: 4.262, avg. samples / sec: 65922.69
Iteration:   2840, Loss function: 4.134, Average Loss: 4.251, avg. samples / sec: 65767.09
Iteration:   2840, Loss function: 3.681, Average Loss: 4.230, avg. samples / sec: 65892.89
Iteration:   2840, Loss function: 5.617, Average Loss: 4.246, avg. samples / sec: 65816.33
Iteration:   2840, Loss function: 3.129, Average Loss: 4.263, avg. samples / sec: 65952.03
Iteration:   2840, Loss function: 4.204, Average Loss: 4.255, avg. samples / sec: 65872.84
Iteration:   2840, Loss function: 4.192, Average Loss: 4.233, avg. samples / sec: 66014.72
Iteration:   2840, Loss function: 4.562, Average Loss: 4.243, avg. samples / sec: 65853.72
Iteration:   2840, Loss function: 3.618, Average Loss: 4.259, avg. samples / sec: 65945.37
Iteration:   2840, Loss function: 3.698, Average Loss: 4.244, avg. samples / sec: 65794.82
Iteration:   2840, Loss function: 4.087, Average Loss: 4.259, avg. samples / sec: 65889.10
Iteration:   2840, Loss function: 3.458, Average Loss: 4.248, avg. samples / sec: 65909.50
Iteration:   2840, Loss function: 2.876, Average Loss: 4.267, avg. samples / sec: 65703.77
Iteration:   2840, Loss function: 4.152, Average Loss: 4.244, avg. samples / sec: 65734.42
Iteration:   2840, Loss function: 3.945, Average Loss: 4.274, avg. samples / sec: 65749.32
Iteration:   2840, Loss function: 3.406, Average Loss: 4.235, avg. samples / sec: 65799.73
Iteration:   2860, Loss function: 4.018, Average Loss: 4.246, avg. samples / sec: 66301.28
Iteration:   2860, Loss function: 2.728, Average Loss: 4.234, avg. samples / sec: 66151.43
Iteration:   2860, Loss function: 4.486, Average Loss: 4.231, avg. samples / sec: 66109.79
Iteration:   2860, Loss function: 3.742, Average Loss: 4.244, avg. samples / sec: 66271.60
Iteration:   2860, Loss function: 3.901, Average Loss: 4.255, avg. samples / sec: 66228.53
Iteration:   2860, Loss function: 4.739, Average Loss: 4.223, avg. samples / sec: 66161.25
Iteration:   2860, Loss function: 2.545, Average Loss: 4.230, avg. samples / sec: 66059.06
Iteration:   2860, Loss function: 3.001, Average Loss: 4.256, avg. samples / sec: 66091.50
Iteration:   2860, Loss function: 4.408, Average Loss: 4.215, avg. samples / sec: 66125.27
Iteration:   2860, Loss function: 3.755, Average Loss: 4.239, avg. samples / sec: 66207.81
Iteration:   2860, Loss function: 4.713, Average Loss: 4.246, avg. samples / sec: 66095.40
Iteration:   2860, Loss function: 4.430, Average Loss: 4.247, avg. samples / sec: 66154.57
Iteration:   2860, Loss function: 4.910, Average Loss: 4.255, avg. samples / sec: 66224.95
Iteration:   2860, Loss function: 3.531, Average Loss: 4.230, avg. samples / sec: 66137.28
Iteration:   2860, Loss function: 3.790, Average Loss: 4.242, avg. samples / sec: 66083.16
Iteration:   2860, Loss function: 3.854, Average Loss: 4.269, avg. samples / sec: 66240.36
Iteration:   2860, Loss function: 4.137, Average Loss: 4.236, avg. samples / sec: 66032.35
Iteration:   2860, Loss function: 3.671, Average Loss: 4.237, avg. samples / sec: 66039.93
Iteration:   2860, Loss function: 4.057, Average Loss: 4.263, avg. samples / sec: 66164.32
Iteration:   2860, Loss function: 4.344, Average Loss: 4.242, avg. samples / sec: 66141.68
Iteration:   2860, Loss function: 4.414, Average Loss: 4.259, avg. samples / sec: 66037.82
Iteration:   2860, Loss function: 2.523, Average Loss: 4.258, avg. samples / sec: 66071.70
Iteration:   2860, Loss function: 3.918, Average Loss: 4.235, avg. samples / sec: 66131.19
Iteration:   2860, Loss function: 5.910, Average Loss: 4.227, avg. samples / sec: 66038.91
Iteration:   2860, Loss function: 3.653, Average Loss: 4.269, avg. samples / sec: 65977.20
Iteration:   2860, Loss function: 4.392, Average Loss: 4.232, avg. samples / sec: 66237.46
Iteration:   2860, Loss function: 3.426, Average Loss: 4.230, avg. samples / sec: 65988.16
Iteration:   2860, Loss function: 3.374, Average Loss: 4.255, avg. samples / sec: 66037.79
Iteration:   2860, Loss function: 2.864, Average Loss: 4.254, avg. samples / sec: 65920.72
Iteration:   2860, Loss function: 4.186, Average Loss: 4.249, avg. samples / sec: 65865.30
:::MLL 1558651768.779 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558651768.779 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 3.539, Average Loss: 4.242, avg. samples / sec: 65290.19
Iteration:   2880, Loss function: 4.210, Average Loss: 4.221, avg. samples / sec: 65286.23
Iteration:   2880, Loss function: 2.955, Average Loss: 4.228, avg. samples / sec: 65212.58
Iteration:   2880, Loss function: 4.269, Average Loss: 4.249, avg. samples / sec: 65229.72
Iteration:   2880, Loss function: 2.879, Average Loss: 4.232, avg. samples / sec: 65311.28
Iteration:   2880, Loss function: 3.757, Average Loss: 4.262, avg. samples / sec: 65365.90
Iteration:   2880, Loss function: 4.386, Average Loss: 4.234, avg. samples / sec: 65130.36
Iteration:   2880, Loss function: 4.144, Average Loss: 4.235, avg. samples / sec: 65335.56
Iteration:   2880, Loss function: 4.346, Average Loss: 4.234, avg. samples / sec: 65206.99
Iteration:   2880, Loss function: 2.883, Average Loss: 4.248, avg. samples / sec: 65376.66
Iteration:   2880, Loss function: 4.742, Average Loss: 4.222, avg. samples / sec: 65219.12
Iteration:   2880, Loss function: 4.175, Average Loss: 4.235, avg. samples / sec: 65303.02
Iteration:   2880, Loss function: 4.354, Average Loss: 4.244, avg. samples / sec: 65379.21
Iteration:   2880, Loss function: 3.605, Average Loss: 4.266, avg. samples / sec: 65227.24
Iteration:   2880, Loss function: 4.766, Average Loss: 4.243, avg. samples / sec: 65203.95
Iteration:   2880, Loss function: 4.491, Average Loss: 4.242, avg. samples / sec: 65164.36
Iteration:   2880, Loss function: 4.236, Average Loss: 4.248, avg. samples / sec: 65273.44
Iteration:   2880, Loss function: 3.940, Average Loss: 4.242, avg. samples / sec: 65096.66
Iteration:   2880, Loss function: 3.928, Average Loss: 4.218, avg. samples / sec: 65271.02
Iteration:   2880, Loss function: 3.713, Average Loss: 4.239, avg. samples / sec: 65110.05
Iteration:   2880, Loss function: 3.459, Average Loss: 4.234, avg. samples / sec: 65242.37
Iteration:   2880, Loss function: 4.088, Average Loss: 4.232, avg. samples / sec: 65209.77
Iteration:   2880, Loss function: 3.881, Average Loss: 4.247, avg. samples / sec: 65283.54
Iteration:   2880, Loss function: 4.142, Average Loss: 4.226, avg. samples / sec: 65280.51
Iteration:   2880, Loss function: 3.008, Average Loss: 4.254, avg. samples / sec: 65202.92
Iteration:   2880, Loss function: 4.648, Average Loss: 4.219, avg. samples / sec: 65076.19
Iteration:   2880, Loss function: 3.927, Average Loss: 4.253, avg. samples / sec: 65221.81
Iteration:   2880, Loss function: 3.158, Average Loss: 4.249, avg. samples / sec: 65107.88
Iteration:   2880, Loss function: 4.864, Average Loss: 4.251, avg. samples / sec: 65053.12
Iteration:   2880, Loss function: 3.194, Average Loss: 4.214, avg. samples / sec: 65040.60
Iteration:   2900, Loss function: 2.027, Average Loss: 4.219, avg. samples / sec: 66178.89
Iteration:   2900, Loss function: 4.241, Average Loss: 4.239, avg. samples / sec: 65999.20
Iteration:   2900, Loss function: 4.192, Average Loss: 4.233, avg. samples / sec: 66260.29
Iteration:   2900, Loss function: 5.721, Average Loss: 4.233, avg. samples / sec: 66175.54
Iteration:   2900, Loss function: 4.454, Average Loss: 4.241, avg. samples / sec: 66212.97
Iteration:   2900, Loss function: 4.213, Average Loss: 4.234, avg. samples / sec: 66267.80
Iteration:   2900, Loss function: 2.419, Average Loss: 4.234, avg. samples / sec: 66213.66
Iteration:   2900, Loss function: 3.873, Average Loss: 4.230, avg. samples / sec: 66162.89
Iteration:   2900, Loss function: 3.917, Average Loss: 4.246, avg. samples / sec: 66086.20
Iteration:   2900, Loss function: 5.180, Average Loss: 4.240, avg. samples / sec: 66153.76
Iteration:   2900, Loss function: 3.398, Average Loss: 4.260, avg. samples / sec: 66142.34
Iteration:   2900, Loss function: 4.703, Average Loss: 4.216, avg. samples / sec: 66159.07
Iteration:   2900, Loss function: 4.434, Average Loss: 4.247, avg. samples / sec: 66216.74
Iteration:   2900, Loss function: 5.316, Average Loss: 4.246, avg. samples / sec: 66210.54
Iteration:   2900, Loss function: 4.194, Average Loss: 4.225, avg. samples / sec: 66022.73
Iteration:   2900, Loss function: 4.681, Average Loss: 4.234, avg. samples / sec: 66127.56
Iteration:   2900, Loss function: 5.306, Average Loss: 4.247, avg. samples / sec: 66167.65
Iteration:   2900, Loss function: 3.896, Average Loss: 4.222, avg. samples / sec: 66112.21
Iteration:   2900, Loss function: 4.493, Average Loss: 4.225, avg. samples / sec: 66015.58
Iteration:   2900, Loss function: 4.244, Average Loss: 4.249, avg. samples / sec: 66077.02
Iteration:   2900, Loss function: 5.348, Average Loss: 4.232, avg. samples / sec: 66060.86
Iteration:   2900, Loss function: 4.964, Average Loss: 4.247, avg. samples / sec: 66109.48
Iteration:   2900, Loss function: 4.593, Average Loss: 4.251, avg. samples / sec: 66161.49
Iteration:   2900, Loss function: 4.735, Average Loss: 4.229, avg. samples / sec: 66080.15
Iteration:   2900, Loss function: 4.403, Average Loss: 4.219, avg. samples / sec: 66098.84
Iteration:   2900, Loss function: 4.457, Average Loss: 4.215, avg. samples / sec: 66172.96
Iteration:   2900, Loss function: 4.514, Average Loss: 4.236, avg. samples / sec: 66052.16
Iteration:   2900, Loss function: 4.023, Average Loss: 4.257, avg. samples / sec: 65910.09
Iteration:   2900, Loss function: 3.676, Average Loss: 4.227, avg. samples / sec: 65990.20
Iteration:   2900, Loss function: 4.128, Average Loss: 4.248, avg. samples / sec: 65970.71
Iteration:   2920, Loss function: 5.140, Average Loss: 4.233, avg. samples / sec: 66045.87
Iteration:   2920, Loss function: 4.929, Average Loss: 4.242, avg. samples / sec: 65936.27
Iteration:   2920, Loss function: 4.265, Average Loss: 4.228, avg. samples / sec: 65965.62
Iteration:   2920, Loss function: 4.236, Average Loss: 4.228, avg. samples / sec: 65918.29
Iteration:   2920, Loss function: 2.501, Average Loss: 4.227, avg. samples / sec: 65928.00
Iteration:   2920, Loss function: 3.849, Average Loss: 4.221, avg. samples / sec: 66007.33
Iteration:   2920, Loss function: 4.384, Average Loss: 4.214, avg. samples / sec: 66075.51
Iteration:   2920, Loss function: 3.406, Average Loss: 4.227, avg. samples / sec: 65904.94
Iteration:   2920, Loss function: 4.054, Average Loss: 4.218, avg. samples / sec: 66081.86
Iteration:   2920, Loss function: 3.076, Average Loss: 4.245, avg. samples / sec: 66079.16
Iteration:   2920, Loss function: 3.413, Average Loss: 4.236, avg. samples / sec: 65942.68
Iteration:   2920, Loss function: 3.614, Average Loss: 4.217, avg. samples / sec: 65945.15
Iteration:   2920, Loss function: 4.192, Average Loss: 4.242, avg. samples / sec: 66141.62
Iteration:   2920, Loss function: 3.073, Average Loss: 4.246, avg. samples / sec: 65867.24
Iteration:   2920, Loss function: 4.473, Average Loss: 4.242, avg. samples / sec: 65901.30
Iteration:   2920, Loss function: 3.980, Average Loss: 4.241, avg. samples / sec: 65966.91
Iteration:   2920, Loss function: 3.043, Average Loss: 4.239, avg. samples / sec: 65824.13
Iteration:   2920, Loss function: 4.053, Average Loss: 4.226, avg. samples / sec: 66002.01
Iteration:   2920, Loss function: 4.397, Average Loss: 4.226, avg. samples / sec: 65936.27
Iteration:   2920, Loss function: 3.718, Average Loss: 4.231, avg. samples / sec: 66022.79
Iteration:   2920, Loss function: 3.436, Average Loss: 4.246, avg. samples / sec: 65919.09
Iteration:   2920, Loss function: 4.309, Average Loss: 4.215, avg. samples / sec: 65707.11
Iteration:   2920, Loss function: 3.836, Average Loss: 4.255, avg. samples / sec: 66038.66
Iteration:   2920, Loss function: 4.351, Average Loss: 4.246, avg. samples / sec: 65870.07
Iteration:   2920, Loss function: 4.331, Average Loss: 4.241, avg. samples / sec: 65915.79
Iteration:   2920, Loss function: 4.093, Average Loss: 4.222, avg. samples / sec: 65886.42
Iteration:   2920, Loss function: 3.688, Average Loss: 4.258, avg. samples / sec: 65823.00
Iteration:   2920, Loss function: 2.977, Average Loss: 4.234, avg. samples / sec: 65848.77
Iteration:   2920, Loss function: 3.835, Average Loss: 4.220, avg. samples / sec: 66019.54
Iteration:   2920, Loss function: 5.379, Average Loss: 4.215, avg. samples / sec: 65797.34
:::MLL 1558651770.563 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558651770.564 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.570, Average Loss: 4.232, avg. samples / sec: 65871.39
Iteration:   2940, Loss function: 3.224, Average Loss: 4.214, avg. samples / sec: 65802.34
Iteration:   2940, Loss function: 4.529, Average Loss: 4.223, avg. samples / sec: 65769.30
Iteration:   2940, Loss function: 4.438, Average Loss: 4.223, avg. samples / sec: 65842.80
Iteration:   2940, Loss function: 4.225, Average Loss: 4.246, avg. samples / sec: 65805.32
Iteration:   2940, Loss function: 3.979, Average Loss: 4.212, avg. samples / sec: 65837.66
Iteration:   2940, Loss function: 4.269, Average Loss: 4.230, avg. samples / sec: 65593.35
Iteration:   2940, Loss function: 4.280, Average Loss: 4.221, avg. samples / sec: 65638.16
Iteration:   2940, Loss function: 3.832, Average Loss: 4.240, avg. samples / sec: 65833.42
Iteration:   2940, Loss function: 4.387, Average Loss: 4.246, avg. samples / sec: 65865.70
Iteration:   2940, Loss function: 3.921, Average Loss: 4.228, avg. samples / sec: 65737.18
Iteration:   2940, Loss function: 3.993, Average Loss: 4.214, avg. samples / sec: 65826.32
Iteration:   2940, Loss function: 3.012, Average Loss: 4.237, avg. samples / sec: 65670.65
Iteration:   2940, Loss function: 4.411, Average Loss: 4.213, avg. samples / sec: 65665.63
Iteration:   2940, Loss function: 3.524, Average Loss: 4.231, avg. samples / sec: 65706.35
Iteration:   2940, Loss function: 4.477, Average Loss: 4.208, avg. samples / sec: 65651.19
Iteration:   2940, Loss function: 3.038, Average Loss: 4.236, avg. samples / sec: 65714.19
Iteration:   2940, Loss function: 4.735, Average Loss: 4.232, avg. samples / sec: 65723.66
Iteration:   2940, Loss function: 3.075, Average Loss: 4.224, avg. samples / sec: 65703.50
Iteration:   2940, Loss function: 4.626, Average Loss: 4.250, avg. samples / sec: 65725.84
Iteration:   2940, Loss function: 4.009, Average Loss: 4.222, avg. samples / sec: 65559.72
Iteration:   2940, Loss function: 3.113, Average Loss: 4.227, avg. samples / sec: 65672.73
Iteration:   2940, Loss function: 4.022, Average Loss: 4.233, avg. samples / sec: 65740.03
Iteration:   2940, Loss function: 3.605, Average Loss: 4.232, avg. samples / sec: 65681.14
Iteration:   2940, Loss function: 3.656, Average Loss: 4.209, avg. samples / sec: 65625.78
Iteration:   2940, Loss function: 5.008, Average Loss: 4.244, avg. samples / sec: 65649.14
Iteration:   2940, Loss function: 4.284, Average Loss: 4.208, avg. samples / sec: 65750.92
Iteration:   2940, Loss function: 3.686, Average Loss: 4.234, avg. samples / sec: 65610.87
Iteration:   2940, Loss function: 4.143, Average Loss: 4.221, avg. samples / sec: 65527.83
Iteration:   2940, Loss function: 3.808, Average Loss: 4.209, avg. samples / sec: 65570.94
Iteration:   2960, Loss function: 4.031, Average Loss: 4.227, avg. samples / sec: 65834.25
Iteration:   2960, Loss function: 3.657, Average Loss: 4.206, avg. samples / sec: 65936.98
Iteration:   2960, Loss function: 3.697, Average Loss: 4.210, avg. samples / sec: 65843.66
Iteration:   2960, Loss function: 2.777, Average Loss: 4.215, avg. samples / sec: 65843.72
Iteration:   2960, Loss function: 3.145, Average Loss: 4.228, avg. samples / sec: 66002.07
Iteration:   2960, Loss function: 3.794, Average Loss: 4.230, avg. samples / sec: 66067.73
Iteration:   2960, Loss function: 3.454, Average Loss: 4.225, avg. samples / sec: 65884.76
Iteration:   2960, Loss function: 4.043, Average Loss: 4.207, avg. samples / sec: 66146.81
Iteration:   2960, Loss function: 3.194, Average Loss: 4.217, avg. samples / sec: 66072.35
Iteration:   2960, Loss function: 4.481, Average Loss: 4.222, avg. samples / sec: 65998.18
Iteration:   2960, Loss function: 3.797, Average Loss: 4.242, avg. samples / sec: 65824.35
Iteration:   2960, Loss function: 4.980, Average Loss: 4.210, avg. samples / sec: 65908.82
Iteration:   2960, Loss function: 3.647, Average Loss: 4.235, avg. samples / sec: 65841.36
Iteration:   2960, Loss function: 3.691, Average Loss: 4.216, avg. samples / sec: 65946.76
Iteration:   2960, Loss function: 2.912, Average Loss: 4.210, avg. samples / sec: 65854.89
Iteration:   2960, Loss function: 3.525, Average Loss: 4.218, avg. samples / sec: 65755.21
Iteration:   2960, Loss function: 2.552, Average Loss: 4.216, avg. samples / sec: 65810.95
Iteration:   2960, Loss function: 4.317, Average Loss: 4.222, avg. samples / sec: 65849.91
Iteration:   2960, Loss function: 4.294, Average Loss: 4.225, avg. samples / sec: 65797.98
Iteration:   2960, Loss function: 4.119, Average Loss: 4.238, avg. samples / sec: 65786.95
Iteration:   2960, Loss function: 3.296, Average Loss: 4.231, avg. samples / sec: 65818.48
Iteration:   2960, Loss function: 4.136, Average Loss: 4.205, avg. samples / sec: 65839.91
Iteration:   2960, Loss function: 3.886, Average Loss: 4.231, avg. samples / sec: 65836.25
Iteration:   2960, Loss function: 4.359, Average Loss: 4.238, avg. samples / sec: 65917.45
Iteration:   2960, Loss function: 3.439, Average Loss: 4.214, avg. samples / sec: 65844.06
Iteration:   2960, Loss function: 3.997, Average Loss: 4.223, avg. samples / sec: 65906.85
Iteration:   2960, Loss function: 3.680, Average Loss: 4.244, avg. samples / sec: 65836.80
Iteration:   2960, Loss function: 4.250, Average Loss: 4.233, avg. samples / sec: 65862.09
Iteration:   2960, Loss function: 4.201, Average Loss: 4.204, avg. samples / sec: 65889.38
Iteration:   2960, Loss function: 4.632, Average Loss: 4.201, avg. samples / sec: 65854.65
Iteration:   2980, Loss function: 3.190, Average Loss: 4.220, avg. samples / sec: 65954.23
Iteration:   2980, Loss function: 4.046, Average Loss: 4.205, avg. samples / sec: 65976.43
Iteration:   2980, Loss function: 3.515, Average Loss: 4.213, avg. samples / sec: 65950.80
Iteration:   2980, Loss function: 3.534, Average Loss: 4.199, avg. samples / sec: 65814.85
Iteration:   2980, Loss function: 5.008, Average Loss: 4.213, avg. samples / sec: 65963.86
Iteration:   2980, Loss function: 4.214, Average Loss: 4.236, avg. samples / sec: 65889.38
Iteration:   2980, Loss function: 4.385, Average Loss: 4.204, avg. samples / sec: 65887.47
Iteration:   2980, Loss function: 3.992, Average Loss: 4.222, avg. samples / sec: 65699.24
Iteration:   2980, Loss function: 3.739, Average Loss: 4.208, avg. samples / sec: 65813.10
Iteration:   2980, Loss function: 3.632, Average Loss: 4.203, avg. samples / sec: 65960.92
Iteration:   2980, Loss function: 3.427, Average Loss: 4.205, avg. samples / sec: 65774.21
Iteration:   2980, Loss function: 5.188, Average Loss: 4.210, avg. samples / sec: 65812.64
Iteration:   2980, Loss function: 3.930, Average Loss: 4.225, avg. samples / sec: 65768.50
Iteration:   2980, Loss function: 4.288, Average Loss: 4.218, avg. samples / sec: 65804.43
Iteration:   2980, Loss function: 4.221, Average Loss: 4.221, avg. samples / sec: 65897.45
Iteration:   2980, Loss function: 4.263, Average Loss: 4.228, avg. samples / sec: 65903.86
Iteration:   2980, Loss function: 5.216, Average Loss: 4.234, avg. samples / sec: 65876.87
Iteration:   2980, Loss function: 3.971, Average Loss: 4.207, avg. samples / sec: 65897.14
Iteration:   2980, Loss function: 3.938, Average Loss: 4.210, avg. samples / sec: 65835.82
Iteration:   2980, Loss function: 3.200, Average Loss: 4.229, avg. samples / sec: 65866.25
Iteration:   2980, Loss function: 4.611, Average Loss: 4.221, avg. samples / sec: 65706.87
Iteration:   2980, Loss function: 3.003, Average Loss: 4.209, avg. samples / sec: 65843.20
Iteration:   2980, Loss function: 4.544, Average Loss: 4.200, avg. samples / sec: 65904.20
Iteration:   2980, Loss function: 4.096, Average Loss: 4.233, avg. samples / sec: 65827.70
Iteration:   2980, Loss function: 3.933, Average Loss: 4.232, avg. samples / sec: 65794.94
Iteration:   2980, Loss function: 3.412, Average Loss: 4.215, avg. samples / sec: 65832.68
Iteration:   2980, Loss function: 4.483, Average Loss: 4.219, avg. samples / sec: 65820.01
Iteration:   2980, Loss function: 3.977, Average Loss: 4.191, avg. samples / sec: 65881.37
Iteration:   2980, Loss function: 3.806, Average Loss: 4.219, avg. samples / sec: 65825.89
Iteration:   2980, Loss function: 3.100, Average Loss: 4.239, avg. samples / sec: 65824.44
Iteration:   3000, Loss function: 3.062, Average Loss: 4.215, avg. samples / sec: 66188.19
Iteration:   3000, Loss function: 2.680, Average Loss: 4.194, avg. samples / sec: 66103.31
Iteration:   3000, Loss function: 3.609, Average Loss: 4.203, avg. samples / sec: 66173.08
Iteration:   3000, Loss function: 5.157, Average Loss: 4.201, avg. samples / sec: 66240.79
Iteration:   3000, Loss function: 4.310, Average Loss: 4.229, avg. samples / sec: 66108.42
Iteration:   3000, Loss function: 4.311, Average Loss: 4.201, avg. samples / sec: 66108.36
Iteration:   3000, Loss function: 3.546, Average Loss: 4.203, avg. samples / sec: 66029.78
Iteration:   3000, Loss function: 3.987, Average Loss: 4.218, avg. samples / sec: 65960.68
Iteration:   3000, Loss function: 4.406, Average Loss: 4.209, avg. samples / sec: 66063.43
Iteration:   3000, Loss function: 3.814, Average Loss: 4.221, avg. samples / sec: 66188.75
Iteration:   3000, Loss function: 3.294, Average Loss: 4.223, avg. samples / sec: 66210.58
Iteration:   3000, Loss function: 4.353, Average Loss: 4.235, avg. samples / sec: 66259.39
Iteration:   3000, Loss function: 3.859, Average Loss: 4.201, avg. samples / sec: 66074.51
Iteration:   3000, Loss function: 4.453, Average Loss: 4.203, avg. samples / sec: 66117.67
Iteration:   3000, Loss function: 3.661, Average Loss: 4.202, avg. samples / sec: 66158.45
Iteration:   3000, Loss function: 4.321, Average Loss: 4.206, avg. samples / sec: 66108.61
Iteration:   3000, Loss function: 3.716, Average Loss: 4.201, avg. samples / sec: 66147.80
Iteration:   3000, Loss function: 4.070, Average Loss: 4.218, avg. samples / sec: 66108.39
Iteration:   3000, Loss function: 2.627, Average Loss: 4.207, avg. samples / sec: 65979.55
Iteration:   3000, Loss function: 4.725, Average Loss: 4.190, avg. samples / sec: 66168.58
Iteration:   3000, Loss function: 4.260, Average Loss: 4.215, avg. samples / sec: 66126.57
Iteration:   3000, Loss function: 3.286, Average Loss: 4.211, avg. samples / sec: 66140.38
Iteration:   3000, Loss function: 3.030, Average Loss: 4.220, avg. samples / sec: 66064.91
Iteration:   3000, Loss function: 3.382, Average Loss: 4.207, avg. samples / sec: 66055.81
Iteration:   3000, Loss function: 3.864, Average Loss: 4.221, avg. samples / sec: 66022.08
Iteration:   3000, Loss function: 3.281, Average Loss: 4.211, avg. samples / sec: 66061.63
Iteration:   3000, Loss function: 4.503, Average Loss: 4.201, avg. samples / sec: 65934.04
Iteration:   3000, Loss function: 3.023, Average Loss: 4.218, avg. samples / sec: 66018.40
Iteration:   3000, Loss function: 3.891, Average Loss: 4.218, avg. samples / sec: 65955.12
Iteration:   3000, Loss function: 3.640, Average Loss: 4.223, avg. samples / sec: 65922.63
:::MLL 1558651772.348 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558651772.349 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 3.523, Average Loss: 4.196, avg. samples / sec: 65570.43
Iteration:   3020, Loss function: 4.127, Average Loss: 4.192, avg. samples / sec: 65542.61
Iteration:   3020, Loss function: 4.083, Average Loss: 4.210, avg. samples / sec: 65476.02
Iteration:   3020, Loss function: 3.367, Average Loss: 4.195, avg. samples / sec: 65561.73
Iteration:   3020, Loss function: 4.045, Average Loss: 4.198, avg. samples / sec: 65475.01
Iteration:   3020, Loss function: 5.110, Average Loss: 4.213, avg. samples / sec: 65695.50
Iteration:   3020, Loss function: 4.310, Average Loss: 4.216, avg. samples / sec: 65613.87
Iteration:   3020, Loss function: 4.867, Average Loss: 4.220, avg. samples / sec: 65506.06
Iteration:   3020, Loss function: 3.441, Average Loss: 4.221, avg. samples / sec: 65500.39
Iteration:   3020, Loss function: 2.794, Average Loss: 4.228, avg. samples / sec: 65495.67
Iteration:   3020, Loss function: 3.202, Average Loss: 4.216, avg. samples / sec: 65615.27
Iteration:   3020, Loss function: 3.382, Average Loss: 4.189, avg. samples / sec: 65548.01
Iteration:   3020, Loss function: 5.007, Average Loss: 4.219, avg. samples / sec: 65515.19
Iteration:   3020, Loss function: 4.100, Average Loss: 4.216, avg. samples / sec: 65578.48
Iteration:   3020, Loss function: 3.783, Average Loss: 4.195, avg. samples / sec: 65407.34
Iteration:   3020, Loss function: 3.719, Average Loss: 4.201, avg. samples / sec: 65441.02
Iteration:   3020, Loss function: 5.082, Average Loss: 4.214, avg. samples / sec: 65539.72
Iteration:   3020, Loss function: 3.363, Average Loss: 4.193, avg. samples / sec: 65597.19
Iteration:   3020, Loss function: 4.801, Average Loss: 4.201, avg. samples / sec: 65480.82
Iteration:   3020, Loss function: 4.880, Average Loss: 4.208, avg. samples / sec: 65578.08
Iteration:   3020, Loss function: 4.202, Average Loss: 4.193, avg. samples / sec: 65395.14
Iteration:   3020, Loss function: 4.617, Average Loss: 4.199, avg. samples / sec: 65466.83
Iteration:   3020, Loss function: 3.952, Average Loss: 4.199, avg. samples / sec: 65525.82
Iteration:   3020, Loss function: 3.624, Average Loss: 4.204, avg. samples / sec: 65467.59
Iteration:   3020, Loss function: 4.057, Average Loss: 4.218, avg. samples / sec: 65409.74
Iteration:   3020, Loss function: 4.929, Average Loss: 4.199, avg. samples / sec: 65411.04
Iteration:   3020, Loss function: 4.977, Average Loss: 4.225, avg. samples / sec: 65322.78
Iteration:   3020, Loss function: 4.053, Average Loss: 4.216, avg. samples / sec: 65613.62
Iteration:   3020, Loss function: 4.292, Average Loss: 4.200, avg. samples / sec: 65371.14
Iteration:   3020, Loss function: 4.165, Average Loss: 4.214, avg. samples / sec: 65442.57
Iteration:   3040, Loss function: 4.195, Average Loss: 4.205, avg. samples / sec: 66185.26
Iteration:   3040, Loss function: 2.481, Average Loss: 4.192, avg. samples / sec: 66210.61
Iteration:   3040, Loss function: 4.199, Average Loss: 4.188, avg. samples / sec: 66187.63
Iteration:   3040, Loss function: 4.030, Average Loss: 4.214, avg. samples / sec: 66233.45
Iteration:   3040, Loss function: 3.419, Average Loss: 4.189, avg. samples / sec: 66091.90
Iteration:   3040, Loss function: 3.743, Average Loss: 4.191, avg. samples / sec: 66281.92
Iteration:   3040, Loss function: 3.412, Average Loss: 4.211, avg. samples / sec: 66214.12
Iteration:   3040, Loss function: 3.648, Average Loss: 4.211, avg. samples / sec: 66375.35
Iteration:   3040, Loss function: 3.996, Average Loss: 4.193, avg. samples / sec: 66205.75
Iteration:   3040, Loss function: 4.694, Average Loss: 4.218, avg. samples / sec: 66139.79
Iteration:   3040, Loss function: 3.787, Average Loss: 4.184, avg. samples / sec: 66162.80
Iteration:   3040, Loss function: 5.035, Average Loss: 4.196, avg. samples / sec: 66190.98
Iteration:   3040, Loss function: 4.042, Average Loss: 4.187, avg. samples / sec: 66192.85
Iteration:   3040, Loss function: 3.270, Average Loss: 4.190, avg. samples / sec: 66013.02
Iteration:   3040, Loss function: 4.166, Average Loss: 4.224, avg. samples / sec: 66260.23
Iteration:   3040, Loss function: 3.763, Average Loss: 4.213, avg. samples / sec: 66215.93
Iteration:   3040, Loss function: 3.796, Average Loss: 4.194, avg. samples / sec: 66178.36
Iteration:   3040, Loss function: 3.284, Average Loss: 4.198, avg. samples / sec: 66257.67
Iteration:   3040, Loss function: 3.469, Average Loss: 4.197, avg. samples / sec: 66134.11
Iteration:   3040, Loss function: 4.108, Average Loss: 4.224, avg. samples / sec: 66077.27
Iteration:   3040, Loss function: 4.736, Average Loss: 4.206, avg. samples / sec: 66155.31
Iteration:   3040, Loss function: 4.463, Average Loss: 4.196, avg. samples / sec: 66175.54
Iteration:   3040, Loss function: 3.393, Average Loss: 4.205, avg. samples / sec: 66050.42
Iteration:   3040, Loss function: 3.865, Average Loss: 4.204, avg. samples / sec: 66108.18
Iteration:   3040, Loss function: 4.913, Average Loss: 4.211, avg. samples / sec: 66083.41
Iteration:   3040, Loss function: 3.633, Average Loss: 4.207, avg. samples / sec: 66185.64
Iteration:   3040, Loss function: 3.437, Average Loss: 4.212, avg. samples / sec: 66075.01
Iteration:   3040, Loss function: 4.278, Average Loss: 4.209, avg. samples / sec: 66058.56
Iteration:   3040, Loss function: 3.851, Average Loss: 4.183, avg. samples / sec: 66014.62
Iteration:   3040, Loss function: 4.179, Average Loss: 4.209, avg. samples / sec: 65973.95
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558651773.328 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.44s)
DONE (t=2.33s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.16922
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31119
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.16964
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04233
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18551
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.27231
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18169
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26802
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28214
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.29458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.44295
Current AP: 0.16922 AP goal: 0.23000
:::MLL 1558651776.699 eval_accuracy: {"value": 0.16921738407430562, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558651776.723 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558651776.729 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558651776.730 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 3.767, Average Loss: 4.190, avg. samples / sec: 8578.36
Iteration:   3060, Loss function: 3.995, Average Loss: 4.198, avg. samples / sec: 8577.19
Iteration:   3060, Loss function: 3.853, Average Loss: 4.185, avg. samples / sec: 8576.74
Iteration:   3060, Loss function: 3.777, Average Loss: 4.206, avg. samples / sec: 8577.40
Iteration:   3060, Loss function: 3.323, Average Loss: 4.180, avg. samples / sec: 8577.08
Iteration:   3060, Loss function: 4.075, Average Loss: 4.189, avg. samples / sec: 8576.02
Iteration:   3060, Loss function: 3.230, Average Loss: 4.198, avg. samples / sec: 8579.35
Iteration:   3060, Loss function: 3.248, Average Loss: 4.185, avg. samples / sec: 8577.84
Iteration:   3060, Loss function: 2.624, Average Loss: 4.185, avg. samples / sec: 8577.60
Iteration:   3060, Loss function: 4.302, Average Loss: 4.199, avg. samples / sec: 8578.66
Iteration:   3060, Loss function: 4.330, Average Loss: 4.205, avg. samples / sec: 8577.01
Iteration:   3060, Loss function: 5.026, Average Loss: 4.208, avg. samples / sec: 8575.76
Iteration:   3060, Loss function: 4.548, Average Loss: 4.192, avg. samples / sec: 8576.71
Iteration:   3060, Loss function: 3.262, Average Loss: 4.191, avg. samples / sec: 8577.97
Iteration:   3060, Loss function: 3.439, Average Loss: 4.203, avg. samples / sec: 8577.11
Iteration:   3060, Loss function: 3.965, Average Loss: 4.204, avg. samples / sec: 8578.64
Iteration:   3060, Loss function: 3.593, Average Loss: 4.219, avg. samples / sec: 8577.67
Iteration:   3060, Loss function: 4.405, Average Loss: 4.195, avg. samples / sec: 8577.51
Iteration:   3060, Loss function: 4.133, Average Loss: 4.204, avg. samples / sec: 8578.41
Iteration:   3060, Loss function: 3.002, Average Loss: 4.193, avg. samples / sec: 8576.11
Iteration:   3060, Loss function: 3.529, Average Loss: 4.204, avg. samples / sec: 8577.47
Iteration:   3060, Loss function: 4.341, Average Loss: 4.184, avg. samples / sec: 8576.08
Iteration:   3060, Loss function: 3.318, Average Loss: 4.204, avg. samples / sec: 8577.84
Iteration:   3060, Loss function: 4.045, Average Loss: 4.203, avg. samples / sec: 8578.68
Iteration:   3060, Loss function: 4.213, Average Loss: 4.217, avg. samples / sec: 8576.29
Iteration:   3060, Loss function: 3.202, Average Loss: 4.206, avg. samples / sec: 8577.56
Iteration:   3060, Loss function: 4.017, Average Loss: 4.193, avg. samples / sec: 8576.48
Iteration:   3060, Loss function: 3.995, Average Loss: 4.177, avg. samples / sec: 8577.62
Iteration:   3060, Loss function: 2.596, Average Loss: 4.192, avg. samples / sec: 8575.01
Iteration:   3060, Loss function: 3.132, Average Loss: 4.208, avg. samples / sec: 8573.84
:::MLL 1558651777.542 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558651777.542 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 4.470, Average Loss: 4.191, avg. samples / sec: 65836.93
Iteration:   3080, Loss function: 3.602, Average Loss: 4.185, avg. samples / sec: 65883.49
Iteration:   3080, Loss function: 2.958, Average Loss: 4.191, avg. samples / sec: 65637.95
Iteration:   3080, Loss function: 3.312, Average Loss: 4.175, avg. samples / sec: 65695.47
Iteration:   3080, Loss function: 4.483, Average Loss: 4.174, avg. samples / sec: 65702.73
Iteration:   3080, Loss function: 5.079, Average Loss: 4.195, avg. samples / sec: 65683.07
Iteration:   3080, Loss function: 3.775, Average Loss: 4.174, avg. samples / sec: 65706.25
Iteration:   3080, Loss function: 3.326, Average Loss: 4.182, avg. samples / sec: 65765.92
Iteration:   3080, Loss function: 2.860, Average Loss: 4.174, avg. samples / sec: 65642.26
Iteration:   3080, Loss function: 3.205, Average Loss: 4.204, avg. samples / sec: 65792.42
Iteration:   3080, Loss function: 4.022, Average Loss: 4.188, avg. samples / sec: 65696.58
Iteration:   3080, Loss function: 3.939, Average Loss: 4.181, avg. samples / sec: 65718.20
Iteration:   3080, Loss function: 4.725, Average Loss: 4.195, avg. samples / sec: 65775.99
Iteration:   3080, Loss function: 3.354, Average Loss: 4.192, avg. samples / sec: 65685.64
Iteration:   3080, Loss function: 2.873, Average Loss: 4.179, avg. samples / sec: 65558.99
Iteration:   3080, Loss function: 4.075, Average Loss: 4.198, avg. samples / sec: 65675.76
Iteration:   3080, Loss function: 3.954, Average Loss: 4.193, avg. samples / sec: 65846.74
Iteration:   3080, Loss function: 3.136, Average Loss: 4.184, avg. samples / sec: 65644.12
Iteration:   3080, Loss function: 2.914, Average Loss: 4.196, avg. samples / sec: 65638.22
Iteration:   3080, Loss function: 3.868, Average Loss: 4.182, avg. samples / sec: 65624.68
Iteration:   3080, Loss function: 3.490, Average Loss: 4.193, avg. samples / sec: 65678.11
Iteration:   3080, Loss function: 2.952, Average Loss: 4.202, avg. samples / sec: 65650.42
Iteration:   3080, Loss function: 2.839, Average Loss: 4.181, avg. samples / sec: 65639.11
Iteration:   3080, Loss function: 4.548, Average Loss: 4.182, avg. samples / sec: 65741.17
Iteration:   3080, Loss function: 2.756, Average Loss: 4.194, avg. samples / sec: 65603.97
Iteration:   3080, Loss function: 3.203, Average Loss: 4.194, avg. samples / sec: 65625.29
Iteration:   3080, Loss function: 3.070, Average Loss: 4.188, avg. samples / sec: 65524.76
Iteration:   3080, Loss function: 4.492, Average Loss: 4.171, avg. samples / sec: 65685.25
Iteration:   3080, Loss function: 4.177, Average Loss: 4.191, avg. samples / sec: 65588.55
Iteration:   3080, Loss function: 5.579, Average Loss: 4.179, avg. samples / sec: 65575.31
Iteration:   3100, Loss function: 2.603, Average Loss: 4.165, avg. samples / sec: 66087.28
Iteration:   3100, Loss function: 3.780, Average Loss: 4.164, avg. samples / sec: 66079.78
Iteration:   3100, Loss function: 3.263, Average Loss: 4.174, avg. samples / sec: 65991.38
Iteration:   3100, Loss function: 5.165, Average Loss: 4.162, avg. samples / sec: 66021.24
Iteration:   3100, Loss function: 4.013, Average Loss: 4.169, avg. samples / sec: 66093.11
Iteration:   3100, Loss function: 2.562, Average Loss: 4.174, avg. samples / sec: 66169.32
Iteration:   3100, Loss function: 3.421, Average Loss: 4.161, avg. samples / sec: 66002.26
Iteration:   3100, Loss function: 3.802, Average Loss: 4.181, avg. samples / sec: 66055.25
Iteration:   3100, Loss function: 4.840, Average Loss: 4.185, avg. samples / sec: 66188.78
Iteration:   3100, Loss function: 4.790, Average Loss: 4.177, avg. samples / sec: 65955.49
Iteration:   3100, Loss function: 3.191, Average Loss: 4.192, avg. samples / sec: 66111.40
Iteration:   3100, Loss function: 2.845, Average Loss: 4.170, avg. samples / sec: 65997.68
Iteration:   3100, Loss function: 4.301, Average Loss: 4.184, avg. samples / sec: 66084.86
Iteration:   3100, Loss function: 4.407, Average Loss: 4.184, avg. samples / sec: 65882.66
Iteration:   3100, Loss function: 3.025, Average Loss: 4.167, avg. samples / sec: 66176.22
Iteration:   3100, Loss function: 3.260, Average Loss: 4.185, avg. samples / sec: 66027.92
Iteration:   3100, Loss function: 3.979, Average Loss: 4.192, avg. samples / sec: 65940.59
Iteration:   3100, Loss function: 3.837, Average Loss: 4.171, avg. samples / sec: 66027.65
Iteration:   3100, Loss function: 2.826, Average Loss: 4.170, avg. samples / sec: 66061.75
Iteration:   3100, Loss function: 4.071, Average Loss: 4.186, avg. samples / sec: 66010.91
Iteration:   3100, Loss function: 3.405, Average Loss: 4.181, avg. samples / sec: 65934.35
Iteration:   3100, Loss function: 4.146, Average Loss: 4.190, avg. samples / sec: 66069.74
Iteration:   3100, Loss function: 2.772, Average Loss: 4.180, avg. samples / sec: 65985.82
Iteration:   3100, Loss function: 3.678, Average Loss: 4.187, avg. samples / sec: 65900.75
Iteration:   3100, Loss function: 3.727, Average Loss: 4.154, avg. samples / sec: 66090.16
Iteration:   3100, Loss function: 3.201, Average Loss: 4.172, avg. samples / sec: 65900.78
Iteration:   3100, Loss function: 4.410, Average Loss: 4.182, avg. samples / sec: 65883.71
Iteration:   3100, Loss function: 3.900, Average Loss: 4.174, avg. samples / sec: 66033.83
Iteration:   3100, Loss function: 2.768, Average Loss: 4.169, avg. samples / sec: 65929.17
Iteration:   3100, Loss function: 3.280, Average Loss: 4.182, avg. samples / sec: 66000.12
Iteration:   3120, Loss function: 3.479, Average Loss: 4.144, avg. samples / sec: 65997.56
Iteration:   3120, Loss function: 2.812, Average Loss: 4.165, avg. samples / sec: 65963.30
Iteration:   3120, Loss function: 2.629, Average Loss: 4.153, avg. samples / sec: 65976.06
Iteration:   3120, Loss function: 2.927, Average Loss: 4.180, avg. samples / sec: 65991.72
Iteration:   3120, Loss function: 2.624, Average Loss: 4.170, avg. samples / sec: 65886.64
Iteration:   3120, Loss function: 3.483, Average Loss: 4.153, avg. samples / sec: 65821.00
Iteration:   3120, Loss function: 4.867, Average Loss: 4.179, avg. samples / sec: 66002.32
Iteration:   3120, Loss function: 4.402, Average Loss: 4.170, avg. samples / sec: 65962.41
Iteration:   3120, Loss function: 4.411, Average Loss: 4.160, avg. samples / sec: 65868.53
Iteration:   3120, Loss function: 3.702, Average Loss: 4.165, avg. samples / sec: 66041.63
Iteration:   3120, Loss function: 3.012, Average Loss: 4.146, avg. samples / sec: 65830.53
Iteration:   3120, Loss function: 3.139, Average Loss: 4.172, avg. samples / sec: 65885.50
Iteration:   3120, Loss function: 3.399, Average Loss: 4.163, avg. samples / sec: 65829.82
Iteration:   3120, Loss function: 5.224, Average Loss: 4.169, avg. samples / sec: 65941.48
Iteration:   3120, Loss function: 4.159, Average Loss: 4.174, avg. samples / sec: 65825.70
Iteration:   3120, Loss function: 3.416, Average Loss: 4.162, avg. samples / sec: 65902.97
Iteration:   3120, Loss function: 4.065, Average Loss: 4.170, avg. samples / sec: 65918.78
Iteration:   3120, Loss function: 4.928, Average Loss: 4.156, avg. samples / sec: 65893.75
Iteration:   3120, Loss function: 4.445, Average Loss: 4.162, avg. samples / sec: 65926.70
Iteration:   3120, Loss function: 2.849, Average Loss: 4.138, avg. samples / sec: 65899.64
Iteration:   3120, Loss function: 3.536, Average Loss: 4.164, avg. samples / sec: 65840.16
Iteration:   3120, Loss function: 3.472, Average Loss: 4.183, avg. samples / sec: 65884.69
Iteration:   3120, Loss function: 4.181, Average Loss: 4.156, avg. samples / sec: 65837.39
Iteration:   3120, Loss function: 2.833, Average Loss: 4.171, avg. samples / sec: 65876.23
Iteration:   3120, Loss function: 2.922, Average Loss: 4.178, avg. samples / sec: 65812.36
Iteration:   3120, Loss function: 3.494, Average Loss: 4.170, avg. samples / sec: 65929.17
Iteration:   3120, Loss function: 3.634, Average Loss: 4.168, avg. samples / sec: 65951.45
Iteration:   3120, Loss function: 2.615, Average Loss: 4.152, avg. samples / sec: 65694.98
Iteration:   3120, Loss function: 3.645, Average Loss: 4.150, avg. samples / sec: 65673.46
Iteration:   3120, Loss function: 3.054, Average Loss: 4.160, avg. samples / sec: 65894.37
Iteration:   3140, Loss function: 4.969, Average Loss: 4.140, avg. samples / sec: 66473.88
Iteration:   3140, Loss function: 4.377, Average Loss: 4.142, avg. samples / sec: 66353.88
Iteration:   3140, Loss function: 2.678, Average Loss: 4.135, avg. samples / sec: 66439.63
Iteration:   3140, Loss function: 4.879, Average Loss: 4.148, avg. samples / sec: 66367.85
Iteration:   3140, Loss function: 3.121, Average Loss: 4.159, avg. samples / sec: 66260.91
Iteration:   3140, Loss function: 3.970, Average Loss: 4.142, avg. samples / sec: 66322.19
Iteration:   3140, Loss function: 3.557, Average Loss: 4.159, avg. samples / sec: 66260.51
Iteration:   3140, Loss function: 3.101, Average Loss: 4.138, avg. samples / sec: 66234.41
Iteration:   3140, Loss function: 3.233, Average Loss: 4.155, avg. samples / sec: 66322.84
Iteration:   3140, Loss function: 4.209, Average Loss: 4.151, avg. samples / sec: 66125.64
Iteration:   3140, Loss function: 2.941, Average Loss: 4.147, avg. samples / sec: 66284.16
Iteration:   3140, Loss function: 4.398, Average Loss: 4.166, avg. samples / sec: 66343.04
Iteration:   3140, Loss function: 2.069, Average Loss: 4.161, avg. samples / sec: 66268.17
Iteration:   3140, Loss function: 3.486, Average Loss: 4.132, avg. samples / sec: 66112.39
Iteration:   3140, Loss function: 3.531, Average Loss: 4.145, avg. samples / sec: 66219.57
Iteration:   3140, Loss function: 3.613, Average Loss: 4.167, avg. samples / sec: 66166.15
Iteration:   3140, Loss function: 3.719, Average Loss: 4.174, avg. samples / sec: 66251.82
Iteration:   3140, Loss function: 3.397, Average Loss: 4.133, avg. samples / sec: 66184.70
Iteration:   3140, Loss function: 3.946, Average Loss: 4.169, avg. samples / sec: 66129.21
Iteration:   3140, Loss function: 3.699, Average Loss: 4.138, avg. samples / sec: 66091.25
Iteration:   3140, Loss function: 3.990, Average Loss: 4.126, avg. samples / sec: 66217.20
Iteration:   3140, Loss function: 3.774, Average Loss: 4.150, avg. samples / sec: 66218.57
Iteration:   3140, Loss function: 3.815, Average Loss: 4.155, avg. samples / sec: 66169.82
Iteration:   3140, Loss function: 2.428, Average Loss: 4.165, avg. samples / sec: 66159.29
Iteration:   3140, Loss function: 3.825, Average Loss: 4.148, avg. samples / sec: 66250.51
Iteration:   3140, Loss function: 3.131, Average Loss: 4.155, avg. samples / sec: 66128.21
Iteration:   3140, Loss function: 3.141, Average Loss: 4.156, avg. samples / sec: 66104.30
Iteration:   3140, Loss function: 2.933, Average Loss: 4.154, avg. samples / sec: 66056.06
Iteration:   3140, Loss function: 3.861, Average Loss: 4.146, avg. samples / sec: 66125.92
Iteration:   3140, Loss function: 2.252, Average Loss: 4.160, avg. samples / sec: 66189.65
:::MLL 1558651779.326 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558651779.327 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 4.187, Average Loss: 4.127, avg. samples / sec: 65654.25
Iteration:   3160, Loss function: 2.933, Average Loss: 4.126, avg. samples / sec: 65593.59
Iteration:   3160, Loss function: 2.065, Average Loss: 4.119, avg. samples / sec: 65653.85
Iteration:   3160, Loss function: 3.789, Average Loss: 4.116, avg. samples / sec: 65657.64
Iteration:   3160, Loss function: 3.683, Average Loss: 4.135, avg. samples / sec: 65641.62
Iteration:   3160, Loss function: 4.191, Average Loss: 4.129, avg. samples / sec: 65605.83
Iteration:   3160, Loss function: 2.819, Average Loss: 4.134, avg. samples / sec: 65630.73
Iteration:   3160, Loss function: 3.438, Average Loss: 4.144, avg. samples / sec: 65558.35
Iteration:   3160, Loss function: 3.809, Average Loss: 4.142, avg. samples / sec: 65561.31
Iteration:   3160, Loss function: 2.874, Average Loss: 4.133, avg. samples / sec: 65504.26
Iteration:   3160, Loss function: 2.645, Average Loss: 4.135, avg. samples / sec: 65670.98
Iteration:   3160, Loss function: 3.967, Average Loss: 4.143, avg. samples / sec: 65706.19
Iteration:   3160, Loss function: 3.989, Average Loss: 4.157, avg. samples / sec: 65626.24
Iteration:   3160, Loss function: 4.643, Average Loss: 4.128, avg. samples / sec: 65633.18
Iteration:   3160, Loss function: 4.298, Average Loss: 4.137, avg. samples / sec: 65730.71
Iteration:   3160, Loss function: 3.271, Average Loss: 4.144, avg. samples / sec: 65686.81
Iteration:   3160, Loss function: 2.564, Average Loss: 4.146, avg. samples / sec: 65656.17
Iteration:   3160, Loss function: 4.339, Average Loss: 4.140, avg. samples / sec: 65525.12
Iteration:   3160, Loss function: 3.661, Average Loss: 4.151, avg. samples / sec: 65502.28
Iteration:   3160, Loss function: 3.897, Average Loss: 4.117, avg. samples / sec: 65583.27
Iteration:   3160, Loss function: 2.387, Average Loss: 4.150, avg. samples / sec: 65537.52
Iteration:   3160, Loss function: 3.455, Average Loss: 4.152, avg. samples / sec: 65622.67
Iteration:   3160, Loss function: 3.708, Average Loss: 4.164, avg. samples / sec: 65550.81
Iteration:   3160, Loss function: 3.293, Average Loss: 4.122, avg. samples / sec: 65411.68
Iteration:   3160, Loss function: 3.556, Average Loss: 4.148, avg. samples / sec: 65445.52
Iteration:   3160, Loss function: 4.117, Average Loss: 4.147, avg. samples / sec: 65658.25
Iteration:   3160, Loss function: 2.732, Average Loss: 4.141, avg. samples / sec: 65617.72
Iteration:   3160, Loss function: 3.405, Average Loss: 4.149, avg. samples / sec: 65431.88
Iteration:   3160, Loss function: 3.823, Average Loss: 4.125, avg. samples / sec: 65530.30
Iteration:   3160, Loss function: 2.914, Average Loss: 4.134, avg. samples / sec: 65508.95
Iteration:   3180, Loss function: 3.436, Average Loss: 4.136, avg. samples / sec: 66124.34
Iteration:   3180, Loss function: 2.925, Average Loss: 4.126, avg. samples / sec: 66074.79
Iteration:   3180, Loss function: 4.742, Average Loss: 4.116, avg. samples / sec: 66228.90
Iteration:   3180, Loss function: 3.371, Average Loss: 4.129, avg. samples / sec: 66128.40
Iteration:   3180, Loss function: 4.005, Average Loss: 4.116, avg. samples / sec: 65974.91
Iteration:   3180, Loss function: 4.506, Average Loss: 4.114, avg. samples / sec: 65999.91
Iteration:   3180, Loss function: 4.425, Average Loss: 4.104, avg. samples / sec: 65967.93
Iteration:   3180, Loss function: 3.618, Average Loss: 4.131, avg. samples / sec: 66178.71
Iteration:   3180, Loss function: 3.380, Average Loss: 4.149, avg. samples / sec: 66154.01
Iteration:   3180, Loss function: 3.849, Average Loss: 4.119, avg. samples / sec: 65934.38
Iteration:   3180, Loss function: 3.703, Average Loss: 4.124, avg. samples / sec: 66268.73
Iteration:   3180, Loss function: 3.693, Average Loss: 4.124, avg. samples / sec: 65972.10
Iteration:   3180, Loss function: 4.220, Average Loss: 4.126, avg. samples / sec: 66152.92
Iteration:   3180, Loss function: 3.952, Average Loss: 4.110, avg. samples / sec: 65915.91
Iteration:   3180, Loss function: 1.542, Average Loss: 4.127, avg. samples / sec: 66087.78
Iteration:   3180, Loss function: 3.882, Average Loss: 4.119, avg. samples / sec: 66041.60
Iteration:   3180, Loss function: 4.362, Average Loss: 4.136, avg. samples / sec: 66097.17
Iteration:   3180, Loss function: 4.098, Average Loss: 4.124, avg. samples / sec: 66059.93
Iteration:   3180, Loss function: 4.409, Average Loss: 4.137, avg. samples / sec: 66093.51
Iteration:   3180, Loss function: 3.268, Average Loss: 4.138, avg. samples / sec: 66082.91
Iteration:   3180, Loss function: 3.709, Average Loss: 4.146, avg. samples / sec: 65998.30
Iteration:   3180, Loss function: 3.116, Average Loss: 4.136, avg. samples / sec: 66083.47
Iteration:   3180, Loss function: 2.757, Average Loss: 4.120, avg. samples / sec: 65974.54
Iteration:   3180, Loss function: 3.720, Average Loss: 4.124, avg. samples / sec: 65986.47
Iteration:   3180, Loss function: 3.376, Average Loss: 4.109, avg. samples / sec: 66026.16
Iteration:   3180, Loss function: 3.421, Average Loss: 4.127, avg. samples / sec: 65910.76
Iteration:   3180, Loss function: 3.959, Average Loss: 4.141, avg. samples / sec: 65985.72
Iteration:   3180, Loss function: 3.011, Average Loss: 4.102, avg. samples / sec: 65997.93
Iteration:   3180, Loss function: 6.024, Average Loss: 4.136, avg. samples / sec: 65970.43
Iteration:   3180, Loss function: 3.258, Average Loss: 4.114, avg. samples / sec: 65947.90
Iteration:   3200, Loss function: 2.266, Average Loss: 4.104, avg. samples / sec: 66163.51
Iteration:   3200, Loss function: 5.054, Average Loss: 4.116, avg. samples / sec: 66115.06
Iteration:   3200, Loss function: 3.359, Average Loss: 4.097, avg. samples / sec: 66306.18
Iteration:   3200, Loss function: 3.807, Average Loss: 4.115, avg. samples / sec: 66159.79
Iteration:   3200, Loss function: 4.093, Average Loss: 4.090, avg. samples / sec: 66128.74
Iteration:   3200, Loss function: 2.437, Average Loss: 4.106, avg. samples / sec: 66200.06
Iteration:   3200, Loss function: 4.153, Average Loss: 4.106, avg. samples / sec: 66072.47
Iteration:   3200, Loss function: 3.712, Average Loss: 4.107, avg. samples / sec: 66074.39
Iteration:   3200, Loss function: 3.429, Average Loss: 4.126, avg. samples / sec: 65972.63
Iteration:   3200, Loss function: 3.030, Average Loss: 4.110, avg. samples / sec: 66037.76
Iteration:   3200, Loss function: 4.157, Average Loss: 4.116, avg. samples / sec: 66097.39
Iteration:   3200, Loss function: 3.540, Average Loss: 4.125, avg. samples / sec: 66135.29
Iteration:   3200, Loss function: 3.721, Average Loss: 4.110, avg. samples / sec: 66056.86
Iteration:   3200, Loss function: 2.515, Average Loss: 4.127, avg. samples / sec: 66156.80
Iteration:   3200, Loss function: 3.071, Average Loss: 4.115, avg. samples / sec: 65987.05
Iteration:   3200, Loss function: 3.839, Average Loss: 4.127, avg. samples / sec: 66060.73
Iteration:   3200, Loss function: 3.481, Average Loss: 4.111, avg. samples / sec: 66033.00
Iteration:   3200, Loss function: 3.977, Average Loss: 4.116, avg. samples / sec: 66112.98
Iteration:   3200, Loss function: 2.683, Average Loss: 4.113, avg. samples / sec: 66074.20
Iteration:   3200, Loss function: 3.495, Average Loss: 4.103, avg. samples / sec: 65989.25
Iteration:   3200, Loss function: 2.645, Average Loss: 4.103, avg. samples / sec: 65917.95
Iteration:   3200, Loss function: 3.390, Average Loss: 4.125, avg. samples / sec: 66013.45
Iteration:   3200, Loss function: 3.161, Average Loss: 4.125, avg. samples / sec: 65979.58
Iteration:   3200, Loss function: 4.597, Average Loss: 4.112, avg. samples / sec: 65978.90
Iteration:   3200, Loss function: 4.278, Average Loss: 4.115, avg. samples / sec: 65963.92
Iteration:   3200, Loss function: 4.014, Average Loss: 4.123, avg. samples / sec: 66077.15
Iteration:   3200, Loss function: 3.503, Average Loss: 4.130, avg. samples / sec: 66011.32
Iteration:   3200, Loss function: 3.059, Average Loss: 4.102, avg. samples / sec: 66053.46
Iteration:   3200, Loss function: 3.968, Average Loss: 4.134, avg. samples / sec: 65963.05
Iteration:   3200, Loss function: 3.814, Average Loss: 4.089, avg. samples / sec: 66001.14
:::MLL 1558651781.110 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558651781.110 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 4.289, Average Loss: 4.117, avg. samples / sec: 65783.97
Iteration:   3220, Loss function: 4.469, Average Loss: 4.100, avg. samples / sec: 65772.09
Iteration:   3220, Loss function: 2.820, Average Loss: 4.117, avg. samples / sec: 65837.69
Iteration:   3220, Loss function: 3.123, Average Loss: 4.105, avg. samples / sec: 65619.73
Iteration:   3220, Loss function: 3.365, Average Loss: 4.078, avg. samples / sec: 65685.61
Iteration:   3220, Loss function: 3.617, Average Loss: 4.099, avg. samples / sec: 65852.00
Iteration:   3220, Loss function: 4.259, Average Loss: 4.115, avg. samples / sec: 65859.51
Iteration:   3220, Loss function: 3.474, Average Loss: 4.109, avg. samples / sec: 65864.96
Iteration:   3220, Loss function: 4.659, Average Loss: 4.093, avg. samples / sec: 65582.72
Iteration:   3220, Loss function: 3.030, Average Loss: 4.104, avg. samples / sec: 65641.10
Iteration:   3220, Loss function: 2.700, Average Loss: 4.087, avg. samples / sec: 65805.45
Iteration:   3220, Loss function: 2.454, Average Loss: 4.100, avg. samples / sec: 65725.35
Iteration:   3220, Loss function: 2.723, Average Loss: 4.099, avg. samples / sec: 65705.49
Iteration:   3220, Loss function: 4.044, Average Loss: 4.100, avg. samples / sec: 65770.90
Iteration:   3220, Loss function: 3.752, Average Loss: 4.094, avg. samples / sec: 65624.56
Iteration:   3220, Loss function: 4.057, Average Loss: 4.100, avg. samples / sec: 65707.45
Iteration:   3220, Loss function: 4.137, Average Loss: 4.121, avg. samples / sec: 65732.70
Iteration:   3220, Loss function: 3.937, Average Loss: 4.099, avg. samples / sec: 65688.22
Iteration:   3220, Loss function: 3.771, Average Loss: 4.091, avg. samples / sec: 65780.78
Iteration:   3220, Loss function: 3.061, Average Loss: 4.117, avg. samples / sec: 65736.41
Iteration:   3220, Loss function: 3.090, Average Loss: 4.093, avg. samples / sec: 65724.27
Iteration:   3220, Loss function: 3.110, Average Loss: 4.094, avg. samples / sec: 65593.80
Iteration:   3220, Loss function: 2.925, Average Loss: 4.081, avg. samples / sec: 65505.36
Iteration:   3220, Loss function: 3.019, Average Loss: 4.114, avg. samples / sec: 65660.46
Iteration:   3220, Loss function: 3.433, Average Loss: 4.100, avg. samples / sec: 65665.47
Iteration:   3220, Loss function: 2.758, Average Loss: 4.115, avg. samples / sec: 65597.53
Iteration:   3220, Loss function: 3.849, Average Loss: 4.102, avg. samples / sec: 65691.58
Iteration:   3220, Loss function: 4.291, Average Loss: 4.104, avg. samples / sec: 65458.41
Iteration:   3220, Loss function: 3.632, Average Loss: 4.114, avg. samples / sec: 65669.70
Iteration:   3220, Loss function: 2.826, Average Loss: 4.076, avg. samples / sec: 65659.32
Iteration:   3240, Loss function: 3.213, Average Loss: 4.105, avg. samples / sec: 65245.24
Iteration:   3240, Loss function: 3.284, Average Loss: 4.085, avg. samples / sec: 65242.61
Iteration:   3240, Loss function: 4.084, Average Loss: 4.080, avg. samples / sec: 65182.84
Iteration:   3240, Loss function: 4.919, Average Loss: 4.094, avg. samples / sec: 65053.51
Iteration:   3240, Loss function: 2.837, Average Loss: 4.089, avg. samples / sec: 65203.43
Iteration:   3240, Loss function: 3.516, Average Loss: 4.101, avg. samples / sec: 65056.67
Iteration:   3240, Loss function: 2.780, Average Loss: 4.068, avg. samples / sec: 65015.70
Iteration:   3240, Loss function: 3.219, Average Loss: 4.102, avg. samples / sec: 65004.06
Iteration:   3240, Loss function: 3.366, Average Loss: 4.071, avg. samples / sec: 65154.18
Iteration:   3240, Loss function: 2.157, Average Loss: 4.082, avg. samples / sec: 65117.93
Iteration:   3240, Loss function: 3.950, Average Loss: 4.090, avg. samples / sec: 64969.27
Iteration:   3240, Loss function: 3.057, Average Loss: 4.082, avg. samples / sec: 65052.01
Iteration:   3240, Loss function: 3.305, Average Loss: 4.109, avg. samples / sec: 65128.34
Iteration:   3240, Loss function: 3.500, Average Loss: 4.098, avg. samples / sec: 65048.65
Iteration:   3240, Loss function: 3.868, Average Loss: 4.072, avg. samples / sec: 65064.12
Iteration:   3240, Loss function: 2.793, Average Loss: 4.106, avg. samples / sec: 64943.94
Iteration:   3240, Loss function: 3.692, Average Loss: 4.090, avg. samples / sec: 65035.44
Iteration:   3240, Loss function: 2.868, Average Loss: 4.088, avg. samples / sec: 65003.37
Iteration:   3240, Loss function: 2.880, Average Loss: 4.083, avg. samples / sec: 65033.37
Iteration:   3240, Loss function: 3.784, Average Loss: 4.086, avg. samples / sec: 65056.43
Iteration:   3240, Loss function: 3.515, Average Loss: 4.095, avg. samples / sec: 65135.48
Iteration:   3240, Loss function: 3.258, Average Loss: 4.098, avg. samples / sec: 65114.35
Iteration:   3240, Loss function: 2.159, Average Loss: 4.084, avg. samples / sec: 65065.38
Iteration:   3240, Loss function: 3.914, Average Loss: 4.065, avg. samples / sec: 65229.51
Iteration:   3240, Loss function: 2.571, Average Loss: 4.101, avg. samples / sec: 65122.65
Iteration:   3240, Loss function: 3.426, Average Loss: 4.079, avg. samples / sec: 65016.75
Iteration:   3240, Loss function: 3.920, Average Loss: 4.101, avg. samples / sec: 65043.10
Iteration:   3240, Loss function: 3.011, Average Loss: 4.096, avg. samples / sec: 64898.45
Iteration:   3240, Loss function: 4.005, Average Loss: 4.092, avg. samples / sec: 64892.51
Iteration:   3240, Loss function: 2.761, Average Loss: 4.090, avg. samples / sec: 64982.06
Iteration:   3260, Loss function: 3.924, Average Loss: 4.069, avg. samples / sec: 66400.62
Iteration:   3260, Loss function: 3.997, Average Loss: 4.098, avg. samples / sec: 66263.97
Iteration:   3260, Loss function: 3.548, Average Loss: 4.058, avg. samples / sec: 66215.93
Iteration:   3260, Loss function: 3.794, Average Loss: 4.076, avg. samples / sec: 66117.01
Iteration:   3260, Loss function: 5.129, Average Loss: 4.086, avg. samples / sec: 66212.22
Iteration:   3260, Loss function: 3.253, Average Loss: 4.088, avg. samples / sec: 66199.07
Iteration:   3260, Loss function: 3.228, Average Loss: 4.085, avg. samples / sec: 66164.54
Iteration:   3260, Loss function: 3.213, Average Loss: 4.074, avg. samples / sec: 66222.31
Iteration:   3260, Loss function: 3.778, Average Loss: 4.069, avg. samples / sec: 66097.79
Iteration:   3260, Loss function: 4.045, Average Loss: 4.081, avg. samples / sec: 66121.67
Iteration:   3260, Loss function: 4.464, Average Loss: 4.083, avg. samples / sec: 66215.09
Iteration:   3260, Loss function: 3.638, Average Loss: 4.084, avg. samples / sec: 66241.26
Iteration:   3260, Loss function: 2.810, Average Loss: 4.088, avg. samples / sec: 66081.98
Iteration:   3260, Loss function: 2.779, Average Loss: 4.074, avg. samples / sec: 66166.25
Iteration:   3260, Loss function: 4.191, Average Loss: 4.063, avg. samples / sec: 66085.39
Iteration:   3260, Loss function: 2.950, Average Loss: 4.072, avg. samples / sec: 66136.38
Iteration:   3260, Loss function: 3.396, Average Loss: 4.077, avg. samples / sec: 66102.13
Iteration:   3260, Loss function: 3.913, Average Loss: 4.076, avg. samples / sec: 66041.20
Iteration:   3260, Loss function: 3.189, Average Loss: 4.094, avg. samples / sec: 66175.41
Iteration:   3260, Loss function: 3.578, Average Loss: 4.073, avg. samples / sec: 66052.03
Iteration:   3260, Loss function: 3.265, Average Loss: 4.091, avg. samples / sec: 66128.93
Iteration:   3260, Loss function: 2.915, Average Loss: 4.078, avg. samples / sec: 66257.39
Iteration:   3260, Loss function: 3.168, Average Loss: 4.083, avg. samples / sec: 66180.73
Iteration:   3260, Loss function: 2.365, Average Loss: 4.093, avg. samples / sec: 66048.60
Iteration:   3260, Loss function: 3.732, Average Loss: 4.079, avg. samples / sec: 66081.05
Iteration:   3260, Loss function: 5.591, Average Loss: 4.081, avg. samples / sec: 66245.34
Iteration:   3260, Loss function: 4.158, Average Loss: 4.059, avg. samples / sec: 65979.42
Iteration:   3260, Loss function: 3.864, Average Loss: 4.089, avg. samples / sec: 65859.11
Iteration:   3260, Loss function: 3.203, Average Loss: 4.051, avg. samples / sec: 66045.19
Iteration:   3260, Loss function: 3.398, Average Loss: 4.074, avg. samples / sec: 65993.36
Iteration:   3280, Loss function: 3.616, Average Loss: 4.068, avg. samples / sec: 66193.81
Iteration:   3280, Loss function: 2.929, Average Loss: 4.053, avg. samples / sec: 66056.52
Iteration:   3280, Loss function: 3.144, Average Loss: 4.050, avg. samples / sec: 66075.44
Iteration:   3280, Loss function: 4.966, Average Loss: 4.077, avg. samples / sec: 66078.26
Iteration:   3280, Loss function: 3.561, Average Loss: 4.059, avg. samples / sec: 66067.48
Iteration:   3280, Loss function: 4.194, Average Loss: 4.082, avg. samples / sec: 66216.64
Iteration:   3280, Loss function: 2.299, Average Loss: 4.071, avg. samples / sec: 66155.72
Iteration:   3280, Loss function: 4.699, Average Loss: 4.073, avg. samples / sec: 66224.70
Iteration:   3280, Loss function: 5.153, Average Loss: 4.071, avg. samples / sec: 66145.53
Iteration:   3280, Loss function: 3.017, Average Loss: 4.043, avg. samples / sec: 66265.09
Iteration:   3280, Loss function: 2.842, Average Loss: 4.063, avg. samples / sec: 66137.90
Iteration:   3280, Loss function: 6.318, Average Loss: 4.073, avg. samples / sec: 66095.77
Iteration:   3280, Loss function: 3.456, Average Loss: 4.085, avg. samples / sec: 65989.34
Iteration:   3280, Loss function: 3.464, Average Loss: 4.070, avg. samples / sec: 66096.02
Iteration:   3280, Loss function: 3.344, Average Loss: 4.065, avg. samples / sec: 66143.30
Iteration:   3280, Loss function: 2.689, Average Loss: 4.063, avg. samples / sec: 65988.47
Iteration:   3280, Loss function: 3.119, Average Loss: 4.074, avg. samples / sec: 65981.09
Iteration:   3280, Loss function: 3.904, Average Loss: 4.053, avg. samples / sec: 66116.55
Iteration:   3280, Loss function: 3.499, Average Loss: 4.072, avg. samples / sec: 66166.28
Iteration:   3280, Loss function: 3.282, Average Loss: 4.069, avg. samples / sec: 66251.66
Iteration:   3280, Loss function: 2.681, Average Loss: 4.056, avg. samples / sec: 66031.57
Iteration:   3280, Loss function: 2.348, Average Loss: 4.080, avg. samples / sec: 66116.95
Iteration:   3280, Loss function: 3.634, Average Loss: 4.059, avg. samples / sec: 66072.19
Iteration:   3280, Loss function: 4.043, Average Loss: 4.045, avg. samples / sec: 66194.50
Iteration:   3280, Loss function: 2.828, Average Loss: 4.077, avg. samples / sec: 66148.05
Iteration:   3280, Loss function: 3.902, Average Loss: 4.067, avg. samples / sec: 66040.86
Iteration:   3280, Loss function: 3.287, Average Loss: 4.060, avg. samples / sec: 66030.65
Iteration:   3280, Loss function: 3.044, Average Loss: 4.089, avg. samples / sec: 66049.93
Iteration:   3280, Loss function: 4.045, Average Loss: 4.068, avg. samples / sec: 66025.08
Iteration:   3280, Loss function: 3.475, Average Loss: 4.065, avg. samples / sec: 66005.04
:::MLL 1558651782.899 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558651782.900 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 5.309, Average Loss: 4.040, avg. samples / sec: 65760.61
Iteration:   3300, Loss function: 4.152, Average Loss: 4.072, avg. samples / sec: 65833.51
Iteration:   3300, Loss function: 4.306, Average Loss: 4.039, avg. samples / sec: 65743.86
Iteration:   3300, Loss function: 2.971, Average Loss: 4.060, avg. samples / sec: 65796.47
Iteration:   3300, Loss function: 2.686, Average Loss: 4.049, avg. samples / sec: 65786.74
Iteration:   3300, Loss function: 2.431, Average Loss: 4.056, avg. samples / sec: 65589.07
Iteration:   3300, Loss function: 4.342, Average Loss: 4.024, avg. samples / sec: 65699.91
Iteration:   3300, Loss function: 3.835, Average Loss: 4.074, avg. samples / sec: 65646.97
Iteration:   3300, Loss function: 4.347, Average Loss: 4.068, avg. samples / sec: 65729.12
Iteration:   3300, Loss function: 3.178, Average Loss: 4.045, avg. samples / sec: 65626.46
Iteration:   3300, Loss function: 3.717, Average Loss: 4.069, avg. samples / sec: 65767.49
Iteration:   3300, Loss function: 3.349, Average Loss: 4.042, avg. samples / sec: 65717.44
Iteration:   3300, Loss function: 4.553, Average Loss: 4.073, avg. samples / sec: 65800.90
Iteration:   3300, Loss function: 2.939, Average Loss: 4.056, avg. samples / sec: 65845.42
Iteration:   3300, Loss function: 3.483, Average Loss: 4.061, avg. samples / sec: 65690.51
Iteration:   3300, Loss function: 3.026, Average Loss: 4.062, avg. samples / sec: 65640.46
Iteration:   3300, Loss function: 2.943, Average Loss: 4.054, avg. samples / sec: 65622.70
Iteration:   3300, Loss function: 4.044, Average Loss: 4.043, avg. samples / sec: 65700.50
Iteration:   3300, Loss function: 4.020, Average Loss: 4.048, avg. samples / sec: 65742.94
Iteration:   3300, Loss function: 3.522, Average Loss: 4.072, avg. samples / sec: 65587.15
Iteration:   3300, Loss function: 4.237, Average Loss: 4.058, avg. samples / sec: 65657.64
Iteration:   3300, Loss function: 3.113, Average Loss: 4.050, avg. samples / sec: 65742.09
Iteration:   3300, Loss function: 2.543, Average Loss: 4.056, avg. samples / sec: 65573.02
Iteration:   3300, Loss function: 3.234, Average Loss: 4.076, avg. samples / sec: 65733.50
Iteration:   3300, Loss function: 3.886, Average Loss: 4.052, avg. samples / sec: 65777.28
Iteration:   3300, Loss function: 3.993, Average Loss: 4.058, avg. samples / sec: 65615.91
Iteration:   3300, Loss function: 3.229, Average Loss: 4.052, avg. samples / sec: 65584.65
Iteration:   3300, Loss function: 2.648, Average Loss: 4.054, avg. samples / sec: 65585.87
Iteration:   3300, Loss function: 2.348, Average Loss: 4.032, avg. samples / sec: 65642.23
Iteration:   3300, Loss function: 3.235, Average Loss: 4.059, avg. samples / sec: 65675.48
Iteration:   3320, Loss function: 3.322, Average Loss: 4.029, avg. samples / sec: 66096.30
Iteration:   3320, Loss function: 2.540, Average Loss: 4.031, avg. samples / sec: 66278.12
Iteration:   3320, Loss function: 3.911, Average Loss: 4.065, avg. samples / sec: 66074.27
Iteration:   3320, Loss function: 3.486, Average Loss: 4.038, avg. samples / sec: 66246.31
Iteration:   3320, Loss function: 4.815, Average Loss: 4.028, avg. samples / sec: 66019.23
Iteration:   3320, Loss function: 3.982, Average Loss: 4.059, avg. samples / sec: 66135.07
Iteration:   3320, Loss function: 2.892, Average Loss: 4.050, avg. samples / sec: 66159.13
Iteration:   3320, Loss function: 4.056, Average Loss: 4.057, avg. samples / sec: 66106.00
Iteration:   3320, Loss function: 2.596, Average Loss: 4.045, avg. samples / sec: 66037.76
Iteration:   3320, Loss function: 3.594, Average Loss: 4.012, avg. samples / sec: 66072.22
Iteration:   3320, Loss function: 2.733, Average Loss: 4.043, avg. samples / sec: 65993.39
Iteration:   3320, Loss function: 4.560, Average Loss: 4.045, avg. samples / sec: 66171.00
Iteration:   3320, Loss function: 3.738, Average Loss: 4.047, avg. samples / sec: 66010.08
Iteration:   3320, Loss function: 4.353, Average Loss: 4.030, avg. samples / sec: 66038.20
Iteration:   3320, Loss function: 3.904, Average Loss: 4.042, avg. samples / sec: 66032.63
Iteration:   3320, Loss function: 4.123, Average Loss: 4.064, avg. samples / sec: 66025.45
Iteration:   3320, Loss function: 2.936, Average Loss: 4.060, avg. samples / sec: 66056.74
Iteration:   3320, Loss function: 3.191, Average Loss: 4.041, avg. samples / sec: 66103.03
Iteration:   3320, Loss function: 3.186, Average Loss: 4.043, avg. samples / sec: 66049.83
Iteration:   3320, Loss function: 3.984, Average Loss: 4.046, avg. samples / sec: 66033.71
Iteration:   3320, Loss function: 3.205, Average Loss: 4.048, avg. samples / sec: 66135.04
Iteration:   3320, Loss function: 3.461, Average Loss: 4.064, avg. samples / sec: 66100.49
Iteration:   3320, Loss function: 4.353, Average Loss: 4.024, avg. samples / sec: 66146.09
Iteration:   3320, Loss function: 2.829, Average Loss: 4.041, avg. samples / sec: 66108.76
Iteration:   3320, Loss function: 1.850, Average Loss: 4.037, avg. samples / sec: 66032.29
Iteration:   3320, Loss function: 3.783, Average Loss: 4.045, avg. samples / sec: 66084.27
Iteration:   3320, Loss function: 3.470, Average Loss: 4.062, avg. samples / sec: 65954.07
Iteration:   3320, Loss function: 4.554, Average Loss: 4.051, avg. samples / sec: 66031.64
Iteration:   3320, Loss function: 3.054, Average Loss: 4.045, avg. samples / sec: 66081.89
Iteration:   3320, Loss function: 2.748, Average Loss: 4.033, avg. samples / sec: 65980.60
Iteration:   3340, Loss function: 3.637, Average Loss: 4.015, avg. samples / sec: 66176.81
Iteration:   3340, Loss function: 3.427, Average Loss: 4.048, avg. samples / sec: 66428.01
Iteration:   3340, Loss function: 3.382, Average Loss: 4.019, avg. samples / sec: 66137.34
Iteration:   3340, Loss function: 3.440, Average Loss: 4.038, avg. samples / sec: 66250.48
Iteration:   3340, Loss function: 3.003, Average Loss: 4.043, avg. samples / sec: 66303.72
Iteration:   3340, Loss function: 1.957, Average Loss: 4.035, avg. samples / sec: 66266.74
Iteration:   3340, Loss function: 4.215, Average Loss: 4.031, avg. samples / sec: 66336.08
Iteration:   3340, Loss function: 4.308, Average Loss: 4.056, avg. samples / sec: 66353.32
Iteration:   3340, Loss function: 3.958, Average Loss: 4.032, avg. samples / sec: 66318.69
Iteration:   3340, Loss function: 3.114, Average Loss: 4.014, avg. samples / sec: 66184.95
Iteration:   3340, Loss function: 3.212, Average Loss: 4.000, avg. samples / sec: 66219.10
Iteration:   3340, Loss function: 3.173, Average Loss: 4.027, avg. samples / sec: 66326.96
Iteration:   3340, Loss function: 3.762, Average Loss: 4.038, avg. samples / sec: 66358.07
Iteration:   3340, Loss function: 3.430, Average Loss: 4.032, avg. samples / sec: 66299.91
Iteration:   3340, Loss function: 3.463, Average Loss: 4.030, avg. samples / sec: 66282.45
Iteration:   3340, Loss function: 4.316, Average Loss: 4.028, avg. samples / sec: 66132.62
Iteration:   3340, Loss function: 3.369, Average Loss: 4.041, avg. samples / sec: 66281.86
Iteration:   3340, Loss function: 2.985, Average Loss: 4.031, avg. samples / sec: 66293.24
Iteration:   3340, Loss function: 3.633, Average Loss: 4.050, avg. samples / sec: 66328.77
Iteration:   3340, Loss function: 3.398, Average Loss: 4.051, avg. samples / sec: 66236.00
Iteration:   3340, Loss function: 3.437, Average Loss: 4.049, avg. samples / sec: 66113.73
Iteration:   3340, Loss function: 3.211, Average Loss: 4.032, avg. samples / sec: 66153.54
Iteration:   3340, Loss function: 3.147, Average Loss: 4.043, avg. samples / sec: 66148.39
Iteration:   3340, Loss function: 2.838, Average Loss: 4.056, avg. samples / sec: 66026.38
Iteration:   3340, Loss function: 4.371, Average Loss: 4.017, avg. samples / sec: 66206.07
Iteration:   3340, Loss function: 3.344, Average Loss: 4.022, avg. samples / sec: 66283.57
Iteration:   3340, Loss function: 3.830, Average Loss: 4.030, avg. samples / sec: 66137.37
Iteration:   3340, Loss function: 3.164, Average Loss: 4.034, avg. samples / sec: 66204.45
Iteration:   3340, Loss function: 4.630, Average Loss: 4.014, avg. samples / sec: 66189.06
Iteration:   3340, Loss function: 3.819, Average Loss: 4.036, avg. samples / sec: 66231.42
:::MLL 1558651784.683 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558651784.684 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 4.268, Average Loss: 4.001, avg. samples / sec: 65630.61
Iteration:   3360, Loss function: 2.061, Average Loss: 4.032, avg. samples / sec: 65534.02
Iteration:   3360, Loss function: 3.743, Average Loss: 4.023, avg. samples / sec: 65529.08
Iteration:   3360, Loss function: 3.479, Average Loss: 4.004, avg. samples / sec: 65425.16
Iteration:   3360, Loss function: 3.628, Average Loss: 4.016, avg. samples / sec: 65538.90
Iteration:   3360, Loss function: 3.305, Average Loss: 4.013, avg. samples / sec: 65518.63
Iteration:   3360, Loss function: 2.989, Average Loss: 4.005, avg. samples / sec: 65407.82
Iteration:   3360, Loss function: 2.585, Average Loss: 4.016, avg. samples / sec: 65532.65
Iteration:   3360, Loss function: 3.436, Average Loss: 4.037, avg. samples / sec: 65356.96
Iteration:   3360, Loss function: 5.170, Average Loss: 4.022, avg. samples / sec: 65489.95
Iteration:   3360, Loss function: 3.508, Average Loss: 4.014, avg. samples / sec: 65425.31
Iteration:   3360, Loss function: 2.742, Average Loss: 4.029, avg. samples / sec: 65465.07
Iteration:   3360, Loss function: 3.347, Average Loss: 4.022, avg. samples / sec: 65480.37
Iteration:   3360, Loss function: 2.761, Average Loss: 4.006, avg. samples / sec: 65534.23
Iteration:   3360, Loss function: 3.913, Average Loss: 4.049, avg. samples / sec: 65520.73
Iteration:   3360, Loss function: 2.799, Average Loss: 4.009, avg. samples / sec: 65539.23
Iteration:   3360, Loss function: 2.946, Average Loss: 4.029, avg. samples / sec: 65374.72
Iteration:   3360, Loss function: 3.139, Average Loss: 3.992, avg. samples / sec: 65441.33
Iteration:   3360, Loss function: 3.482, Average Loss: 4.018, avg. samples / sec: 65425.74
Iteration:   3360, Loss function: 3.181, Average Loss: 4.032, avg. samples / sec: 65447.71
Iteration:   3360, Loss function: 4.013, Average Loss: 4.036, avg. samples / sec: 65485.24
Iteration:   3360, Loss function: 3.116, Average Loss: 4.045, avg. samples / sec: 65382.33
Iteration:   3360, Loss function: 4.271, Average Loss: 4.021, avg. samples / sec: 65489.62
Iteration:   3360, Loss function: 3.396, Average Loss: 4.033, avg. samples / sec: 65458.80
Iteration:   3360, Loss function: 3.252, Average Loss: 4.036, avg. samples / sec: 65420.73
Iteration:   3360, Loss function: 2.461, Average Loss: 4.024, avg. samples / sec: 65472.64
Iteration:   3360, Loss function: 3.423, Average Loss: 4.022, avg. samples / sec: 65376.33
Iteration:   3360, Loss function: 3.826, Average Loss: 4.003, avg. samples / sec: 65417.84
Iteration:   3360, Loss function: 3.663, Average Loss: 4.038, avg. samples / sec: 65314.70
Iteration:   3360, Loss function: 3.425, Average Loss: 4.025, avg. samples / sec: 65290.73
Iteration:   3380, Loss function: 3.196, Average Loss: 3.995, avg. samples / sec: 65849.14
Iteration:   3380, Loss function: 3.607, Average Loss: 3.993, avg. samples / sec: 65723.78
Iteration:   3380, Loss function: 2.445, Average Loss: 3.992, avg. samples / sec: 65861.97
Iteration:   3380, Loss function: 4.308, Average Loss: 4.009, avg. samples / sec: 65743.07
Iteration:   3380, Loss function: 3.798, Average Loss: 4.006, avg. samples / sec: 65829.51
Iteration:   3380, Loss function: 3.402, Average Loss: 3.996, avg. samples / sec: 65847.57
Iteration:   3380, Loss function: 3.596, Average Loss: 4.018, avg. samples / sec: 65672.76
Iteration:   3380, Loss function: 3.720, Average Loss: 4.019, avg. samples / sec: 66114.07
Iteration:   3380, Loss function: 3.944, Average Loss: 4.024, avg. samples / sec: 65782.01
Iteration:   3380, Loss function: 3.463, Average Loss: 4.010, avg. samples / sec: 65867.20
Iteration:   3380, Loss function: 2.841, Average Loss: 4.039, avg. samples / sec: 65810.49
Iteration:   3380, Loss function: 2.068, Average Loss: 4.017, avg. samples / sec: 65848.00
Iteration:   3380, Loss function: 3.314, Average Loss: 4.025, avg. samples / sec: 65835.45
Iteration:   3380, Loss function: 3.129, Average Loss: 4.024, avg. samples / sec: 65863.57
Iteration:   3380, Loss function: 4.018, Average Loss: 4.034, avg. samples / sec: 65808.86
Iteration:   3380, Loss function: 3.742, Average Loss: 4.023, avg. samples / sec: 65808.70
Iteration:   3380, Loss function: 5.219, Average Loss: 3.997, avg. samples / sec: 65929.73
Iteration:   3380, Loss function: 3.554, Average Loss: 4.002, avg. samples / sec: 65675.97
Iteration:   3380, Loss function: 2.355, Average Loss: 4.013, avg. samples / sec: 65722.13
Iteration:   3380, Loss function: 3.141, Average Loss: 4.013, avg. samples / sec: 65759.26
Iteration:   3380, Loss function: 3.522, Average Loss: 4.001, avg. samples / sec: 65686.87
Iteration:   3380, Loss function: 3.444, Average Loss: 4.024, avg. samples / sec: 65921.21
Iteration:   3380, Loss function: 3.447, Average Loss: 3.980, avg. samples / sec: 65737.88
Iteration:   3380, Loss function: 3.752, Average Loss: 4.014, avg. samples / sec: 65819.15
Iteration:   3380, Loss function: 3.153, Average Loss: 4.023, avg. samples / sec: 65704.81
Iteration:   3380, Loss function: 2.508, Average Loss: 4.003, avg. samples / sec: 65671.66
Iteration:   3380, Loss function: 3.353, Average Loss: 4.014, avg. samples / sec: 65770.80
Iteration:   3380, Loss function: 4.139, Average Loss: 4.014, avg. samples / sec: 65649.57
Iteration:   3380, Loss function: 2.316, Average Loss: 4.011, avg. samples / sec: 65675.42
Iteration:   3380, Loss function: 3.488, Average Loss: 3.994, avg. samples / sec: 65639.81
Iteration:   3400, Loss function: 4.034, Average Loss: 4.014, avg. samples / sec: 66154.66
Iteration:   3400, Loss function: 3.800, Average Loss: 4.028, avg. samples / sec: 66158.36
Iteration:   3400, Loss function: 4.286, Average Loss: 3.967, avg. samples / sec: 66182.84
Iteration:   3400, Loss function: 3.358, Average Loss: 4.010, avg. samples / sec: 66112.98
Iteration:   3400, Loss function: 5.216, Average Loss: 3.988, avg. samples / sec: 65948.86
Iteration:   3400, Loss function: 4.341, Average Loss: 3.996, avg. samples / sec: 65989.12
Iteration:   3400, Loss function: 3.779, Average Loss: 4.007, avg. samples / sec: 66151.28
Iteration:   3400, Loss function: 4.229, Average Loss: 4.010, avg. samples / sec: 66034.64
Iteration:   3400, Loss function: 2.839, Average Loss: 3.996, avg. samples / sec: 66186.26
Iteration:   3400, Loss function: 3.808, Average Loss: 3.984, avg. samples / sec: 65923.13
Iteration:   3400, Loss function: 4.455, Average Loss: 3.988, avg. samples / sec: 66092.61
Iteration:   3400, Loss function: 4.358, Average Loss: 4.029, avg. samples / sec: 66047.14
Iteration:   3400, Loss function: 3.650, Average Loss: 4.001, avg. samples / sec: 66076.93
Iteration:   3400, Loss function: 4.038, Average Loss: 4.014, avg. samples / sec: 66095.06
Iteration:   3400, Loss function: 3.535, Average Loss: 4.010, avg. samples / sec: 65974.39
Iteration:   3400, Loss function: 3.654, Average Loss: 4.009, avg. samples / sec: 65993.42
Iteration:   3400, Loss function: 3.741, Average Loss: 3.989, avg. samples / sec: 66025.98
Iteration:   3400, Loss function: 3.889, Average Loss: 4.013, avg. samples / sec: 66006.68
Iteration:   3400, Loss function: 2.526, Average Loss: 3.982, avg. samples / sec: 66143.76
Iteration:   3400, Loss function: 3.728, Average Loss: 3.979, avg. samples / sec: 65870.44
Iteration:   3400, Loss function: 1.986, Average Loss: 3.992, avg. samples / sec: 65926.06
Iteration:   3400, Loss function: 4.631, Average Loss: 3.992, avg. samples / sec: 66012.61
Iteration:   3400, Loss function: 3.020, Average Loss: 4.000, avg. samples / sec: 66029.32
Iteration:   3400, Loss function: 4.207, Average Loss: 3.987, avg. samples / sec: 65902.87
Iteration:   3400, Loss function: 4.274, Average Loss: 3.998, avg. samples / sec: 66057.14
Iteration:   3400, Loss function: 3.315, Average Loss: 4.007, avg. samples / sec: 65948.08
Iteration:   3400, Loss function: 2.325, Average Loss: 4.003, avg. samples / sec: 65901.83
Iteration:   3400, Loss function: 4.387, Average Loss: 4.009, avg. samples / sec: 66037.70
Iteration:   3400, Loss function: 2.836, Average Loss: 4.009, avg. samples / sec: 65949.87
Iteration:   3400, Loss function: 2.596, Average Loss: 3.990, avg. samples / sec: 65943.86
Iteration:   3420, Loss function: 4.339, Average Loss: 3.974, avg. samples / sec: 66053.73
Iteration:   3420, Loss function: 2.070, Average Loss: 3.970, avg. samples / sec: 66104.55
Iteration:   3420, Loss function: 3.190, Average Loss: 3.982, avg. samples / sec: 66036.31
Iteration:   3420, Loss function: 3.162, Average Loss: 3.997, avg. samples / sec: 66068.69
Iteration:   3420, Loss function: 3.933, Average Loss: 3.962, avg. samples / sec: 65927.81
Iteration:   3420, Loss function: 3.818, Average Loss: 3.996, avg. samples / sec: 66029.22
Iteration:   3420, Loss function: 3.032, Average Loss: 3.983, avg. samples / sec: 66180.73
Iteration:   3420, Loss function: 3.481, Average Loss: 3.976, avg. samples / sec: 65938.55
Iteration:   3420, Loss function: 2.388, Average Loss: 3.979, avg. samples / sec: 66032.60
Iteration:   3420, Loss function: 2.369, Average Loss: 4.000, avg. samples / sec: 66014.47
Iteration:   3420, Loss function: 3.136, Average Loss: 4.000, avg. samples / sec: 65907.80
Iteration:   3420, Loss function: 4.489, Average Loss: 3.984, avg. samples / sec: 65923.34
Iteration:   3420, Loss function: 3.053, Average Loss: 3.996, avg. samples / sec: 66090.26
Iteration:   3420, Loss function: 3.093, Average Loss: 4.003, avg. samples / sec: 65817.19
Iteration:   3420, Loss function: 3.238, Average Loss: 3.990, avg. samples / sec: 66042.75
Iteration:   3420, Loss function: 1.986, Average Loss: 3.976, avg. samples / sec: 65935.99
Iteration:   3420, Loss function: 2.565, Average Loss: 3.986, avg. samples / sec: 65985.54
Iteration:   3420, Loss function: 2.821, Average Loss: 4.000, avg. samples / sec: 66053.92
Iteration:   3420, Loss function: 4.203, Average Loss: 3.990, avg. samples / sec: 65943.18
Iteration:   3420, Loss function: 3.815, Average Loss: 3.989, avg. samples / sec: 65868.71
Iteration:   3420, Loss function: 3.389, Average Loss: 3.976, avg. samples / sec: 65946.36
Iteration:   3420, Loss function: 2.852, Average Loss: 3.985, avg. samples / sec: 65835.45
Iteration:   3420, Loss function: 3.763, Average Loss: 3.997, avg. samples / sec: 65921.28
Iteration:   3420, Loss function: 2.653, Average Loss: 3.999, avg. samples / sec: 65802.25
Iteration:   3420, Loss function: 2.950, Average Loss: 3.973, avg. samples / sec: 65875.21
Iteration:   3420, Loss function: 4.436, Average Loss: 4.005, avg. samples / sec: 65828.32
Iteration:   3420, Loss function: 3.452, Average Loss: 4.018, avg. samples / sec: 65788.15
Iteration:   3420, Loss function: 3.066, Average Loss: 3.996, avg. samples / sec: 65773.60
Iteration:   3420, Loss function: 2.366, Average Loss: 4.011, avg. samples / sec: 65621.44
Iteration:   3420, Loss function: 3.147, Average Loss: 3.980, avg. samples / sec: 65792.60
:::MLL 1558651786.450 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.55s)
DONE (t=2.47s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22116
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.37902
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22897
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05393
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23301
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32971
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.35612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52017
Current AP: 0.22116 AP goal: 0.23000
:::MLL 1558651790.066 eval_accuracy: {"value": 0.22116046002606163, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558651790.088 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558651790.094 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558651790.095 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558651790.120 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558651790.120 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.135, Average Loss: 3.960, avg. samples / sec: 8071.83
Iteration:   3440, Loss function: 3.660, Average Loss: 3.950, avg. samples / sec: 8072.38
Iteration:   3440, Loss function: 3.551, Average Loss: 3.962, avg. samples / sec: 8074.77
Iteration:   3440, Loss function: 3.735, Average Loss: 3.994, avg. samples / sec: 8072.08
Iteration:   3440, Loss function: 3.400, Average Loss: 3.963, avg. samples / sec: 8071.51
Iteration:   3440, Loss function: 3.905, Average Loss: 3.972, avg. samples / sec: 8070.15
Iteration:   3440, Loss function: 3.713, Average Loss: 3.976, avg. samples / sec: 8071.06
Iteration:   3440, Loss function: 3.480, Average Loss: 3.998, avg. samples / sec: 8070.96
Iteration:   3440, Loss function: 3.674, Average Loss: 3.969, avg. samples / sec: 8070.22
Iteration:   3440, Loss function: 2.341, Average Loss: 3.986, avg. samples / sec: 8072.95
Iteration:   3440, Loss function: 2.575, Average Loss: 3.981, avg. samples / sec: 8069.38
Iteration:   3440, Loss function: 4.521, Average Loss: 3.961, avg. samples / sec: 8069.16
Iteration:   3440, Loss function: 3.683, Average Loss: 3.981, avg. samples / sec: 8071.81
Iteration:   3440, Loss function: 3.513, Average Loss: 3.983, avg. samples / sec: 8073.05
Iteration:   3440, Loss function: 3.504, Average Loss: 4.002, avg. samples / sec: 8073.13
Iteration:   3440, Loss function: 4.571, Average Loss: 3.978, avg. samples / sec: 8070.64
Iteration:   3440, Loss function: 4.663, Average Loss: 3.982, avg. samples / sec: 8069.86
Iteration:   3440, Loss function: 3.686, Average Loss: 3.990, avg. samples / sec: 8070.18
Iteration:   3440, Loss function: 2.792, Average Loss: 3.988, avg. samples / sec: 8072.09
Iteration:   3440, Loss function: 2.667, Average Loss: 3.988, avg. samples / sec: 8069.84
Iteration:   3440, Loss function: 2.965, Average Loss: 3.971, avg. samples / sec: 8069.42
Iteration:   3440, Loss function: 3.814, Average Loss: 3.999, avg. samples / sec: 8072.96
Iteration:   3440, Loss function: 3.072, Average Loss: 3.973, avg. samples / sec: 8072.98
Iteration:   3440, Loss function: 2.837, Average Loss: 3.964, avg. samples / sec: 8070.06
Iteration:   3440, Loss function: 3.627, Average Loss: 3.986, avg. samples / sec: 8070.35
Iteration:   3440, Loss function: 2.946, Average Loss: 3.970, avg. samples / sec: 8070.82
Iteration:   3440, Loss function: 2.057, Average Loss: 3.982, avg. samples / sec: 8070.88
Iteration:   3440, Loss function: 5.510, Average Loss: 3.976, avg. samples / sec: 8069.40
Iteration:   3440, Loss function: 3.183, Average Loss: 3.980, avg. samples / sec: 8069.23
Iteration:   3440, Loss function: 3.298, Average Loss: 3.965, avg. samples / sec: 8069.05
Iteration:   3460, Loss function: 3.504, Average Loss: 3.965, avg. samples / sec: 66192.10
Iteration:   3460, Loss function: 2.824, Average Loss: 3.957, avg. samples / sec: 66295.95
Iteration:   3460, Loss function: 3.750, Average Loss: 3.969, avg. samples / sec: 66346.48
Iteration:   3460, Loss function: 2.785, Average Loss: 3.947, avg. samples / sec: 65971.92
Iteration:   3460, Loss function: 2.284, Average Loss: 3.977, avg. samples / sec: 66256.43
Iteration:   3460, Loss function: 2.823, Average Loss: 3.957, avg. samples / sec: 66093.67
Iteration:   3460, Loss function: 3.546, Average Loss: 3.975, avg. samples / sec: 66325.68
Iteration:   3460, Loss function: 2.991, Average Loss: 3.964, avg. samples / sec: 66105.57
Iteration:   3460, Loss function: 4.066, Average Loss: 3.970, avg. samples / sec: 66103.34
Iteration:   3460, Loss function: 2.887, Average Loss: 3.952, avg. samples / sec: 65970.93
Iteration:   3460, Loss function: 4.038, Average Loss: 3.972, avg. samples / sec: 66131.97
Iteration:   3460, Loss function: 3.801, Average Loss: 3.955, avg. samples / sec: 66180.11
Iteration:   3460, Loss function: 2.161, Average Loss: 3.976, avg. samples / sec: 66132.12
Iteration:   3460, Loss function: 3.686, Average Loss: 3.984, avg. samples / sec: 66114.87
Iteration:   3460, Loss function: 3.034, Average Loss: 3.992, avg. samples / sec: 66094.94
Iteration:   3460, Loss function: 3.012, Average Loss: 3.953, avg. samples / sec: 66268.27
Iteration:   3460, Loss function: 3.734, Average Loss: 3.978, avg. samples / sec: 66070.55
Iteration:   3460, Loss function: 3.761, Average Loss: 3.950, avg. samples / sec: 66061.04
Iteration:   3460, Loss function: 4.386, Average Loss: 3.969, avg. samples / sec: 66042.47
Iteration:   3460, Loss function: 3.853, Average Loss: 3.988, avg. samples / sec: 66073.06
Iteration:   3460, Loss function: 3.018, Average Loss: 3.984, avg. samples / sec: 65985.35
Iteration:   3460, Loss function: 3.556, Average Loss: 3.973, avg. samples / sec: 66030.15
Iteration:   3460, Loss function: 3.750, Average Loss: 3.955, avg. samples / sec: 65939.51
Iteration:   3460, Loss function: 4.098, Average Loss: 3.941, avg. samples / sec: 65828.50
Iteration:   3460, Loss function: 4.244, Average Loss: 3.958, avg. samples / sec: 66056.46
Iteration:   3460, Loss function: 3.806, Average Loss: 3.977, avg. samples / sec: 66010.36
Iteration:   3460, Loss function: 3.873, Average Loss: 3.974, avg. samples / sec: 66075.72
Iteration:   3460, Loss function: 4.252, Average Loss: 3.986, avg. samples / sec: 65861.33
Iteration:   3460, Loss function: 3.141, Average Loss: 3.979, avg. samples / sec: 65912.03
Iteration:   3460, Loss function: 3.811, Average Loss: 3.948, avg. samples / sec: 66032.22
Iteration:   3480, Loss function: 4.189, Average Loss: 3.935, avg. samples / sec: 66195.93
Iteration:   3480, Loss function: 3.051, Average Loss: 3.978, avg. samples / sec: 66406.50
Iteration:   3480, Loss function: 3.055, Average Loss: 3.965, avg. samples / sec: 66378.98
Iteration:   3480, Loss function: 3.068, Average Loss: 3.948, avg. samples / sec: 66186.57
Iteration:   3480, Loss function: 3.384, Average Loss: 3.956, avg. samples / sec: 66286.00
Iteration:   3480, Loss function: 3.349, Average Loss: 3.940, avg. samples / sec: 66240.79
Iteration:   3480, Loss function: 2.939, Average Loss: 3.943, avg. samples / sec: 66090.66
Iteration:   3480, Loss function: 3.273, Average Loss: 3.956, avg. samples / sec: 66105.73
Iteration:   3480, Loss function: 3.421, Average Loss: 3.950, avg. samples / sec: 66047.08
Iteration:   3480, Loss function: 3.294, Average Loss: 3.963, avg. samples / sec: 66167.74
Iteration:   3480, Loss function: 3.797, Average Loss: 3.974, avg. samples / sec: 66257.36
Iteration:   3480, Loss function: 3.343, Average Loss: 3.945, avg. samples / sec: 66254.00
Iteration:   3480, Loss function: 2.665, Average Loss: 3.951, avg. samples / sec: 66107.03
Iteration:   3480, Loss function: 4.402, Average Loss: 3.941, avg. samples / sec: 66140.16
Iteration:   3480, Loss function: 3.032, Average Loss: 3.982, avg. samples / sec: 66170.88
Iteration:   3480, Loss function: 3.574, Average Loss: 3.978, avg. samples / sec: 66157.74
Iteration:   3480, Loss function: 3.445, Average Loss: 3.962, avg. samples / sec: 66093.20
Iteration:   3480, Loss function: 2.271, Average Loss: 3.970, avg. samples / sec: 66194.68
Iteration:   3480, Loss function: 3.535, Average Loss: 3.959, avg. samples / sec: 66107.74
Iteration:   3480, Loss function: 4.684, Average Loss: 3.946, avg. samples / sec: 66155.16
Iteration:   3480, Loss function: 3.675, Average Loss: 3.968, avg. samples / sec: 66274.13
Iteration:   3480, Loss function: 2.714, Average Loss: 3.949, avg. samples / sec: 66221.40
Iteration:   3480, Loss function: 4.981, Average Loss: 3.952, avg. samples / sec: 66066.15
Iteration:   3480, Loss function: 2.906, Average Loss: 3.929, avg. samples / sec: 66188.12
Iteration:   3480, Loss function: 3.661, Average Loss: 3.955, avg. samples / sec: 66151.06
Iteration:   3480, Loss function: 3.382, Average Loss: 3.977, avg. samples / sec: 66143.89
Iteration:   3480, Loss function: 4.237, Average Loss: 3.939, avg. samples / sec: 66206.63
Iteration:   3480, Loss function: 3.891, Average Loss: 3.971, avg. samples / sec: 66174.57
Iteration:   3480, Loss function: 4.118, Average Loss: 3.964, avg. samples / sec: 66010.67
Iteration:   3480, Loss function: 5.033, Average Loss: 3.966, avg. samples / sec: 65900.81
:::MLL 1558651791.901 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558651791.902 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 2.910, Average Loss: 3.961, avg. samples / sec: 66050.08
Iteration:   3500, Loss function: 3.708, Average Loss: 3.947, avg. samples / sec: 66076.50
Iteration:   3500, Loss function: 3.181, Average Loss: 3.939, avg. samples / sec: 66018.52
Iteration:   3500, Loss function: 5.442, Average Loss: 3.926, avg. samples / sec: 65917.95
Iteration:   3500, Loss function: 4.437, Average Loss: 3.935, avg. samples / sec: 65997.19
Iteration:   3500, Loss function: 3.723, Average Loss: 3.935, avg. samples / sec: 65942.90
Iteration:   3500, Loss function: 4.095, Average Loss: 3.937, avg. samples / sec: 65988.23
Iteration:   3500, Loss function: 3.454, Average Loss: 3.955, avg. samples / sec: 65937.81
Iteration:   3500, Loss function: 3.739, Average Loss: 3.940, avg. samples / sec: 65953.24
Iteration:   3500, Loss function: 3.009, Average Loss: 3.969, avg. samples / sec: 65855.26
Iteration:   3500, Loss function: 4.255, Average Loss: 3.964, avg. samples / sec: 66047.30
Iteration:   3500, Loss function: 2.139, Average Loss: 3.923, avg. samples / sec: 65984.86
Iteration:   3500, Loss function: 4.568, Average Loss: 3.945, avg. samples / sec: 65881.68
Iteration:   3500, Loss function: 2.974, Average Loss: 3.945, avg. samples / sec: 65870.50
Iteration:   3500, Loss function: 4.732, Average Loss: 3.976, avg. samples / sec: 65902.47
Iteration:   3500, Loss function: 3.549, Average Loss: 3.943, avg. samples / sec: 65960.83
Iteration:   3500, Loss function: 4.271, Average Loss: 3.955, avg. samples / sec: 66032.66
Iteration:   3500, Loss function: 3.514, Average Loss: 3.928, avg. samples / sec: 65900.25
Iteration:   3500, Loss function: 2.780, Average Loss: 3.955, avg. samples / sec: 65889.01
Iteration:   3500, Loss function: 3.441, Average Loss: 3.957, avg. samples / sec: 65807.87
Iteration:   3500, Loss function: 3.284, Average Loss: 3.927, avg. samples / sec: 66001.02
Iteration:   3500, Loss function: 4.712, Average Loss: 3.929, avg. samples / sec: 65849.38
Iteration:   3500, Loss function: 3.297, Average Loss: 3.968, avg. samples / sec: 65890.21
Iteration:   3500, Loss function: 3.204, Average Loss: 3.934, avg. samples / sec: 65907.65
Iteration:   3500, Loss function: 3.006, Average Loss: 3.963, avg. samples / sec: 65857.08
Iteration:   3500, Loss function: 3.866, Average Loss: 3.936, avg. samples / sec: 65875.36
Iteration:   3500, Loss function: 4.434, Average Loss: 3.947, avg. samples / sec: 65932.53
Iteration:   3500, Loss function: 3.372, Average Loss: 3.953, avg. samples / sec: 66023.01
Iteration:   3500, Loss function: 3.019, Average Loss: 3.960, avg. samples / sec: 65873.52
Iteration:   3500, Loss function: 4.723, Average Loss: 3.970, avg. samples / sec: 65934.17
Iteration:   3520, Loss function: 2.678, Average Loss: 3.940, avg. samples / sec: 64990.54
Iteration:   3520, Loss function: 3.021, Average Loss: 3.928, avg. samples / sec: 65028.72
Iteration:   3520, Loss function: 2.552, Average Loss: 3.920, avg. samples / sec: 64961.78
Iteration:   3520, Loss function: 2.527, Average Loss: 3.919, avg. samples / sec: 65080.37
Iteration:   3520, Loss function: 2.928, Average Loss: 3.927, avg. samples / sec: 64982.84
Iteration:   3520, Loss function: 3.329, Average Loss: 3.928, avg. samples / sec: 64903.03
Iteration:   3520, Loss function: 3.677, Average Loss: 3.948, avg. samples / sec: 64873.12
Iteration:   3520, Loss function: 2.365, Average Loss: 3.933, avg. samples / sec: 64986.80
Iteration:   3520, Loss function: 3.916, Average Loss: 3.955, avg. samples / sec: 65051.23
Iteration:   3520, Loss function: 3.583, Average Loss: 3.950, avg. samples / sec: 65072.83
Iteration:   3520, Loss function: 2.185, Average Loss: 3.951, avg. samples / sec: 64991.44
Iteration:   3520, Loss function: 3.169, Average Loss: 3.960, avg. samples / sec: 65073.88
Iteration:   3520, Loss function: 2.724, Average Loss: 3.947, avg. samples / sec: 65089.03
Iteration:   3520, Loss function: 3.985, Average Loss: 3.933, avg. samples / sec: 65005.98
Iteration:   3520, Loss function: 2.904, Average Loss: 3.942, avg. samples / sec: 64924.85
Iteration:   3520, Loss function: 4.193, Average Loss: 3.943, avg. samples / sec: 64999.21
Iteration:   3520, Loss function: 4.015, Average Loss: 3.952, avg. samples / sec: 65005.32
Iteration:   3520, Loss function: 3.303, Average Loss: 3.918, avg. samples / sec: 64999.15
Iteration:   3520, Loss function: 4.076, Average Loss: 3.927, avg. samples / sec: 64830.44
Iteration:   3520, Loss function: 3.481, Average Loss: 3.943, avg. samples / sec: 65017.71
Iteration:   3520, Loss function: 2.587, Average Loss: 3.956, avg. samples / sec: 64888.77
Iteration:   3520, Loss function: 3.202, Average Loss: 3.917, avg. samples / sec: 64950.62
Iteration:   3520, Loss function: 3.744, Average Loss: 3.937, avg. samples / sec: 64980.36
Iteration:   3520, Loss function: 3.304, Average Loss: 3.915, avg. samples / sec: 64899.38
Iteration:   3520, Loss function: 4.321, Average Loss: 3.927, avg. samples / sec: 64967.80
Iteration:   3520, Loss function: 2.719, Average Loss: 3.965, avg. samples / sec: 64909.24
Iteration:   3520, Loss function: 3.551, Average Loss: 3.935, avg. samples / sec: 64896.90
Iteration:   3520, Loss function: 2.720, Average Loss: 3.922, avg. samples / sec: 64931.88
Iteration:   3520, Loss function: 3.531, Average Loss: 3.938, avg. samples / sec: 64881.24
Iteration:   3520, Loss function: 3.420, Average Loss: 3.947, avg. samples / sec: 64851.86
Iteration:   3540, Loss function: 3.426, Average Loss: 3.911, avg. samples / sec: 66032.41
Iteration:   3540, Loss function: 3.347, Average Loss: 3.933, avg. samples / sec: 65949.56
Iteration:   3540, Loss function: 2.883, Average Loss: 3.912, avg. samples / sec: 65943.89
Iteration:   3540, Loss function: 3.079, Average Loss: 3.913, avg. samples / sec: 66125.33
Iteration:   3540, Loss function: 3.610, Average Loss: 3.908, avg. samples / sec: 65984.09
Iteration:   3540, Loss function: 3.030, Average Loss: 3.957, avg. samples / sec: 66151.43
Iteration:   3540, Loss function: 3.927, Average Loss: 3.907, avg. samples / sec: 66059.83
Iteration:   3540, Loss function: 4.035, Average Loss: 3.919, avg. samples / sec: 66003.18
Iteration:   3540, Loss function: 2.477, Average Loss: 3.904, avg. samples / sec: 66133.12
Iteration:   3540, Loss function: 3.425, Average Loss: 3.918, avg. samples / sec: 66129.18
Iteration:   3540, Loss function: 3.130, Average Loss: 3.922, avg. samples / sec: 66039.22
Iteration:   3540, Loss function: 2.540, Average Loss: 3.927, avg. samples / sec: 66141.90
Iteration:   3540, Loss function: 3.085, Average Loss: 3.925, avg. samples / sec: 66099.40
Iteration:   3540, Loss function: 4.494, Average Loss: 3.931, avg. samples / sec: 66024.12
Iteration:   3540, Loss function: 3.095, Average Loss: 3.924, avg. samples / sec: 66089.08
Iteration:   3540, Loss function: 3.293, Average Loss: 3.936, avg. samples / sec: 65926.77
Iteration:   3540, Loss function: 2.753, Average Loss: 3.947, avg. samples / sec: 65931.21
Iteration:   3540, Loss function: 3.798, Average Loss: 3.921, avg. samples / sec: 65917.92
Iteration:   3540, Loss function: 2.989, Average Loss: 3.944, avg. samples / sec: 66040.15
Iteration:   3540, Loss function: 2.580, Average Loss: 3.940, avg. samples / sec: 65981.43
Iteration:   3540, Loss function: 4.206, Average Loss: 3.951, avg. samples / sec: 65935.25
Iteration:   3540, Loss function: 2.705, Average Loss: 3.934, avg. samples / sec: 65954.07
Iteration:   3540, Loss function: 4.238, Average Loss: 3.934, avg. samples / sec: 66000.19
Iteration:   3540, Loss function: 3.684, Average Loss: 3.939, avg. samples / sec: 65894.06
Iteration:   3540, Loss function: 2.484, Average Loss: 3.938, avg. samples / sec: 65915.73
Iteration:   3540, Loss function: 3.109, Average Loss: 3.911, avg. samples / sec: 66009.89
Iteration:   3540, Loss function: 3.144, Average Loss: 3.942, avg. samples / sec: 66040.76
Iteration:   3540, Loss function: 3.396, Average Loss: 3.918, avg. samples / sec: 65788.98
Iteration:   3540, Loss function: 2.459, Average Loss: 3.936, avg. samples / sec: 65805.45
Iteration:   3540, Loss function: 3.024, Average Loss: 3.910, avg. samples / sec: 65889.13
:::MLL 1558651793.442 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558651793.442 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 1.928, Average Loss: 3.920, avg. samples / sec: 65619.18
Iteration:   3560, Loss function: 3.455, Average Loss: 3.899, avg. samples / sec: 65478.02
Iteration:   3560, Loss function: 4.359, Average Loss: 3.906, avg. samples / sec: 65431.72
Iteration:   3560, Loss function: 3.902, Average Loss: 3.901, avg. samples / sec: 65340.62
Iteration:   3560, Loss function: 3.268, Average Loss: 3.923, avg. samples / sec: 65357.53
Iteration:   3560, Loss function: 2.182, Average Loss: 3.908, avg. samples / sec: 65474.40
Iteration:   3560, Loss function: 2.671, Average Loss: 3.920, avg. samples / sec: 65501.52
Iteration:   3560, Loss function: 3.519, Average Loss: 3.905, avg. samples / sec: 65582.23
Iteration:   3560, Loss function: 3.576, Average Loss: 3.904, avg. samples / sec: 65600.43
Iteration:   3560, Loss function: 2.801, Average Loss: 3.926, avg. samples / sec: 65443.18
Iteration:   3560, Loss function: 3.934, Average Loss: 3.916, avg. samples / sec: 65381.94
Iteration:   3560, Loss function: 2.519, Average Loss: 3.892, avg. samples / sec: 65364.78
Iteration:   3560, Loss function: 1.956, Average Loss: 3.919, avg. samples / sec: 65370.05
Iteration:   3560, Loss function: 2.742, Average Loss: 3.938, avg. samples / sec: 65458.41
Iteration:   3560, Loss function: 3.684, Average Loss: 3.909, avg. samples / sec: 65357.62
Iteration:   3560, Loss function: 4.368, Average Loss: 3.906, avg. samples / sec: 65347.26
Iteration:   3560, Loss function: 3.259, Average Loss: 3.914, avg. samples / sec: 65397.47
Iteration:   3560, Loss function: 3.955, Average Loss: 3.941, avg. samples / sec: 65432.21
Iteration:   3560, Loss function: 2.480, Average Loss: 3.924, avg. samples / sec: 65462.27
Iteration:   3560, Loss function: 2.999, Average Loss: 3.936, avg. samples / sec: 65396.32
Iteration:   3560, Loss function: 2.803, Average Loss: 3.926, avg. samples / sec: 65535.82
Iteration:   3560, Loss function: 3.702, Average Loss: 3.930, avg. samples / sec: 65467.38
Iteration:   3560, Loss function: 5.347, Average Loss: 3.931, avg. samples / sec: 65352.35
Iteration:   3560, Loss function: 3.375, Average Loss: 3.896, avg. samples / sec: 65284.72
Iteration:   3560, Loss function: 2.836, Average Loss: 3.907, avg. samples / sec: 65271.17
Iteration:   3560, Loss function: 3.171, Average Loss: 3.921, avg. samples / sec: 65377.03
Iteration:   3560, Loss function: 3.015, Average Loss: 3.921, avg. samples / sec: 65326.36
Iteration:   3560, Loss function: 2.497, Average Loss: 3.916, avg. samples / sec: 65186.00
Iteration:   3560, Loss function: 3.946, Average Loss: 3.942, avg. samples / sec: 65175.03
Iteration:   3560, Loss function: 3.893, Average Loss: 3.897, avg. samples / sec: 65241.41
Iteration:   3580, Loss function: 2.294, Average Loss: 3.884, avg. samples / sec: 65975.10
Iteration:   3580, Loss function: 4.484, Average Loss: 3.896, avg. samples / sec: 66057.88
Iteration:   3580, Loss function: 3.793, Average Loss: 3.911, avg. samples / sec: 66015.46
Iteration:   3580, Loss function: 2.860, Average Loss: 3.906, avg. samples / sec: 66115.74
Iteration:   3580, Loss function: 4.683, Average Loss: 3.900, avg. samples / sec: 65981.68
Iteration:   3580, Loss function: 3.085, Average Loss: 3.919, avg. samples / sec: 66077.98
Iteration:   3580, Loss function: 4.528, Average Loss: 3.883, avg. samples / sec: 65999.01
Iteration:   3580, Loss function: 2.513, Average Loss: 3.885, avg. samples / sec: 66044.05
Iteration:   3580, Loss function: 3.650, Average Loss: 3.897, avg. samples / sec: 65858.52
Iteration:   3580, Loss function: 3.161, Average Loss: 3.895, avg. samples / sec: 65950.43
Iteration:   3580, Loss function: 3.928, Average Loss: 3.920, avg. samples / sec: 65984.18
Iteration:   3580, Loss function: 4.295, Average Loss: 3.907, avg. samples / sec: 66143.33
Iteration:   3580, Loss function: 3.840, Average Loss: 3.901, avg. samples / sec: 66045.65
Iteration:   3580, Loss function: 3.506, Average Loss: 3.894, avg. samples / sec: 65880.75
Iteration:   3580, Loss function: 3.141, Average Loss: 3.916, avg. samples / sec: 65700.28
Iteration:   3580, Loss function: 3.117, Average Loss: 3.888, avg. samples / sec: 66201.71
Iteration:   3580, Loss function: 4.040, Average Loss: 3.906, avg. samples / sec: 65903.37
Iteration:   3580, Loss function: 4.965, Average Loss: 3.912, avg. samples / sec: 65917.30
Iteration:   3580, Loss function: 3.652, Average Loss: 3.895, avg. samples / sec: 65872.32
Iteration:   3580, Loss function: 3.364, Average Loss: 3.931, avg. samples / sec: 65926.95
Iteration:   3580, Loss function: 3.845, Average Loss: 3.932, avg. samples / sec: 66080.18
Iteration:   3580, Loss function: 3.266, Average Loss: 3.914, avg. samples / sec: 65925.62
Iteration:   3580, Loss function: 3.622, Average Loss: 3.916, avg. samples / sec: 65837.91
Iteration:   3580, Loss function: 3.250, Average Loss: 3.914, avg. samples / sec: 65992.61
Iteration:   3580, Loss function: 3.988, Average Loss: 3.932, avg. samples / sec: 65888.82
Iteration:   3580, Loss function: 3.236, Average Loss: 3.905, avg. samples / sec: 65887.59
Iteration:   3580, Loss function: 4.069, Average Loss: 3.917, avg. samples / sec: 65834.93
Iteration:   3580, Loss function: 4.202, Average Loss: 3.914, avg. samples / sec: 65867.20
Iteration:   3580, Loss function: 4.246, Average Loss: 3.928, avg. samples / sec: 65880.75
Iteration:   3580, Loss function: 3.690, Average Loss: 3.892, avg. samples / sec: 65622.12
Iteration:   3600, Loss function: 2.710, Average Loss: 3.891, avg. samples / sec: 65510.71
Iteration:   3600, Loss function: 4.488, Average Loss: 3.919, avg. samples / sec: 65722.34
Iteration:   3600, Loss function: 3.397, Average Loss: 3.912, avg. samples / sec: 65714.56
Iteration:   3600, Loss function: 4.191, Average Loss: 3.905, avg. samples / sec: 65503.13
Iteration:   3600, Loss function: 3.192, Average Loss: 3.884, avg. samples / sec: 65600.43
Iteration:   3600, Loss function: 3.632, Average Loss: 3.874, avg. samples / sec: 65430.69
Iteration:   3600, Loss function: 3.557, Average Loss: 3.903, avg. samples / sec: 65619.64
Iteration:   3600, Loss function: 2.255, Average Loss: 3.886, avg. samples / sec: 65583.36
Iteration:   3600, Loss function: 2.616, Average Loss: 3.907, avg. samples / sec: 65673.71
Iteration:   3600, Loss function: 2.649, Average Loss: 3.912, avg. samples / sec: 65519.18
Iteration:   3600, Loss function: 3.178, Average Loss: 3.905, avg. samples / sec: 65628.38
Iteration:   3600, Loss function: 3.673, Average Loss: 3.899, avg. samples / sec: 65584.37
Iteration:   3600, Loss function: 5.840, Average Loss: 3.927, avg. samples / sec: 65622.24
Iteration:   3600, Loss function: 3.388, Average Loss: 3.896, avg. samples / sec: 65512.72
Iteration:   3600, Loss function: 3.084, Average Loss: 3.890, avg. samples / sec: 65568.84
Iteration:   3600, Loss function: 3.166, Average Loss: 3.887, avg. samples / sec: 65555.18
Iteration:   3600, Loss function: 3.533, Average Loss: 3.899, avg. samples / sec: 65527.47
Iteration:   3600, Loss function: 3.409, Average Loss: 3.892, avg. samples / sec: 65489.34
Iteration:   3600, Loss function: 3.545, Average Loss: 3.871, avg. samples / sec: 65437.86
Iteration:   3600, Loss function: 3.518, Average Loss: 3.895, avg. samples / sec: 65451.81
Iteration:   3600, Loss function: 3.606, Average Loss: 3.877, avg. samples / sec: 65779.89
Iteration:   3600, Loss function: 3.312, Average Loss: 3.903, avg. samples / sec: 65530.33
Iteration:   3600, Loss function: 3.234, Average Loss: 3.926, avg. samples / sec: 65526.68
Iteration:   3600, Loss function: 2.635, Average Loss: 3.898, avg. samples / sec: 65473.19
Iteration:   3600, Loss function: 2.253, Average Loss: 3.921, avg. samples / sec: 65478.21
Iteration:   3600, Loss function: 3.593, Average Loss: 3.899, avg. samples / sec: 65510.81
Iteration:   3600, Loss function: 4.030, Average Loss: 3.875, avg. samples / sec: 65464.52
Iteration:   3600, Loss function: 3.137, Average Loss: 3.875, avg. samples / sec: 65407.89
Iteration:   3600, Loss function: 4.114, Average Loss: 3.893, avg. samples / sec: 65480.09
Iteration:   3600, Loss function: 3.125, Average Loss: 3.914, avg. samples / sec: 65418.54
Iteration:   3620, Loss function: 2.889, Average Loss: 3.881, avg. samples / sec: 66139.20
Iteration:   3620, Loss function: 3.656, Average Loss: 3.865, avg. samples / sec: 66184.21
Iteration:   3620, Loss function: 3.783, Average Loss: 3.921, avg. samples / sec: 66223.27
Iteration:   3620, Loss function: 2.303, Average Loss: 3.883, avg. samples / sec: 66283.26
Iteration:   3620, Loss function: 2.766, Average Loss: 3.878, avg. samples / sec: 66242.23
Iteration:   3620, Loss function: 3.189, Average Loss: 3.889, avg. samples / sec: 66251.63
Iteration:   3620, Loss function: 3.135, Average Loss: 3.908, avg. samples / sec: 66131.16
Iteration:   3620, Loss function: 2.852, Average Loss: 3.902, avg. samples / sec: 66130.20
Iteration:   3620, Loss function: 2.315, Average Loss: 3.879, avg. samples / sec: 66148.79
Iteration:   3620, Loss function: 3.334, Average Loss: 3.893, avg. samples / sec: 66114.94
Iteration:   3620, Loss function: 3.750, Average Loss: 3.889, avg. samples / sec: 66159.29
Iteration:   3620, Loss function: 2.963, Average Loss: 3.898, avg. samples / sec: 66124.55
Iteration:   3620, Loss function: 2.254, Average Loss: 3.884, avg. samples / sec: 66223.71
Iteration:   3620, Loss function: 3.256, Average Loss: 3.897, avg. samples / sec: 66118.26
Iteration:   3620, Loss function: 3.038, Average Loss: 3.891, avg. samples / sec: 66249.79
Iteration:   3620, Loss function: 3.009, Average Loss: 3.885, avg. samples / sec: 66238.93
Iteration:   3620, Loss function: 3.361, Average Loss: 3.873, avg. samples / sec: 66063.43
Iteration:   3620, Loss function: 3.657, Average Loss: 3.881, avg. samples / sec: 66116.02
Iteration:   3620, Loss function: 2.996, Average Loss: 3.865, avg. samples / sec: 66239.92
Iteration:   3620, Loss function: 3.865, Average Loss: 3.897, avg. samples / sec: 66175.16
Iteration:   3620, Loss function: 2.863, Average Loss: 3.916, avg. samples / sec: 66186.23
Iteration:   3620, Loss function: 2.511, Average Loss: 3.864, avg. samples / sec: 66138.58
Iteration:   3620, Loss function: 4.190, Average Loss: 3.903, avg. samples / sec: 66060.67
Iteration:   3620, Loss function: 4.016, Average Loss: 3.869, avg. samples / sec: 66137.87
Iteration:   3620, Loss function: 4.342, Average Loss: 3.886, avg. samples / sec: 66059.74
Iteration:   3620, Loss function: 3.622, Average Loss: 3.881, avg. samples / sec: 66112.70
Iteration:   3620, Loss function: 3.562, Average Loss: 3.906, avg. samples / sec: 66203.11
Iteration:   3620, Loss function: 3.367, Average Loss: 3.865, avg. samples / sec: 66144.94
Iteration:   3620, Loss function: 2.455, Average Loss: 3.911, avg. samples / sec: 66069.28
Iteration:   3620, Loss function: 3.341, Average Loss: 3.892, avg. samples / sec: 65964.29
:::MLL 1558651795.228 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558651795.229 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 3.858, Average Loss: 3.878, avg. samples / sec: 65732.92
Iteration:   3640, Loss function: 3.530, Average Loss: 3.857, avg. samples / sec: 65715.48
Iteration:   3640, Loss function: 2.926, Average Loss: 3.890, avg. samples / sec: 65846.95
Iteration:   3640, Loss function: 3.710, Average Loss: 3.871, avg. samples / sec: 65717.35
Iteration:   3640, Loss function: 3.116, Average Loss: 3.860, avg. samples / sec: 65805.51
Iteration:   3640, Loss function: 2.992, Average Loss: 3.897, avg. samples / sec: 65763.93
Iteration:   3640, Loss function: 5.070, Average Loss: 3.866, avg. samples / sec: 65700.99
Iteration:   3640, Loss function: 3.000, Average Loss: 3.882, avg. samples / sec: 65670.13
Iteration:   3640, Loss function: 3.626, Average Loss: 3.895, avg. samples / sec: 65624.87
Iteration:   3640, Loss function: 2.589, Average Loss: 3.869, avg. samples / sec: 65601.16
Iteration:   3640, Loss function: 3.258, Average Loss: 3.871, avg. samples / sec: 65765.37
Iteration:   3640, Loss function: 3.225, Average Loss: 3.854, avg. samples / sec: 65743.93
Iteration:   3640, Loss function: 4.058, Average Loss: 3.882, avg. samples / sec: 65629.76
Iteration:   3640, Loss function: 3.209, Average Loss: 3.867, avg. samples / sec: 65620.53
Iteration:   3640, Loss function: 2.610, Average Loss: 3.859, avg. samples / sec: 65734.42
Iteration:   3640, Loss function: 2.573, Average Loss: 3.886, avg. samples / sec: 65609.68
Iteration:   3640, Loss function: 2.164, Average Loss: 3.910, avg. samples / sec: 65549.41
Iteration:   3640, Loss function: 4.386, Average Loss: 3.881, avg. samples / sec: 65683.13
Iteration:   3640, Loss function: 4.195, Average Loss: 3.909, avg. samples / sec: 65697.13
Iteration:   3640, Loss function: 4.227, Average Loss: 3.903, avg. samples / sec: 65568.72
Iteration:   3640, Loss function: 3.547, Average Loss: 3.874, avg. samples / sec: 65617.32
Iteration:   3640, Loss function: 3.179, Average Loss: 3.885, avg. samples / sec: 65649.84
Iteration:   3640, Loss function: 3.754, Average Loss: 3.876, avg. samples / sec: 65682.25
Iteration:   3640, Loss function: 3.417, Average Loss: 3.851, avg. samples / sec: 65620.53
Iteration:   3640, Loss function: 3.558, Average Loss: 3.874, avg. samples / sec: 65561.92
Iteration:   3640, Loss function: 3.129, Average Loss: 3.882, avg. samples / sec: 65724.73
Iteration:   3640, Loss function: 2.715, Average Loss: 3.873, avg. samples / sec: 65461.66
Iteration:   3640, Loss function: 4.651, Average Loss: 3.881, avg. samples / sec: 65453.42
Iteration:   3640, Loss function: 2.304, Average Loss: 3.886, avg. samples / sec: 65532.10
Iteration:   3640, Loss function: 3.506, Average Loss: 3.901, avg. samples / sec: 65639.05
Iteration:   3660, Loss function: 2.969, Average Loss: 3.849, avg. samples / sec: 65966.57
Iteration:   3660, Loss function: 3.302, Average Loss: 3.900, avg. samples / sec: 66085.36
Iteration:   3660, Loss function: 3.178, Average Loss: 3.871, avg. samples / sec: 66135.07
Iteration:   3660, Loss function: 2.173, Average Loss: 3.871, avg. samples / sec: 66142.18
Iteration:   3660, Loss function: 3.154, Average Loss: 3.866, avg. samples / sec: 66087.62
Iteration:   3660, Loss function: 4.095, Average Loss: 3.872, avg. samples / sec: 65850.65
Iteration:   3660, Loss function: 2.910, Average Loss: 3.873, avg. samples / sec: 66029.01
Iteration:   3660, Loss function: 4.421, Average Loss: 3.888, avg. samples / sec: 65981.68
Iteration:   3660, Loss function: 2.299, Average Loss: 3.854, avg. samples / sec: 65979.82
Iteration:   3660, Loss function: 4.728, Average Loss: 3.864, avg. samples / sec: 65973.74
Iteration:   3660, Loss function: 3.010, Average Loss: 3.873, avg. samples / sec: 66022.14
Iteration:   3660, Loss function: 3.680, Average Loss: 3.878, avg. samples / sec: 65852.34
Iteration:   3660, Loss function: 3.343, Average Loss: 3.848, avg. samples / sec: 66013.26
Iteration:   3660, Loss function: 3.312, Average Loss: 3.864, avg. samples / sec: 66039.50
Iteration:   3660, Loss function: 2.896, Average Loss: 3.870, avg. samples / sec: 65965.65
Iteration:   3660, Loss function: 3.614, Average Loss: 3.890, avg. samples / sec: 65925.66
Iteration:   3660, Loss function: 3.393, Average Loss: 3.876, avg. samples / sec: 65957.34
Iteration:   3660, Loss function: 3.657, Average Loss: 3.874, avg. samples / sec: 65874.32
Iteration:   3660, Loss function: 3.229, Average Loss: 3.873, avg. samples / sec: 66055.03
Iteration:   3660, Loss function: 3.757, Average Loss: 3.852, avg. samples / sec: 65878.87
Iteration:   3660, Loss function: 3.628, Average Loss: 3.865, avg. samples / sec: 66022.02
Iteration:   3660, Loss function: 3.730, Average Loss: 3.880, avg. samples / sec: 66032.75
Iteration:   3660, Loss function: 3.396, Average Loss: 3.897, avg. samples / sec: 65884.60
Iteration:   3660, Loss function: 2.234, Average Loss: 3.860, avg. samples / sec: 65843.02
Iteration:   3660, Loss function: 3.830, Average Loss: 3.848, avg. samples / sec: 65845.97
Iteration:   3660, Loss function: 4.262, Average Loss: 3.855, avg. samples / sec: 65828.07
Iteration:   3660, Loss function: 4.666, Average Loss: 3.866, avg. samples / sec: 65823.46
Iteration:   3660, Loss function: 3.003, Average Loss: 3.849, avg. samples / sec: 65860.00
Iteration:   3660, Loss function: 3.648, Average Loss: 3.894, avg. samples / sec: 65886.48
Iteration:   3660, Loss function: 2.509, Average Loss: 3.891, avg. samples / sec: 65965.77
Iteration:   3680, Loss function: 3.401, Average Loss: 3.853, avg. samples / sec: 66289.96
Iteration:   3680, Loss function: 3.535, Average Loss: 3.864, avg. samples / sec: 66110.10
Iteration:   3680, Loss function: 3.638, Average Loss: 3.889, avg. samples / sec: 66293.49
Iteration:   3680, Loss function: 3.530, Average Loss: 3.866, avg. samples / sec: 66216.24
Iteration:   3680, Loss function: 3.627, Average Loss: 3.864, avg. samples / sec: 66083.44
Iteration:   3680, Loss function: 3.923, Average Loss: 3.845, avg. samples / sec: 66018.09
Iteration:   3680, Loss function: 2.840, Average Loss: 3.865, avg. samples / sec: 66059.83
Iteration:   3680, Loss function: 3.267, Average Loss: 3.847, avg. samples / sec: 66097.82
Iteration:   3680, Loss function: 3.452, Average Loss: 3.863, avg. samples / sec: 66163.08
Iteration:   3680, Loss function: 3.236, Average Loss: 3.872, avg. samples / sec: 66081.08
Iteration:   3680, Loss function: 4.263, Average Loss: 3.866, avg. samples / sec: 66162.92
Iteration:   3680, Loss function: 3.248, Average Loss: 3.891, avg. samples / sec: 65994.93
Iteration:   3680, Loss function: 4.224, Average Loss: 3.851, avg. samples / sec: 66179.39
Iteration:   3680, Loss function: 4.374, Average Loss: 3.869, avg. samples / sec: 66171.56
Iteration:   3680, Loss function: 3.604, Average Loss: 3.856, avg. samples / sec: 66202.52
Iteration:   3680, Loss function: 2.891, Average Loss: 3.838, avg. samples / sec: 66089.11
Iteration:   3680, Loss function: 4.554, Average Loss: 3.859, avg. samples / sec: 66137.09
Iteration:   3680, Loss function: 3.401, Average Loss: 3.839, avg. samples / sec: 66144.10
Iteration:   3680, Loss function: 4.794, Average Loss: 3.865, avg. samples / sec: 65961.29
Iteration:   3680, Loss function: 3.141, Average Loss: 3.879, avg. samples / sec: 66049.65
Iteration:   3680, Loss function: 2.733, Average Loss: 3.886, avg. samples / sec: 66126.32
Iteration:   3680, Loss function: 3.230, Average Loss: 3.854, avg. samples / sec: 66048.56
Iteration:   3680, Loss function: 2.940, Average Loss: 3.859, avg. samples / sec: 65908.24
Iteration:   3680, Loss function: 3.594, Average Loss: 3.863, avg. samples / sec: 66028.08
Iteration:   3680, Loss function: 3.193, Average Loss: 3.863, avg. samples / sec: 65985.51
Iteration:   3680, Loss function: 3.820, Average Loss: 3.841, avg. samples / sec: 66054.57
Iteration:   3680, Loss function: 3.180, Average Loss: 3.882, avg. samples / sec: 66132.65
Iteration:   3680, Loss function: 3.672, Average Loss: 3.865, avg. samples / sec: 65954.90
Iteration:   3680, Loss function: 3.774, Average Loss: 3.850, avg. samples / sec: 66025.51
Iteration:   3680, Loss function: 2.680, Average Loss: 3.836, avg. samples / sec: 66028.45
:::MLL 1558651797.012 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558651797.012 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 2.601, Average Loss: 3.854, avg. samples / sec: 65899.58
Iteration:   3700, Loss function: 2.211, Average Loss: 3.854, avg. samples / sec: 65921.58
Iteration:   3700, Loss function: 3.021, Average Loss: 3.839, avg. samples / sec: 65885.56
Iteration:   3700, Loss function: 3.474, Average Loss: 3.851, avg. samples / sec: 65848.58
Iteration:   3700, Loss function: 3.457, Average Loss: 3.842, avg. samples / sec: 65943.92
Iteration:   3700, Loss function: 4.053, Average Loss: 3.865, avg. samples / sec: 65925.66
Iteration:   3700, Loss function: 3.598, Average Loss: 3.844, avg. samples / sec: 65714.16
Iteration:   3700, Loss function: 4.058, Average Loss: 3.856, avg. samples / sec: 65956.54
Iteration:   3700, Loss function: 3.038, Average Loss: 3.834, avg. samples / sec: 65984.24
Iteration:   3700, Loss function: 3.486, Average Loss: 3.874, avg. samples / sec: 65796.04
Iteration:   3700, Loss function: 2.373, Average Loss: 3.863, avg. samples / sec: 65877.58
Iteration:   3700, Loss function: 3.064, Average Loss: 3.856, avg. samples / sec: 65859.91
Iteration:   3700, Loss function: 2.570, Average Loss: 3.847, avg. samples / sec: 65872.84
Iteration:   3700, Loss function: 4.130, Average Loss: 3.840, avg. samples / sec: 66036.03
Iteration:   3700, Loss function: 3.658, Average Loss: 3.850, avg. samples / sec: 65921.03
Iteration:   3700, Loss function: 3.045, Average Loss: 3.858, avg. samples / sec: 65758.84
Iteration:   3700, Loss function: 3.784, Average Loss: 3.824, avg. samples / sec: 65839.79
Iteration:   3700, Loss function: 2.517, Average Loss: 3.879, avg. samples / sec: 65792.21
Iteration:   3700, Loss function: 3.325, Average Loss: 3.844, avg. samples / sec: 65875.86
Iteration:   3700, Loss function: 3.830, Average Loss: 3.875, avg. samples / sec: 65866.84
Iteration:   3700, Loss function: 3.147, Average Loss: 3.853, avg. samples / sec: 65945.18
Iteration:   3700, Loss function: 3.333, Average Loss: 3.855, avg. samples / sec: 65878.29
Iteration:   3700, Loss function: 2.962, Average Loss: 3.861, avg. samples / sec: 65835.39
Iteration:   3700, Loss function: 3.660, Average Loss: 3.859, avg. samples / sec: 65735.86
Iteration:   3700, Loss function: 3.882, Average Loss: 3.845, avg. samples / sec: 65799.33
Iteration:   3700, Loss function: 3.126, Average Loss: 3.839, avg. samples / sec: 65722.77
Iteration:   3700, Loss function: 3.924, Average Loss: 3.833, avg. samples / sec: 65788.34
Iteration:   3700, Loss function: 3.285, Average Loss: 3.859, avg. samples / sec: 65804.16
Iteration:   3700, Loss function: 2.582, Average Loss: 3.870, avg. samples / sec: 65776.36
Iteration:   3700, Loss function: 3.905, Average Loss: 3.830, avg. samples / sec: 65792.94
Iteration:   3720, Loss function: 3.556, Average Loss: 3.841, avg. samples / sec: 66172.09
Iteration:   3720, Loss function: 3.792, Average Loss: 3.828, avg. samples / sec: 66336.99
Iteration:   3720, Loss function: 3.967, Average Loss: 3.836, avg. samples / sec: 66104.05
Iteration:   3720, Loss function: 2.958, Average Loss: 3.851, avg. samples / sec: 66110.63
Iteration:   3720, Loss function: 4.268, Average Loss: 3.845, avg. samples / sec: 66089.02
Iteration:   3720, Loss function: 3.499, Average Loss: 3.844, avg. samples / sec: 66088.12
Iteration:   3720, Loss function: 3.623, Average Loss: 3.867, avg. samples / sec: 66135.57
Iteration:   3720, Loss function: 3.201, Average Loss: 3.838, avg. samples / sec: 66160.62
Iteration:   3720, Loss function: 4.243, Average Loss: 3.851, avg. samples / sec: 66213.10
Iteration:   3720, Loss function: 3.281, Average Loss: 3.841, avg. samples / sec: 66020.53
Iteration:   3720, Loss function: 3.598, Average Loss: 3.817, avg. samples / sec: 66148.20
Iteration:   3720, Loss function: 3.778, Average Loss: 3.846, avg. samples / sec: 66183.52
Iteration:   3720, Loss function: 3.852, Average Loss: 3.851, avg. samples / sec: 66138.77
Iteration:   3720, Loss function: 4.279, Average Loss: 3.849, avg. samples / sec: 66165.47
Iteration:   3720, Loss function: 2.971, Average Loss: 3.834, avg. samples / sec: 66001.58
Iteration:   3720, Loss function: 3.454, Average Loss: 3.855, avg. samples / sec: 66209.52
Iteration:   3720, Loss function: 3.513, Average Loss: 3.844, avg. samples / sec: 66060.55
Iteration:   3720, Loss function: 3.703, Average Loss: 3.847, avg. samples / sec: 66106.90
Iteration:   3720, Loss function: 2.882, Average Loss: 3.855, avg. samples / sec: 66277.55
Iteration:   3720, Loss function: 3.416, Average Loss: 3.865, avg. samples / sec: 66114.10
Iteration:   3720, Loss function: 3.554, Average Loss: 3.868, avg. samples / sec: 66093.20
Iteration:   3720, Loss function: 2.836, Average Loss: 3.824, avg. samples / sec: 66165.66
Iteration:   3720, Loss function: 3.425, Average Loss: 3.833, avg. samples / sec: 66071.17
Iteration:   3720, Loss function: 4.066, Average Loss: 3.832, avg. samples / sec: 66034.95
Iteration:   3720, Loss function: 4.443, Average Loss: 3.820, avg. samples / sec: 66251.29
Iteration:   3720, Loss function: 3.017, Average Loss: 3.849, avg. samples / sec: 65969.85
Iteration:   3720, Loss function: 2.936, Average Loss: 3.823, avg. samples / sec: 65968.06
Iteration:   3720, Loss function: 3.872, Average Loss: 3.835, avg. samples / sec: 66046.83
Iteration:   3720, Loss function: 3.657, Average Loss: 3.846, avg. samples / sec: 65873.30
Iteration:   3720, Loss function: 4.698, Average Loss: 3.857, avg. samples / sec: 65866.90
Iteration:   3740, Loss function: 2.986, Average Loss: 3.858, avg. samples / sec: 65372.27
Iteration:   3740, Loss function: 3.737, Average Loss: 3.840, avg. samples / sec: 65320.06
Iteration:   3740, Loss function: 3.300, Average Loss: 3.861, avg. samples / sec: 65471.61
Iteration:   3740, Loss function: 2.176, Average Loss: 3.837, avg. samples / sec: 65316.58
Iteration:   3740, Loss function: 3.986, Average Loss: 3.826, avg. samples / sec: 65291.91
Iteration:   3740, Loss function: 4.222, Average Loss: 3.840, avg. samples / sec: 65330.51
Iteration:   3740, Loss function: 4.328, Average Loss: 3.839, avg. samples / sec: 65586.69
Iteration:   3740, Loss function: 3.834, Average Loss: 3.846, avg. samples / sec: 65590.17
Iteration:   3740, Loss function: 3.815, Average Loss: 3.828, avg. samples / sec: 65379.06
Iteration:   3740, Loss function: 2.663, Average Loss: 3.826, avg. samples / sec: 65294.88
Iteration:   3740, Loss function: 4.145, Average Loss: 3.856, avg. samples / sec: 65391.25
Iteration:   3740, Loss function: 2.540, Average Loss: 3.804, avg. samples / sec: 65312.13
Iteration:   3740, Loss function: 5.298, Average Loss: 3.839, avg. samples / sec: 65321.27
Iteration:   3740, Loss function: 4.314, Average Loss: 3.836, avg. samples / sec: 65161.77
Iteration:   3740, Loss function: 2.743, Average Loss: 3.842, avg. samples / sec: 65261.53
Iteration:   3740, Loss function: 4.235, Average Loss: 3.842, avg. samples / sec: 65352.53
Iteration:   3740, Loss function: 2.540, Average Loss: 3.811, avg. samples / sec: 65381.33
Iteration:   3740, Loss function: 4.049, Average Loss: 3.847, avg. samples / sec: 65306.59
Iteration:   3740, Loss function: 3.124, Average Loss: 3.836, avg. samples / sec: 65286.95
Iteration:   3740, Loss function: 2.314, Average Loss: 3.845, avg. samples / sec: 65276.25
Iteration:   3740, Loss function: 3.648, Average Loss: 3.827, avg. samples / sec: 65316.24
Iteration:   3740, Loss function: 2.474, Average Loss: 3.828, avg. samples / sec: 65361.53
Iteration:   3740, Loss function: 4.741, Average Loss: 3.835, avg. samples / sec: 65180.24
Iteration:   3740, Loss function: 3.095, Average Loss: 3.846, avg. samples / sec: 65221.93
Iteration:   3740, Loss function: 3.918, Average Loss: 3.830, avg. samples / sec: 65264.70
Iteration:   3740, Loss function: 3.579, Average Loss: 3.838, avg. samples / sec: 65291.40
Iteration:   3740, Loss function: 2.902, Average Loss: 3.818, avg. samples / sec: 65242.92
Iteration:   3740, Loss function: 4.206, Average Loss: 3.819, avg. samples / sec: 65050.87
Iteration:   3740, Loss function: 2.866, Average Loss: 3.842, avg. samples / sec: 65144.69
Iteration:   3740, Loss function: 2.833, Average Loss: 3.813, avg. samples / sec: 65231.26
Iteration:   3760, Loss function: 3.229, Average Loss: 3.817, avg. samples / sec: 65695.01
Iteration:   3760, Loss function: 2.713, Average Loss: 3.824, avg. samples / sec: 65794.66
Iteration:   3760, Loss function: 3.688, Average Loss: 3.847, avg. samples / sec: 65627.43
Iteration:   3760, Loss function: 2.767, Average Loss: 3.822, avg. samples / sec: 65673.64
Iteration:   3760, Loss function: 3.370, Average Loss: 3.833, avg. samples / sec: 65637.31
Iteration:   3760, Loss function: 2.452, Average Loss: 3.822, avg. samples / sec: 65811.90
Iteration:   3760, Loss function: 2.579, Average Loss: 3.831, avg. samples / sec: 65682.89
Iteration:   3760, Loss function: 2.987, Average Loss: 3.833, avg. samples / sec: 65738.04
Iteration:   3760, Loss function: 4.082, Average Loss: 3.796, avg. samples / sec: 65682.58
Iteration:   3760, Loss function: 2.546, Average Loss: 3.831, avg. samples / sec: 65581.35
Iteration:   3760, Loss function: 3.076, Average Loss: 3.849, avg. samples / sec: 65602.17
Iteration:   3760, Loss function: 3.629, Average Loss: 3.818, avg. samples / sec: 65653.88
Iteration:   3760, Loss function: 3.501, Average Loss: 3.833, avg. samples / sec: 65621.48
Iteration:   3760, Loss function: 3.887, Average Loss: 3.837, avg. samples / sec: 65680.35
Iteration:   3760, Loss function: 2.861, Average Loss: 3.827, avg. samples / sec: 65760.40
Iteration:   3760, Loss function: 3.654, Average Loss: 3.836, avg. samples / sec: 65649.72
Iteration:   3760, Loss function: 3.610, Average Loss: 3.830, avg. samples / sec: 65573.57
Iteration:   3760, Loss function: 1.835, Average Loss: 3.836, avg. samples / sec: 65737.58
Iteration:   3760, Loss function: 3.533, Average Loss: 3.810, avg. samples / sec: 65777.16
Iteration:   3760, Loss function: 2.990, Average Loss: 3.828, avg. samples / sec: 65618.14
Iteration:   3760, Loss function: 3.499, Average Loss: 3.830, avg. samples / sec: 65564.23
Iteration:   3760, Loss function: 3.073, Average Loss: 3.836, avg. samples / sec: 65718.57
Iteration:   3760, Loss function: 4.827, Average Loss: 3.809, avg. samples / sec: 65764.45
Iteration:   3760, Loss function: 4.041, Average Loss: 3.823, avg. samples / sec: 65691.74
Iteration:   3760, Loss function: 3.841, Average Loss: 3.831, avg. samples / sec: 65769.36
Iteration:   3760, Loss function: 2.512, Average Loss: 3.800, avg. samples / sec: 65613.59
Iteration:   3760, Loss function: 3.415, Average Loss: 3.849, avg. samples / sec: 65547.22
Iteration:   3760, Loss function: 4.406, Average Loss: 3.799, avg. samples / sec: 65713.42
Iteration:   3760, Loss function: 3.838, Average Loss: 3.817, avg. samples / sec: 65616.49
Iteration:   3760, Loss function: 4.273, Average Loss: 3.816, avg. samples / sec: 65539.78
:::MLL 1558651798.803 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558651798.803 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 2.946, Average Loss: 3.822, avg. samples / sec: 65762.15
Iteration:   3780, Loss function: 3.447, Average Loss: 3.839, avg. samples / sec: 65707.23
Iteration:   3780, Loss function: 3.537, Average Loss: 3.844, avg. samples / sec: 65753.28
Iteration:   3780, Loss function: 3.635, Average Loss: 3.790, avg. samples / sec: 65715.94
Iteration:   3780, Loss function: 3.592, Average Loss: 3.824, avg. samples / sec: 65716.24
Iteration:   3780, Loss function: 2.091, Average Loss: 3.810, avg. samples / sec: 65667.40
Iteration:   3780, Loss function: 3.691, Average Loss: 3.804, avg. samples / sec: 65593.96
Iteration:   3780, Loss function: 3.647, Average Loss: 3.828, avg. samples / sec: 65705.40
Iteration:   3780, Loss function: 4.560, Average Loss: 3.833, avg. samples / sec: 65685.00
Iteration:   3780, Loss function: 4.240, Average Loss: 3.823, avg. samples / sec: 65670.31
Iteration:   3780, Loss function: 4.439, Average Loss: 3.789, avg. samples / sec: 65801.51
Iteration:   3780, Loss function: 2.978, Average Loss: 3.820, avg. samples / sec: 65699.76
Iteration:   3780, Loss function: 3.430, Average Loss: 3.821, avg. samples / sec: 65720.10
Iteration:   3780, Loss function: 2.907, Average Loss: 3.823, avg. samples / sec: 65687.21
Iteration:   3780, Loss function: 3.706, Average Loss: 3.828, avg. samples / sec: 65614.60
Iteration:   3780, Loss function: 3.466, Average Loss: 3.811, avg. samples / sec: 65621.87
Iteration:   3780, Loss function: 3.315, Average Loss: 3.818, avg. samples / sec: 65667.43
Iteration:   3780, Loss function: 2.321, Average Loss: 3.805, avg. samples / sec: 65802.00
Iteration:   3780, Loss function: 3.259, Average Loss: 3.798, avg. samples / sec: 65658.90
Iteration:   3780, Loss function: 3.932, Average Loss: 3.821, avg. samples / sec: 65600.03
Iteration:   3780, Loss function: 3.845, Average Loss: 3.811, avg. samples / sec: 65558.32
Iteration:   3780, Loss function: 3.668, Average Loss: 3.836, avg. samples / sec: 65680.84
Iteration:   3780, Loss function: 3.073, Average Loss: 3.824, avg. samples / sec: 65613.10
Iteration:   3780, Loss function: 3.630, Average Loss: 3.787, avg. samples / sec: 65646.42
Iteration:   3780, Loss function: 2.841, Average Loss: 3.811, avg. samples / sec: 65623.55
Iteration:   3780, Loss function: 2.801, Average Loss: 3.812, avg. samples / sec: 65485.45
Iteration:   3780, Loss function: 2.495, Average Loss: 3.816, avg. samples / sec: 65569.30
Iteration:   3780, Loss function: 3.369, Average Loss: 3.802, avg. samples / sec: 65578.08
Iteration:   3780, Loss function: 3.249, Average Loss: 3.806, avg. samples / sec: 65741.14
Iteration:   3780, Loss function: 3.433, Average Loss: 3.831, avg. samples / sec: 65549.87
Iteration:   3800, Loss function: 3.485, Average Loss: 3.830, avg. samples / sec: 65857.79
Iteration:   3800, Loss function: 3.186, Average Loss: 3.797, avg. samples / sec: 65927.32
Iteration:   3800, Loss function: 2.908, Average Loss: 3.836, avg. samples / sec: 65806.74
Iteration:   3800, Loss function: 2.980, Average Loss: 3.815, avg. samples / sec: 65773.75
Iteration:   3800, Loss function: 2.216, Average Loss: 3.811, avg. samples / sec: 65919.12
Iteration:   3800, Loss function: 2.710, Average Loss: 3.803, avg. samples / sec: 65851.08
Iteration:   3800, Loss function: 2.014, Average Loss: 3.815, avg. samples / sec: 65914.40
Iteration:   3800, Loss function: 2.628, Average Loss: 3.813, avg. samples / sec: 65889.10
Iteration:   3800, Loss function: 2.951, Average Loss: 3.804, avg. samples / sec: 65913.78
Iteration:   3800, Loss function: 2.922, Average Loss: 3.779, avg. samples / sec: 65861.82
Iteration:   3800, Loss function: 2.489, Average Loss: 3.796, avg. samples / sec: 65991.90
Iteration:   3800, Loss function: 2.586, Average Loss: 3.807, avg. samples / sec: 65985.60
Iteration:   3800, Loss function: 3.625, Average Loss: 3.812, avg. samples / sec: 65917.11
Iteration:   3800, Loss function: 3.259, Average Loss: 3.804, avg. samples / sec: 65908.98
Iteration:   3800, Loss function: 2.926, Average Loss: 3.813, avg. samples / sec: 65756.41
Iteration:   3800, Loss function: 2.611, Average Loss: 3.793, avg. samples / sec: 65863.48
Iteration:   3800, Loss function: 5.358, Average Loss: 3.827, avg. samples / sec: 65795.68
Iteration:   3800, Loss function: 3.160, Average Loss: 3.805, avg. samples / sec: 65929.91
Iteration:   3800, Loss function: 3.602, Average Loss: 3.824, avg. samples / sec: 65959.63
Iteration:   3800, Loss function: 3.067, Average Loss: 3.807, avg. samples / sec: 65832.50
Iteration:   3800, Loss function: 4.486, Average Loss: 3.783, avg. samples / sec: 65925.56
Iteration:   3800, Loss function: 3.767, Average Loss: 3.830, avg. samples / sec: 65879.58
Iteration:   3800, Loss function: 3.091, Average Loss: 3.820, avg. samples / sec: 65765.56
Iteration:   3800, Loss function: 3.670, Average Loss: 3.810, avg. samples / sec: 65829.27
Iteration:   3800, Loss function: 3.570, Average Loss: 3.780, avg. samples / sec: 65696.67
Iteration:   3800, Loss function: 2.755, Average Loss: 3.821, avg. samples / sec: 65810.49
Iteration:   3800, Loss function: 3.946, Average Loss: 3.790, avg. samples / sec: 65818.91
Iteration:   3800, Loss function: 3.763, Average Loss: 3.818, avg. samples / sec: 65660.64
Iteration:   3800, Loss function: 3.643, Average Loss: 3.805, avg. samples / sec: 65768.16
Iteration:   3800, Loss function: 3.337, Average Loss: 3.797, avg. samples / sec: 65714.77
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558651799.832 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.55s)
DONE (t=2.47s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22550
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38640
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22890
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05811
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23741
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21881
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31885
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09961
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52758
Current AP: 0.22550 AP goal: 0.23000
:::MLL 1558651803.522 eval_accuracy: {"value": 0.22550274742115678, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558651803.530 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558651803.537 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558651803.537 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 3.961, Average Loss: 3.777, avg. samples / sec: 7957.06
Iteration:   3820, Loss function: 4.712, Average Loss: 3.794, avg. samples / sec: 7954.35
Iteration:   3820, Loss function: 3.389, Average Loss: 3.823, avg. samples / sec: 7953.50
Iteration:   3820, Loss function: 4.054, Average Loss: 3.807, avg. samples / sec: 7955.75
Iteration:   3820, Loss function: 4.305, Average Loss: 3.786, avg. samples / sec: 7955.55
Iteration:   3820, Loss function: 2.846, Average Loss: 3.823, avg. samples / sec: 7954.05
Iteration:   3820, Loss function: 3.018, Average Loss: 3.809, avg. samples / sec: 7955.26
Iteration:   3820, Loss function: 4.443, Average Loss: 3.809, avg. samples / sec: 7954.10
Iteration:   3820, Loss function: 2.490, Average Loss: 3.812, avg. samples / sec: 7957.18
Iteration:   3820, Loss function: 4.676, Average Loss: 3.804, avg. samples / sec: 7954.22
Iteration:   3820, Loss function: 2.335, Average Loss: 3.793, avg. samples / sec: 7953.88
Iteration:   3820, Loss function: 2.817, Average Loss: 3.796, avg. samples / sec: 7955.23
Iteration:   3820, Loss function: 2.789, Average Loss: 3.795, avg. samples / sec: 7954.35
Iteration:   3820, Loss function: 4.245, Average Loss: 3.795, avg. samples / sec: 7954.67
Iteration:   3820, Loss function: 3.297, Average Loss: 3.781, avg. samples / sec: 7955.69
Iteration:   3820, Loss function: 3.065, Average Loss: 3.810, avg. samples / sec: 7955.07
Iteration:   3820, Loss function: 2.682, Average Loss: 3.790, avg. samples / sec: 7958.15
Iteration:   3820, Loss function: 3.112, Average Loss: 3.798, avg. samples / sec: 7954.61
Iteration:   3820, Loss function: 3.806, Average Loss: 3.803, avg. samples / sec: 7955.16
Iteration:   3820, Loss function: 4.751, Average Loss: 3.820, avg. samples / sec: 7954.50
Iteration:   3820, Loss function: 3.746, Average Loss: 3.816, avg. samples / sec: 7954.37
Iteration:   3820, Loss function: 1.606, Average Loss: 3.797, avg. samples / sec: 7952.71
Iteration:   3820, Loss function: 3.005, Average Loss: 3.804, avg. samples / sec: 7952.78
Iteration:   3820, Loss function: 4.608, Average Loss: 3.786, avg. samples / sec: 7953.43
Iteration:   3820, Loss function: 3.503, Average Loss: 3.802, avg. samples / sec: 7953.10
Iteration:   3820, Loss function: 3.002, Average Loss: 3.794, avg. samples / sec: 7956.13
Iteration:   3820, Loss function: 3.647, Average Loss: 3.825, avg. samples / sec: 7953.75
Iteration:   3820, Loss function: 4.878, Average Loss: 3.775, avg. samples / sec: 7953.63
Iteration:   3820, Loss function: 2.670, Average Loss: 3.812, avg. samples / sec: 7952.30
Iteration:   3820, Loss function: 3.867, Average Loss: 3.773, avg. samples / sec: 7950.79
:::MLL 1558651804.309 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558651804.309 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 3.171, Average Loss: 3.784, avg. samples / sec: 65283.29
Iteration:   3840, Loss function: 3.610, Average Loss: 3.786, avg. samples / sec: 65191.79
Iteration:   3840, Loss function: 3.441, Average Loss: 3.786, avg. samples / sec: 65230.90
Iteration:   3840, Loss function: 3.578, Average Loss: 3.774, avg. samples / sec: 65130.24
Iteration:   3840, Loss function: 3.755, Average Loss: 3.817, avg. samples / sec: 65327.20
Iteration:   3840, Loss function: 3.544, Average Loss: 3.802, avg. samples / sec: 65182.56
Iteration:   3840, Loss function: 2.552, Average Loss: 3.788, avg. samples / sec: 65255.42
Iteration:   3840, Loss function: 3.013, Average Loss: 3.816, avg. samples / sec: 65119.28
Iteration:   3840, Loss function: 3.517, Average Loss: 3.813, avg. samples / sec: 65139.96
Iteration:   3840, Loss function: 3.958, Average Loss: 3.809, avg. samples / sec: 65199.84
Iteration:   3840, Loss function: 6.446, Average Loss: 3.785, avg. samples / sec: 65131.92
Iteration:   3840, Loss function: 4.215, Average Loss: 3.801, avg. samples / sec: 65117.66
Iteration:   3840, Loss function: 3.935, Average Loss: 3.807, avg. samples / sec: 65077.88
Iteration:   3840, Loss function: 4.149, Average Loss: 3.780, avg. samples / sec: 65137.01
Iteration:   3840, Loss function: 3.891, Average Loss: 3.774, avg. samples / sec: 65109.51
Iteration:   3840, Loss function: 3.916, Average Loss: 3.793, avg. samples / sec: 65103.49
Iteration:   3840, Loss function: 4.473, Average Loss: 3.793, avg. samples / sec: 65161.02
Iteration:   3840, Loss function: 2.575, Average Loss: 3.806, avg. samples / sec: 65149.72
Iteration:   3840, Loss function: 2.236, Average Loss: 3.789, avg. samples / sec: 65107.22
Iteration:   3840, Loss function: 4.319, Average Loss: 3.796, avg. samples / sec: 65109.87
Iteration:   3840, Loss function: 3.833, Average Loss: 3.780, avg. samples / sec: 65033.19
Iteration:   3840, Loss function: 2.488, Average Loss: 3.796, avg. samples / sec: 65089.93
Iteration:   3840, Loss function: 3.119, Average Loss: 3.775, avg. samples / sec: 65108.87
Iteration:   3840, Loss function: 3.879, Average Loss: 3.764, avg. samples / sec: 65146.74
Iteration:   3840, Loss function: 3.205, Average Loss: 3.781, avg. samples / sec: 65103.88
Iteration:   3840, Loss function: 2.935, Average Loss: 3.764, avg. samples / sec: 65247.90
Iteration:   3840, Loss function: 4.351, Average Loss: 3.804, avg. samples / sec: 65228.84
Iteration:   3840, Loss function: 3.010, Average Loss: 3.800, avg. samples / sec: 64947.83
Iteration:   3840, Loss function: 3.166, Average Loss: 3.792, avg. samples / sec: 65086.14
Iteration:   3840, Loss function: 3.536, Average Loss: 3.795, avg. samples / sec: 64938.68
Iteration:   3860, Loss function: 2.819, Average Loss: 3.792, avg. samples / sec: 64801.26
Iteration:   3860, Loss function: 3.046, Average Loss: 3.802, avg. samples / sec: 64612.39
Iteration:   3860, Loss function: 2.856, Average Loss: 3.779, avg. samples / sec: 64543.21
Iteration:   3860, Loss function: 3.411, Average Loss: 3.771, avg. samples / sec: 64545.19
Iteration:   3860, Loss function: 2.097, Average Loss: 3.796, avg. samples / sec: 64623.71
Iteration:   3860, Loss function: 2.672, Average Loss: 3.773, avg. samples / sec: 64738.03
Iteration:   3860, Loss function: 3.152, Average Loss: 3.760, avg. samples / sec: 64744.67
Iteration:   3860, Loss function: 3.184, Average Loss: 3.792, avg. samples / sec: 64545.37
Iteration:   3860, Loss function: 3.902, Average Loss: 3.779, avg. samples / sec: 64464.59
Iteration:   3860, Loss function: 3.421, Average Loss: 3.766, avg. samples / sec: 64714.88
Iteration:   3860, Loss function: 2.938, Average Loss: 3.782, avg. samples / sec: 64652.97
Iteration:   3860, Loss function: 3.142, Average Loss: 3.793, avg. samples / sec: 64637.44
Iteration:   3860, Loss function: 3.080, Average Loss: 3.800, avg. samples / sec: 64621.13
Iteration:   3860, Loss function: 3.430, Average Loss: 3.801, avg. samples / sec: 64571.72
Iteration:   3860, Loss function: 3.933, Average Loss: 3.784, avg. samples / sec: 64611.89
Iteration:   3860, Loss function: 3.770, Average Loss: 3.770, avg. samples / sec: 64636.67
Iteration:   3860, Loss function: 4.592, Average Loss: 3.781, avg. samples / sec: 64513.90
Iteration:   3860, Loss function: 2.728, Average Loss: 3.811, avg. samples / sec: 64512.31
Iteration:   3860, Loss function: 3.127, Average Loss: 3.778, avg. samples / sec: 64551.75
Iteration:   3860, Loss function: 2.858, Average Loss: 3.782, avg. samples / sec: 64702.16
Iteration:   3860, Loss function: 3.546, Average Loss: 3.759, avg. samples / sec: 64655.70
Iteration:   3860, Loss function: 2.989, Average Loss: 3.771, avg. samples / sec: 64575.09
Iteration:   3860, Loss function: 2.806, Average Loss: 3.782, avg. samples / sec: 64567.22
Iteration:   3860, Loss function: 2.803, Average Loss: 3.788, avg. samples / sec: 64590.10
Iteration:   3860, Loss function: 3.021, Average Loss: 3.807, avg. samples / sec: 64434.38
Iteration:   3860, Loss function: 3.408, Average Loss: 3.789, avg. samples / sec: 64573.11
Iteration:   3860, Loss function: 3.743, Average Loss: 3.777, avg. samples / sec: 64361.75
Iteration:   3860, Loss function: 3.349, Average Loss: 3.795, avg. samples / sec: 64646.15
Iteration:   3860, Loss function: 3.174, Average Loss: 3.791, avg. samples / sec: 64699.60
Iteration:   3860, Loss function: 2.423, Average Loss: 3.774, avg. samples / sec: 64452.77
Iteration:   3880, Loss function: 2.990, Average Loss: 3.764, avg. samples / sec: 66170.16
Iteration:   3880, Loss function: 2.768, Average Loss: 3.770, avg. samples / sec: 66165.04
Iteration:   3880, Loss function: 3.882, Average Loss: 3.783, avg. samples / sec: 66141.68
Iteration:   3880, Loss function: 2.807, Average Loss: 3.768, avg. samples / sec: 66260.76
Iteration:   3880, Loss function: 3.957, Average Loss: 3.792, avg. samples / sec: 66127.66
Iteration:   3880, Loss function: 4.074, Average Loss: 3.797, avg. samples / sec: 66208.49
Iteration:   3880, Loss function: 4.776, Average Loss: 3.762, avg. samples / sec: 66178.18
Iteration:   3880, Loss function: 4.507, Average Loss: 3.787, avg. samples / sec: 66130.51
Iteration:   3880, Loss function: 2.523, Average Loss: 3.769, avg. samples / sec: 66070.74
Iteration:   3880, Loss function: 2.650, Average Loss: 3.801, avg. samples / sec: 66077.33
Iteration:   3880, Loss function: 2.817, Average Loss: 3.765, avg. samples / sec: 66068.26
Iteration:   3880, Loss function: 2.519, Average Loss: 3.770, avg. samples / sec: 65981.00
Iteration:   3880, Loss function: 2.947, Average Loss: 3.789, avg. samples / sec: 65968.43
Iteration:   3880, Loss function: 3.343, Average Loss: 3.774, avg. samples / sec: 66073.90
Iteration:   3880, Loss function: 3.005, Average Loss: 3.786, avg. samples / sec: 65968.43
Iteration:   3880, Loss function: 1.940, Average Loss: 3.763, avg. samples / sec: 65963.09
Iteration:   3880, Loss function: 1.944, Average Loss: 3.782, avg. samples / sec: 66094.72
Iteration:   3880, Loss function: 3.182, Average Loss: 3.771, avg. samples / sec: 65942.84
Iteration:   3880, Loss function: 3.507, Average Loss: 3.756, avg. samples / sec: 65946.54
Iteration:   3880, Loss function: 3.033, Average Loss: 3.785, avg. samples / sec: 65864.71
Iteration:   3880, Loss function: 3.555, Average Loss: 3.762, avg. samples / sec: 65949.97
Iteration:   3880, Loss function: 3.471, Average Loss: 3.782, avg. samples / sec: 66042.44
Iteration:   3880, Loss function: 3.516, Average Loss: 3.791, avg. samples / sec: 65918.66
Iteration:   3880, Loss function: 4.475, Average Loss: 3.770, avg. samples / sec: 65938.46
Iteration:   3880, Loss function: 4.067, Average Loss: 3.777, avg. samples / sec: 65915.54
Iteration:   3880, Loss function: 4.073, Average Loss: 3.786, avg. samples / sec: 65882.72
Iteration:   3880, Loss function: 3.400, Average Loss: 3.763, avg. samples / sec: 65886.30
Iteration:   3880, Loss function: 3.594, Average Loss: 3.767, avg. samples / sec: 66056.86
Iteration:   3880, Loss function: 4.852, Average Loss: 3.751, avg. samples / sec: 65927.04
Iteration:   3880, Loss function: 2.448, Average Loss: 3.778, avg. samples / sec: 65931.67
Iteration:   3900, Loss function: 3.838, Average Loss: 3.766, avg. samples / sec: 65869.42
Iteration:   3900, Loss function: 3.562, Average Loss: 3.759, avg. samples / sec: 65793.46
Iteration:   3900, Loss function: 3.318, Average Loss: 3.779, avg. samples / sec: 66023.07
Iteration:   3900, Loss function: 3.072, Average Loss: 3.758, avg. samples / sec: 66079.56
Iteration:   3900, Loss function: 3.906, Average Loss: 3.778, avg. samples / sec: 65769.61
Iteration:   3900, Loss function: 2.452, Average Loss: 3.773, avg. samples / sec: 66074.64
Iteration:   3900, Loss function: 4.130, Average Loss: 3.756, avg. samples / sec: 65934.26
Iteration:   3900, Loss function: 2.751, Average Loss: 3.774, avg. samples / sec: 65985.66
Iteration:   3900, Loss function: 3.708, Average Loss: 3.754, avg. samples / sec: 65860.06
Iteration:   3900, Loss function: 3.905, Average Loss: 3.799, avg. samples / sec: 65847.94
Iteration:   3900, Loss function: 2.781, Average Loss: 3.762, avg. samples / sec: 65976.18
Iteration:   3900, Loss function: 3.230, Average Loss: 3.762, avg. samples / sec: 65852.68
Iteration:   3900, Loss function: 2.420, Average Loss: 3.760, avg. samples / sec: 65688.12
Iteration:   3900, Loss function: 3.595, Average Loss: 3.763, avg. samples / sec: 65910.09
Iteration:   3900, Loss function: 3.693, Average Loss: 3.755, avg. samples / sec: 65888.27
Iteration:   3900, Loss function: 1.918, Average Loss: 3.772, avg. samples / sec: 65868.31
Iteration:   3900, Loss function: 2.689, Average Loss: 3.774, avg. samples / sec: 65965.71
Iteration:   3900, Loss function: 2.577, Average Loss: 3.779, avg. samples / sec: 65844.77
Iteration:   3900, Loss function: 2.147, Average Loss: 3.755, avg. samples / sec: 65705.89
Iteration:   3900, Loss function: 1.796, Average Loss: 3.782, avg. samples / sec: 65797.21
Iteration:   3900, Loss function: 3.641, Average Loss: 3.758, avg. samples / sec: 65949.60
Iteration:   3900, Loss function: 1.974, Average Loss: 3.772, avg. samples / sec: 65849.14
Iteration:   3900, Loss function: 2.411, Average Loss: 3.742, avg. samples / sec: 65920.20
Iteration:   3900, Loss function: 3.427, Average Loss: 3.789, avg. samples / sec: 65658.04
Iteration:   3900, Loss function: 3.107, Average Loss: 3.769, avg. samples / sec: 65775.01
Iteration:   3900, Loss function: 2.995, Average Loss: 3.778, avg. samples / sec: 65723.66
Iteration:   3900, Loss function: 3.645, Average Loss: 3.771, avg. samples / sec: 65876.87
Iteration:   3900, Loss function: 3.624, Average Loss: 3.764, avg. samples / sec: 65742.18
Iteration:   3900, Loss function: 4.116, Average Loss: 3.785, avg. samples / sec: 65616.19
Iteration:   3900, Loss function: 3.979, Average Loss: 3.749, avg. samples / sec: 65764.05
:::MLL 1558651806.105 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558651806.106 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 3.749, Average Loss: 3.777, avg. samples / sec: 65850.15
Iteration:   3920, Loss function: 3.735, Average Loss: 3.757, avg. samples / sec: 65563.56
Iteration:   3920, Loss function: 2.912, Average Loss: 3.749, avg. samples / sec: 65599.42
Iteration:   3920, Loss function: 2.986, Average Loss: 3.772, avg. samples / sec: 65608.22
Iteration:   3920, Loss function: 3.526, Average Loss: 3.792, avg. samples / sec: 65655.81
Iteration:   3920, Loss function: 3.916, Average Loss: 3.746, avg. samples / sec: 65693.36
Iteration:   3920, Loss function: 2.760, Average Loss: 3.750, avg. samples / sec: 65725.22
Iteration:   3920, Loss function: 4.177, Average Loss: 3.755, avg. samples / sec: 65673.37
Iteration:   3920, Loss function: 4.076, Average Loss: 3.775, avg. samples / sec: 65679.55
Iteration:   3920, Loss function: 3.323, Average Loss: 3.756, avg. samples / sec: 65626.67
Iteration:   3920, Loss function: 3.764, Average Loss: 3.756, avg. samples / sec: 65735.25
Iteration:   3920, Loss function: 3.608, Average Loss: 3.779, avg. samples / sec: 65696.94
Iteration:   3920, Loss function: 2.766, Average Loss: 3.770, avg. samples / sec: 65708.74
Iteration:   3920, Loss function: 2.589, Average Loss: 3.749, avg. samples / sec: 65495.49
Iteration:   3920, Loss function: 3.835, Average Loss: 3.766, avg. samples / sec: 65538.01
Iteration:   3920, Loss function: 2.217, Average Loss: 3.758, avg. samples / sec: 65574.27
Iteration:   3920, Loss function: 2.770, Average Loss: 3.761, avg. samples / sec: 65633.91
Iteration:   3920, Loss function: 2.987, Average Loss: 3.737, avg. samples / sec: 65631.16
Iteration:   3920, Loss function: 2.083, Average Loss: 3.750, avg. samples / sec: 65519.76
Iteration:   3920, Loss function: 3.357, Average Loss: 3.764, avg. samples / sec: 65499.45
Iteration:   3920, Loss function: 3.283, Average Loss: 3.748, avg. samples / sec: 65590.08
Iteration:   3920, Loss function: 3.881, Average Loss: 3.742, avg. samples / sec: 65520.19
Iteration:   3920, Loss function: 3.081, Average Loss: 3.743, avg. samples / sec: 65679.80
Iteration:   3920, Loss function: 2.869, Average Loss: 3.777, avg. samples / sec: 65467.87
Iteration:   3920, Loss function: 3.747, Average Loss: 3.774, avg. samples / sec: 65560.54
Iteration:   3920, Loss function: 3.684, Average Loss: 3.761, avg. samples / sec: 65589.62
Iteration:   3920, Loss function: 3.305, Average Loss: 3.761, avg. samples / sec: 65496.56
Iteration:   3920, Loss function: 3.036, Average Loss: 3.755, avg. samples / sec: 65473.13
Iteration:   3920, Loss function: 2.951, Average Loss: 3.765, avg. samples / sec: 65544.72
Iteration:   3920, Loss function: 3.399, Average Loss: 3.763, avg. samples / sec: 65443.30
Iteration:   3940, Loss function: 3.358, Average Loss: 3.751, avg. samples / sec: 66120.55
Iteration:   3940, Loss function: 3.932, Average Loss: 3.740, avg. samples / sec: 66152.95
Iteration:   3940, Loss function: 3.474, Average Loss: 3.787, avg. samples / sec: 66092.30
Iteration:   3940, Loss function: 1.905, Average Loss: 3.752, avg. samples / sec: 66299.88
Iteration:   3940, Loss function: 3.761, Average Loss: 3.745, avg. samples / sec: 66177.74
Iteration:   3940, Loss function: 2.918, Average Loss: 3.761, avg. samples / sec: 66111.18
Iteration:   3940, Loss function: 2.429, Average Loss: 3.751, avg. samples / sec: 66164.51
Iteration:   3940, Loss function: 2.751, Average Loss: 3.777, avg. samples / sec: 66108.30
Iteration:   3940, Loss function: 2.973, Average Loss: 3.740, avg. samples / sec: 66044.23
Iteration:   3940, Loss function: 3.938, Average Loss: 3.735, avg. samples / sec: 66170.13
Iteration:   3940, Loss function: 2.307, Average Loss: 3.726, avg. samples / sec: 66137.83
Iteration:   3940, Loss function: 3.270, Average Loss: 3.750, avg. samples / sec: 66127.44
Iteration:   3940, Loss function: 3.815, Average Loss: 3.748, avg. samples / sec: 66032.84
Iteration:   3940, Loss function: 3.194, Average Loss: 3.745, avg. samples / sec: 66218.85
Iteration:   3940, Loss function: 2.416, Average Loss: 3.749, avg. samples / sec: 66184.08
Iteration:   3940, Loss function: 3.493, Average Loss: 3.770, avg. samples / sec: 66145.84
Iteration:   3940, Loss function: 2.731, Average Loss: 3.738, avg. samples / sec: 65995.58
Iteration:   3940, Loss function: 3.424, Average Loss: 3.770, avg. samples / sec: 65933.37
Iteration:   3940, Loss function: 3.950, Average Loss: 3.765, avg. samples / sec: 65991.72
Iteration:   3940, Loss function: 3.223, Average Loss: 3.741, avg. samples / sec: 65980.69
Iteration:   3940, Loss function: 4.160, Average Loss: 3.767, avg. samples / sec: 66154.38
Iteration:   3940, Loss function: 2.460, Average Loss: 3.755, avg. samples / sec: 66122.10
Iteration:   3940, Loss function: 2.143, Average Loss: 3.740, avg. samples / sec: 66064.36
Iteration:   3940, Loss function: 2.092, Average Loss: 3.747, avg. samples / sec: 65996.20
Iteration:   3940, Loss function: 3.468, Average Loss: 3.751, avg. samples / sec: 66166.62
Iteration:   3940, Loss function: 3.157, Average Loss: 3.758, avg. samples / sec: 65977.63
Iteration:   3940, Loss function: 3.159, Average Loss: 3.755, avg. samples / sec: 66013.02
Iteration:   3940, Loss function: 2.858, Average Loss: 3.771, avg. samples / sec: 65924.08
Iteration:   3940, Loss function: 3.123, Average Loss: 3.746, avg. samples / sec: 65875.24
Iteration:   3940, Loss function: 3.004, Average Loss: 3.741, avg. samples / sec: 65930.25
Iteration:   3960, Loss function: 2.208, Average Loss: 3.762, avg. samples / sec: 65880.88
Iteration:   3960, Loss function: 3.524, Average Loss: 3.733, avg. samples / sec: 65715.88
Iteration:   3960, Loss function: 3.951, Average Loss: 3.751, avg. samples / sec: 65866.74
Iteration:   3960, Loss function: 3.485, Average Loss: 3.772, avg. samples / sec: 65681.91
Iteration:   3960, Loss function: 3.886, Average Loss: 3.729, avg. samples / sec: 65750.67
Iteration:   3960, Loss function: 4.455, Average Loss: 3.747, avg. samples / sec: 65591.39
Iteration:   3960, Loss function: 3.489, Average Loss: 3.739, avg. samples / sec: 65745.71
Iteration:   3960, Loss function: 4.096, Average Loss: 3.762, avg. samples / sec: 65732.30
Iteration:   3960, Loss function: 2.869, Average Loss: 3.749, avg. samples / sec: 65792.51
Iteration:   3960, Loss function: 3.111, Average Loss: 3.757, avg. samples / sec: 65749.36
Iteration:   3960, Loss function: 4.272, Average Loss: 3.730, avg. samples / sec: 65742.64
Iteration:   3960, Loss function: 3.253, Average Loss: 3.732, avg. samples / sec: 65665.81
Iteration:   3960, Loss function: 2.596, Average Loss: 3.753, avg. samples / sec: 65657.15
Iteration:   3960, Loss function: 2.610, Average Loss: 3.739, avg. samples / sec: 65688.64
Iteration:   3960, Loss function: 3.746, Average Loss: 3.736, avg. samples / sec: 65643.12
Iteration:   3960, Loss function: 3.088, Average Loss: 3.763, avg. samples / sec: 65805.51
Iteration:   3960, Loss function: 2.609, Average Loss: 3.742, avg. samples / sec: 65642.17
Iteration:   3960, Loss function: 3.882, Average Loss: 3.751, avg. samples / sec: 65796.84
Iteration:   3960, Loss function: 3.417, Average Loss: 3.768, avg. samples / sec: 65614.42
Iteration:   3960, Loss function: 2.896, Average Loss: 3.725, avg. samples / sec: 65869.85
Iteration:   3960, Loss function: 3.137, Average Loss: 3.739, avg. samples / sec: 65827.15
Iteration:   3960, Loss function: 3.323, Average Loss: 3.731, avg. samples / sec: 65643.97
Iteration:   3960, Loss function: 3.368, Average Loss: 3.758, avg. samples / sec: 65660.82
Iteration:   3960, Loss function: 3.617, Average Loss: 3.736, avg. samples / sec: 65711.62
Iteration:   3960, Loss function: 2.787, Average Loss: 3.743, avg. samples / sec: 65618.11
Iteration:   3960, Loss function: 3.122, Average Loss: 3.735, avg. samples / sec: 65669.33
Iteration:   3960, Loss function: 3.659, Average Loss: 3.747, avg. samples / sec: 65527.35
Iteration:   3960, Loss function: 2.917, Average Loss: 3.720, avg. samples / sec: 65547.58
Iteration:   3960, Loss function: 3.199, Average Loss: 3.743, avg. samples / sec: 65616.59
Iteration:   3960, Loss function: 4.473, Average Loss: 3.730, avg. samples / sec: 65406.28
:::MLL 1558651807.893 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558651807.894 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.405, Average Loss: 3.728, avg. samples / sec: 65700.07
Iteration:   3980, Loss function: 3.025, Average Loss: 3.742, avg. samples / sec: 65635.96
Iteration:   3980, Loss function: 2.491, Average Loss: 3.729, avg. samples / sec: 65674.53
Iteration:   3980, Loss function: 3.048, Average Loss: 3.719, avg. samples / sec: 65684.39
Iteration:   3980, Loss function: 2.960, Average Loss: 3.746, avg. samples / sec: 65591.67
Iteration:   3980, Loss function: 3.275, Average Loss: 3.747, avg. samples / sec: 65578.36
Iteration:   3980, Loss function: 4.452, Average Loss: 3.751, avg. samples / sec: 65653.91
Iteration:   3980, Loss function: 4.331, Average Loss: 3.724, avg. samples / sec: 65643.54
Iteration:   3980, Loss function: 2.496, Average Loss: 3.732, avg. samples / sec: 65574.33
Iteration:   3980, Loss function: 4.151, Average Loss: 3.736, avg. samples / sec: 65654.25
Iteration:   3980, Loss function: 3.533, Average Loss: 3.755, avg. samples / sec: 65390.77
Iteration:   3980, Loss function: 4.107, Average Loss: 3.731, avg. samples / sec: 65616.80
Iteration:   3980, Loss function: 3.055, Average Loss: 3.760, avg. samples / sec: 65476.81
Iteration:   3980, Loss function: 3.923, Average Loss: 3.727, avg. samples / sec: 65802.99
Iteration:   3980, Loss function: 4.016, Average Loss: 3.738, avg. samples / sec: 65523.78
Iteration:   3980, Loss function: 3.796, Average Loss: 3.745, avg. samples / sec: 65523.39
Iteration:   3980, Loss function: 3.271, Average Loss: 3.715, avg. samples / sec: 65654.09
Iteration:   3980, Loss function: 2.794, Average Loss: 3.756, avg. samples / sec: 65515.16
Iteration:   3980, Loss function: 3.714, Average Loss: 3.723, avg. samples / sec: 65442.15
Iteration:   3980, Loss function: 3.279, Average Loss: 3.743, avg. samples / sec: 65557.16
Iteration:   3980, Loss function: 4.241, Average Loss: 3.761, avg. samples / sec: 65480.98
Iteration:   3980, Loss function: 3.533, Average Loss: 3.725, avg. samples / sec: 65438.23
Iteration:   3980, Loss function: 2.569, Average Loss: 3.721, avg. samples / sec: 65398.32
Iteration:   3980, Loss function: 3.276, Average Loss: 3.730, avg. samples / sec: 65454.49
Iteration:   3980, Loss function: 2.146, Average Loss: 3.758, avg. samples / sec: 65353.80
Iteration:   3980, Loss function: 3.222, Average Loss: 3.725, avg. samples / sec: 65491.11
Iteration:   3980, Loss function: 2.767, Average Loss: 3.731, avg. samples / sec: 65549.60
Iteration:   3980, Loss function: 3.694, Average Loss: 3.733, avg. samples / sec: 65328.99
Iteration:   3980, Loss function: 3.655, Average Loss: 3.742, avg. samples / sec: 65375.33
Iteration:   3980, Loss function: 2.661, Average Loss: 3.743, avg. samples / sec: 65286.02
Iteration:   4000, Loss function: 3.142, Average Loss: 3.742, avg. samples / sec: 65835.17
Iteration:   4000, Loss function: 3.631, Average Loss: 3.719, avg. samples / sec: 65673.16
Iteration:   4000, Loss function: 3.166, Average Loss: 3.721, avg. samples / sec: 65748.90
Iteration:   4000, Loss function: 3.309, Average Loss: 3.717, avg. samples / sec: 65954.87
Iteration:   4000, Loss function: 3.309, Average Loss: 3.739, avg. samples / sec: 65666.94
Iteration:   4000, Loss function: 3.994, Average Loss: 3.722, avg. samples / sec: 65863.54
Iteration:   4000, Loss function: 3.382, Average Loss: 3.725, avg. samples / sec: 65489.16
Iteration:   4000, Loss function: 3.674, Average Loss: 3.754, avg. samples / sec: 65854.52
Iteration:   4000, Loss function: 3.495, Average Loss: 3.738, avg. samples / sec: 65838.31
Iteration:   4000, Loss function: 3.936, Average Loss: 3.747, avg. samples / sec: 65693.30
Iteration:   4000, Loss function: 3.270, Average Loss: 3.749, avg. samples / sec: 65771.94
Iteration:   4000, Loss function: 4.882, Average Loss: 3.721, avg. samples / sec: 65740.77
Iteration:   4000, Loss function: 3.542, Average Loss: 3.751, avg. samples / sec: 65725.13
Iteration:   4000, Loss function: 3.140, Average Loss: 3.734, avg. samples / sec: 65548.80
Iteration:   4000, Loss function: 3.399, Average Loss: 3.714, avg. samples / sec: 65829.70
Iteration:   4000, Loss function: 4.325, Average Loss: 3.750, avg. samples / sec: 65857.51
Iteration:   4000, Loss function: 3.215, Average Loss: 3.725, avg. samples / sec: 65667.98
Iteration:   4000, Loss function: 3.199, Average Loss: 3.732, avg. samples / sec: 65673.37
Iteration:   4000, Loss function: 2.476, Average Loss: 3.728, avg. samples / sec: 65730.43
Iteration:   4000, Loss function: 3.324, Average Loss: 3.733, avg. samples / sec: 65888.67
Iteration:   4000, Loss function: 3.747, Average Loss: 3.736, avg. samples / sec: 65697.52
Iteration:   4000, Loss function: 2.190, Average Loss: 3.718, avg. samples / sec: 65823.40
Iteration:   4000, Loss function: 3.914, Average Loss: 3.707, avg. samples / sec: 65708.37
Iteration:   4000, Loss function: 3.143, Average Loss: 3.717, avg. samples / sec: 65559.90
Iteration:   4000, Loss function: 3.733, Average Loss: 3.724, avg. samples / sec: 65623.58
Iteration:   4000, Loss function: 4.337, Average Loss: 3.735, avg. samples / sec: 65820.11
Iteration:   4000, Loss function: 3.448, Average Loss: 3.720, avg. samples / sec: 65781.09
Iteration:   4000, Loss function: 3.615, Average Loss: 3.718, avg. samples / sec: 65667.86
Iteration:   4000, Loss function: 3.641, Average Loss: 3.739, avg. samples / sec: 65464.64
Iteration:   4000, Loss function: 3.149, Average Loss: 3.728, avg. samples / sec: 65690.36
Iteration:   4020, Loss function: 4.084, Average Loss: 3.717, avg. samples / sec: 66021.74
Iteration:   4020, Loss function: 3.373, Average Loss: 3.743, avg. samples / sec: 65955.52
Iteration:   4020, Loss function: 3.472, Average Loss: 3.734, avg. samples / sec: 65971.45
Iteration:   4020, Loss function: 3.289, Average Loss: 3.727, avg. samples / sec: 65965.62
Iteration:   4020, Loss function: 2.597, Average Loss: 3.743, avg. samples / sec: 65897.79
Iteration:   4020, Loss function: 2.369, Average Loss: 3.704, avg. samples / sec: 65970.56
Iteration:   4020, Loss function: 2.826, Average Loss: 3.733, avg. samples / sec: 65897.91
Iteration:   4020, Loss function: 2.980, Average Loss: 3.745, avg. samples / sec: 65899.51
Iteration:   4020, Loss function: 3.980, Average Loss: 3.715, avg. samples / sec: 65973.52
Iteration:   4020, Loss function: 3.097, Average Loss: 3.724, avg. samples / sec: 65896.37
Iteration:   4020, Loss function: 3.826, Average Loss: 3.739, avg. samples / sec: 65855.88
Iteration:   4020, Loss function: 2.644, Average Loss: 3.713, avg. samples / sec: 65775.04
Iteration:   4020, Loss function: 3.529, Average Loss: 3.737, avg. samples / sec: 65733.19
Iteration:   4020, Loss function: 2.764, Average Loss: 3.711, avg. samples / sec: 65852.18
Iteration:   4020, Loss function: 3.264, Average Loss: 3.720, avg. samples / sec: 66043.89
Iteration:   4020, Loss function: 3.202, Average Loss: 3.736, avg. samples / sec: 66027.58
Iteration:   4020, Loss function: 4.245, Average Loss: 3.719, avg. samples / sec: 65848.83
Iteration:   4020, Loss function: 3.566, Average Loss: 3.704, avg. samples / sec: 65860.74
Iteration:   4020, Loss function: 3.759, Average Loss: 3.731, avg. samples / sec: 65898.53
Iteration:   4020, Loss function: 2.990, Average Loss: 3.716, avg. samples / sec: 65899.76
Iteration:   4020, Loss function: 3.402, Average Loss: 3.709, avg. samples / sec: 65714.96
Iteration:   4020, Loss function: 4.217, Average Loss: 3.722, avg. samples / sec: 65703.74
Iteration:   4020, Loss function: 2.363, Average Loss: 3.710, avg. samples / sec: 65808.52
Iteration:   4020, Loss function: 2.942, Average Loss: 3.723, avg. samples / sec: 65778.11
Iteration:   4020, Loss function: 3.160, Average Loss: 3.727, avg. samples / sec: 65810.55
Iteration:   4020, Loss function: 3.880, Average Loss: 3.713, avg. samples / sec: 65891.47
Iteration:   4020, Loss function: 3.069, Average Loss: 3.744, avg. samples / sec: 65755.15
Iteration:   4020, Loss function: 3.545, Average Loss: 3.707, avg. samples / sec: 65768.72
Iteration:   4020, Loss function: 4.591, Average Loss: 3.726, avg. samples / sec: 65718.17
Iteration:   4020, Loss function: 3.623, Average Loss: 3.718, avg. samples / sec: 65680.23
Iteration:   4040, Loss function: 3.211, Average Loss: 3.719, avg. samples / sec: 66087.00
Iteration:   4040, Loss function: 2.824, Average Loss: 3.722, avg. samples / sec: 65867.08
Iteration:   4040, Loss function: 2.424, Average Loss: 3.707, avg. samples / sec: 65740.09
Iteration:   4040, Loss function: 3.776, Average Loss: 3.733, avg. samples / sec: 65896.40
Iteration:   4040, Loss function: 3.274, Average Loss: 3.724, avg. samples / sec: 65828.25
Iteration:   4040, Loss function: 3.281, Average Loss: 3.737, avg. samples / sec: 65824.32
Iteration:   4040, Loss function: 3.131, Average Loss: 3.729, avg. samples / sec: 65905.43
Iteration:   4040, Loss function: 2.249, Average Loss: 3.734, avg. samples / sec: 65725.93
Iteration:   4040, Loss function: 3.577, Average Loss: 3.704, avg. samples / sec: 65914.89
Iteration:   4040, Loss function: 3.644, Average Loss: 3.731, avg. samples / sec: 65805.02
Iteration:   4040, Loss function: 3.527, Average Loss: 3.703, avg. samples / sec: 65808.95
Iteration:   4040, Loss function: 3.833, Average Loss: 3.707, avg. samples / sec: 65814.48
Iteration:   4040, Loss function: 3.355, Average Loss: 3.715, avg. samples / sec: 65786.92
Iteration:   4040, Loss function: 2.592, Average Loss: 3.701, avg. samples / sec: 65879.98
Iteration:   4040, Loss function: 4.341, Average Loss: 3.720, avg. samples / sec: 65881.09
Iteration:   4040, Loss function: 3.346, Average Loss: 3.718, avg. samples / sec: 65871.08
Iteration:   4040, Loss function: 3.917, Average Loss: 3.700, avg. samples / sec: 65887.07
Iteration:   4040, Loss function: 2.808, Average Loss: 3.729, avg. samples / sec: 65783.08
Iteration:   4040, Loss function: 3.684, Average Loss: 3.739, avg. samples / sec: 65868.71
Iteration:   4040, Loss function: 2.922, Average Loss: 3.718, avg. samples / sec: 65721.15
Iteration:   4040, Loss function: 5.455, Average Loss: 3.715, avg. samples / sec: 65831.94
Iteration:   4040, Loss function: 2.731, Average Loss: 3.696, avg. samples / sec: 65678.08
Iteration:   4040, Loss function: 3.728, Average Loss: 3.710, avg. samples / sec: 65806.06
Iteration:   4040, Loss function: 2.885, Average Loss: 3.708, avg. samples / sec: 65864.25
Iteration:   4040, Loss function: 2.908, Average Loss: 3.715, avg. samples / sec: 65642.78
Iteration:   4040, Loss function: 2.877, Average Loss: 3.734, avg. samples / sec: 65635.84
Iteration:   4040, Loss function: 3.684, Average Loss: 3.698, avg. samples / sec: 65743.90
Iteration:   4040, Loss function: 2.815, Average Loss: 3.704, avg. samples / sec: 65761.35
Iteration:   4040, Loss function: 3.079, Average Loss: 3.712, avg. samples / sec: 65689.07
Iteration:   4040, Loss function: 2.581, Average Loss: 3.712, avg. samples / sec: 65579.88
:::MLL 1558651809.683 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558651809.683 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 2.765, Average Loss: 3.713, avg. samples / sec: 65471.36
Iteration:   4060, Loss function: 2.909, Average Loss: 3.715, avg. samples / sec: 65643.79
Iteration:   4060, Loss function: 3.405, Average Loss: 3.717, avg. samples / sec: 65489.53
Iteration:   4060, Loss function: 2.855, Average Loss: 3.724, avg. samples / sec: 65566.28
Iteration:   4060, Loss function: 2.394, Average Loss: 3.719, avg. samples / sec: 65426.50
Iteration:   4060, Loss function: 3.482, Average Loss: 3.701, avg. samples / sec: 65438.86
Iteration:   4060, Loss function: 3.834, Average Loss: 3.727, avg. samples / sec: 65652.20
Iteration:   4060, Loss function: 2.713, Average Loss: 3.708, avg. samples / sec: 65793.80
Iteration:   4060, Loss function: 3.462, Average Loss: 3.703, avg. samples / sec: 65532.10
Iteration:   4060, Loss function: 4.335, Average Loss: 3.726, avg. samples / sec: 65435.01
Iteration:   4060, Loss function: 2.788, Average Loss: 3.719, avg. samples / sec: 65555.60
Iteration:   4060, Loss function: 3.159, Average Loss: 3.722, avg. samples / sec: 65487.40
Iteration:   4060, Loss function: 2.310, Average Loss: 3.729, avg. samples / sec: 65451.02
Iteration:   4060, Loss function: 3.393, Average Loss: 3.713, avg. samples / sec: 65551.24
Iteration:   4060, Loss function: 3.062, Average Loss: 3.706, avg. samples / sec: 65516.47
Iteration:   4060, Loss function: 4.224, Average Loss: 3.732, avg. samples / sec: 65532.04
Iteration:   4060, Loss function: 1.823, Average Loss: 3.708, avg. samples / sec: 65474.59
Iteration:   4060, Loss function: 3.890, Average Loss: 3.702, avg. samples / sec: 65528.69
Iteration:   4060, Loss function: 3.348, Average Loss: 3.712, avg. samples / sec: 65514.34
Iteration:   4060, Loss function: 2.880, Average Loss: 3.708, avg. samples / sec: 65529.78
Iteration:   4060, Loss function: 3.767, Average Loss: 3.688, avg. samples / sec: 65492.75
Iteration:   4060, Loss function: 3.759, Average Loss: 3.697, avg. samples / sec: 65456.25
Iteration:   4060, Loss function: 3.014, Average Loss: 3.693, avg. samples / sec: 65539.32
Iteration:   4060, Loss function: 3.086, Average Loss: 3.693, avg. samples / sec: 65415.93
Iteration:   4060, Loss function: 3.530, Average Loss: 3.695, avg. samples / sec: 65416.30
Iteration:   4060, Loss function: 2.736, Average Loss: 3.701, avg. samples / sec: 65561.43
Iteration:   4060, Loss function: 3.346, Average Loss: 3.700, avg. samples / sec: 65537.92
Iteration:   4060, Loss function: 3.495, Average Loss: 3.694, avg. samples / sec: 65383.18
Iteration:   4060, Loss function: 3.403, Average Loss: 3.724, avg. samples / sec: 65333.17
Iteration:   4060, Loss function: 3.446, Average Loss: 3.703, avg. samples / sec: 65447.80
Iteration:   4080, Loss function: 3.082, Average Loss: 3.726, avg. samples / sec: 66281.17
Iteration:   4080, Loss function: 3.152, Average Loss: 3.694, avg. samples / sec: 66206.44
Iteration:   4080, Loss function: 3.512, Average Loss: 3.698, avg. samples / sec: 66244.62
Iteration:   4080, Loss function: 1.595, Average Loss: 3.711, avg. samples / sec: 66166.78
Iteration:   4080, Loss function: 3.535, Average Loss: 3.691, avg. samples / sec: 66210.42
Iteration:   4080, Loss function: 3.358, Average Loss: 3.709, avg. samples / sec: 66094.84
Iteration:   4080, Loss function: 3.151, Average Loss: 3.694, avg. samples / sec: 66223.24
Iteration:   4080, Loss function: 4.165, Average Loss: 3.722, avg. samples / sec: 66115.43
Iteration:   4080, Loss function: 3.583, Average Loss: 3.703, avg. samples / sec: 66105.63
Iteration:   4080, Loss function: 5.139, Average Loss: 3.692, avg. samples / sec: 66194.84
Iteration:   4080, Loss function: 3.333, Average Loss: 3.702, avg. samples / sec: 66018.61
Iteration:   4080, Loss function: 4.542, Average Loss: 3.725, avg. samples / sec: 66131.88
Iteration:   4080, Loss function: 3.650, Average Loss: 3.693, avg. samples / sec: 66047.76
Iteration:   4080, Loss function: 3.949, Average Loss: 3.722, avg. samples / sec: 66056.99
Iteration:   4080, Loss function: 2.445, Average Loss: 3.707, avg. samples / sec: 66117.54
Iteration:   4080, Loss function: 3.761, Average Loss: 3.711, avg. samples / sec: 66092.49
Iteration:   4080, Loss function: 2.064, Average Loss: 3.679, avg. samples / sec: 66173.05
Iteration:   4080, Loss function: 2.242, Average Loss: 3.703, avg. samples / sec: 66137.40
Iteration:   4080, Loss function: 3.374, Average Loss: 3.703, avg. samples / sec: 66128.87
Iteration:   4080, Loss function: 3.545, Average Loss: 3.714, avg. samples / sec: 66061.91
Iteration:   4080, Loss function: 2.826, Average Loss: 3.713, avg. samples / sec: 66167.02
Iteration:   4080, Loss function: 3.605, Average Loss: 3.690, avg. samples / sec: 66130.01
Iteration:   4080, Loss function: 2.392, Average Loss: 3.686, avg. samples / sec: 66147.49
Iteration:   4080, Loss function: 3.096, Average Loss: 3.711, avg. samples / sec: 65955.12
Iteration:   4080, Loss function: 2.931, Average Loss: 3.686, avg. samples / sec: 66092.55
Iteration:   4080, Loss function: 4.758, Average Loss: 3.685, avg. samples / sec: 66119.90
Iteration:   4080, Loss function: 4.685, Average Loss: 3.688, avg. samples / sec: 66103.62
Iteration:   4080, Loss function: 2.983, Average Loss: 3.700, avg. samples / sec: 66037.67
Iteration:   4080, Loss function: 2.495, Average Loss: 3.700, avg. samples / sec: 66144.42
Iteration:   4080, Loss function: 3.223, Average Loss: 3.707, avg. samples / sec: 65850.06
Iteration:   4100, Loss function: 4.000, Average Loss: 3.706, avg. samples / sec: 66346.17
Iteration:   4100, Loss function: 3.980, Average Loss: 3.718, avg. samples / sec: 66187.50
Iteration:   4100, Loss function: 3.476, Average Loss: 3.733, avg. samples / sec: 66034.45
Iteration:   4100, Loss function: 3.645, Average Loss: 3.706, avg. samples / sec: 66246.34
Iteration:   4100, Loss function: 2.562, Average Loss: 3.674, avg. samples / sec: 66205.97
Iteration:   4100, Loss function: 2.808, Average Loss: 3.686, avg. samples / sec: 66025.48
Iteration:   4100, Loss function: 3.717, Average Loss: 3.693, avg. samples / sec: 66030.99
Iteration:   4100, Loss function: 3.062, Average Loss: 3.712, avg. samples / sec: 66150.50
Iteration:   4100, Loss function: 2.574, Average Loss: 3.687, avg. samples / sec: 66134.89
Iteration:   4100, Loss function: 3.467, Average Loss: 3.689, avg. samples / sec: 66215.55
Iteration:   4100, Loss function: 2.754, Average Loss: 3.706, avg. samples / sec: 65985.97
Iteration:   4100, Loss function: 3.161, Average Loss: 3.705, avg. samples / sec: 66212.35
Iteration:   4100, Loss function: 2.922, Average Loss: 3.682, avg. samples / sec: 66099.87
Iteration:   4100, Loss function: 3.667, Average Loss: 3.695, avg. samples / sec: 66134.95
Iteration:   4100, Loss function: 3.104, Average Loss: 3.676, avg. samples / sec: 66181.35
Iteration:   4100, Loss function: 4.056, Average Loss: 3.723, avg. samples / sec: 66108.92
Iteration:   4100, Loss function: 3.371, Average Loss: 3.692, avg. samples / sec: 66219.91
Iteration:   4100, Loss function: 3.018, Average Loss: 3.699, avg. samples / sec: 66061.26
Iteration:   4100, Loss function: 3.893, Average Loss: 3.706, avg. samples / sec: 66048.47
Iteration:   4100, Loss function: 4.218, Average Loss: 3.681, avg. samples / sec: 66200.87
Iteration:   4100, Loss function: 2.487, Average Loss: 3.686, avg. samples / sec: 66031.70
Iteration:   4100, Loss function: 3.404, Average Loss: 3.707, avg. samples / sec: 66081.55
Iteration:   4100, Loss function: 3.174, Average Loss: 3.685, avg. samples / sec: 66020.65
Iteration:   4100, Loss function: 4.180, Average Loss: 3.693, avg. samples / sec: 66066.34
Iteration:   4100, Loss function: 3.526, Average Loss: 3.681, avg. samples / sec: 66148.92
Iteration:   4100, Loss function: 3.135, Average Loss: 3.703, avg. samples / sec: 66052.74
Iteration:   4100, Loss function: 2.743, Average Loss: 3.694, avg. samples / sec: 66160.00
Iteration:   4100, Loss function: 3.629, Average Loss: 3.680, avg. samples / sec: 66111.03
Iteration:   4100, Loss function: 3.140, Average Loss: 3.700, avg. samples / sec: 66018.03
Iteration:   4100, Loss function: 3.387, Average Loss: 3.685, avg. samples / sec: 66081.76
:::MLL 1558651811.466 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558651811.467 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 3.014, Average Loss: 3.696, avg. samples / sec: 65920.32
Iteration:   4120, Loss function: 2.866, Average Loss: 3.700, avg. samples / sec: 65894.71
Iteration:   4120, Loss function: 3.184, Average Loss: 3.683, avg. samples / sec: 65799.79
Iteration:   4120, Loss function: 4.014, Average Loss: 3.695, avg. samples / sec: 65791.93
Iteration:   4120, Loss function: 3.347, Average Loss: 3.696, avg. samples / sec: 65840.92
Iteration:   4120, Loss function: 4.335, Average Loss: 3.696, avg. samples / sec: 65798.84
Iteration:   4120, Loss function: 2.304, Average Loss: 3.677, avg. samples / sec: 65716.03
Iteration:   4120, Loss function: 4.493, Average Loss: 3.690, avg. samples / sec: 65789.90
Iteration:   4120, Loss function: 3.233, Average Loss: 3.664, avg. samples / sec: 65699.42
Iteration:   4120, Loss function: 3.356, Average Loss: 3.695, avg. samples / sec: 65809.93
Iteration:   4120, Loss function: 3.054, Average Loss: 3.729, avg. samples / sec: 65661.77
Iteration:   4120, Loss function: 3.213, Average Loss: 3.710, avg. samples / sec: 65647.06
Iteration:   4120, Loss function: 3.625, Average Loss: 3.673, avg. samples / sec: 65738.90
Iteration:   4120, Loss function: 3.956, Average Loss: 3.691, avg. samples / sec: 65781.30
Iteration:   4120, Loss function: 3.330, Average Loss: 3.675, avg. samples / sec: 65816.57
Iteration:   4120, Loss function: 3.746, Average Loss: 3.675, avg. samples / sec: 65685.43
Iteration:   4120, Loss function: 3.130, Average Loss: 3.697, avg. samples / sec: 65551.94
Iteration:   4120, Loss function: 3.342, Average Loss: 3.679, avg. samples / sec: 65709.41
Iteration:   4120, Loss function: 3.021, Average Loss: 3.689, avg. samples / sec: 65768.93
Iteration:   4120, Loss function: 4.061, Average Loss: 3.715, avg. samples / sec: 65635.04
Iteration:   4120, Loss function: 3.350, Average Loss: 3.686, avg. samples / sec: 65647.58
Iteration:   4120, Loss function: 3.138, Average Loss: 3.705, avg. samples / sec: 65591.30
Iteration:   4120, Loss function: 3.084, Average Loss: 3.677, avg. samples / sec: 65630.61
Iteration:   4120, Loss function: 3.244, Average Loss: 3.684, avg. samples / sec: 65620.04
Iteration:   4120, Loss function: 2.815, Average Loss: 3.686, avg. samples / sec: 65604.03
Iteration:   4120, Loss function: 3.250, Average Loss: 3.678, avg. samples / sec: 65702.55
Iteration:   4120, Loss function: 2.774, Average Loss: 3.673, avg. samples / sec: 65599.70
Iteration:   4120, Loss function: 3.502, Average Loss: 3.682, avg. samples / sec: 65494.27
Iteration:   4120, Loss function: 3.625, Average Loss: 3.681, avg. samples / sec: 65568.23
Iteration:   4120, Loss function: 3.984, Average Loss: 3.701, avg. samples / sec: 65408.55
Iteration:   4140, Loss function: 4.020, Average Loss: 3.687, avg. samples / sec: 65832.37
Iteration:   4140, Loss function: 3.372, Average Loss: 3.692, avg. samples / sec: 65833.30
Iteration:   4140, Loss function: 2.487, Average Loss: 3.718, avg. samples / sec: 65771.45
Iteration:   4140, Loss function: 4.517, Average Loss: 3.695, avg. samples / sec: 65627.50
Iteration:   4140, Loss function: 3.928, Average Loss: 3.679, avg. samples / sec: 65951.94
Iteration:   4140, Loss function: 4.758, Average Loss: 3.699, avg. samples / sec: 65745.86
Iteration:   4140, Loss function: 2.959, Average Loss: 3.689, avg. samples / sec: 65668.72
Iteration:   4140, Loss function: 4.919, Average Loss: 3.671, avg. samples / sec: 65824.38
Iteration:   4140, Loss function: 2.449, Average Loss: 3.694, avg. samples / sec: 65977.17
Iteration:   4140, Loss function: 3.904, Average Loss: 3.686, avg. samples / sec: 65552.43
Iteration:   4140, Loss function: 2.526, Average Loss: 3.669, avg. samples / sec: 65702.64
Iteration:   4140, Loss function: 3.776, Average Loss: 3.686, avg. samples / sec: 65688.18
Iteration:   4140, Loss function: 3.554, Average Loss: 3.682, avg. samples / sec: 65805.23
Iteration:   4140, Loss function: 3.842, Average Loss: 3.681, avg. samples / sec: 65727.55
Iteration:   4140, Loss function: 3.629, Average Loss: 3.669, avg. samples / sec: 65818.75
Iteration:   4140, Loss function: 2.444, Average Loss: 3.674, avg. samples / sec: 65604.43
Iteration:   4140, Loss function: 2.573, Average Loss: 3.698, avg. samples / sec: 65795.40
Iteration:   4140, Loss function: 2.176, Average Loss: 3.670, avg. samples / sec: 65873.21
Iteration:   4140, Loss function: 3.604, Average Loss: 3.666, avg. samples / sec: 65728.35
Iteration:   4140, Loss function: 4.433, Average Loss: 3.687, avg. samples / sec: 65751.04
Iteration:   4140, Loss function: 2.919, Average Loss: 3.683, avg. samples / sec: 65582.75
Iteration:   4140, Loss function: 3.334, Average Loss: 3.679, avg. samples / sec: 65821.40
Iteration:   4140, Loss function: 2.940, Average Loss: 3.709, avg. samples / sec: 65760.06
Iteration:   4140, Loss function: 3.361, Average Loss: 3.665, avg. samples / sec: 65655.90
Iteration:   4140, Loss function: 2.756, Average Loss: 3.665, avg. samples / sec: 65609.53
Iteration:   4140, Loss function: 3.476, Average Loss: 3.660, avg. samples / sec: 65559.14
Iteration:   4140, Loss function: 2.714, Average Loss: 3.686, avg. samples / sec: 65535.06
Iteration:   4140, Loss function: 3.060, Average Loss: 3.668, avg. samples / sec: 65753.13
Iteration:   4140, Loss function: 3.272, Average Loss: 3.667, avg. samples / sec: 65706.99
Iteration:   4140, Loss function: 2.993, Average Loss: 3.676, avg. samples / sec: 65621.44
Iteration:   4160, Loss function: 4.382, Average Loss: 3.712, avg. samples / sec: 65957.07
Iteration:   4160, Loss function: 3.898, Average Loss: 3.682, avg. samples / sec: 66001.14
Iteration:   4160, Loss function: 3.930, Average Loss: 3.682, avg. samples / sec: 65921.21
Iteration:   4160, Loss function: 4.040, Average Loss: 3.683, avg. samples / sec: 65827.73
Iteration:   4160, Loss function: 3.469, Average Loss: 3.660, avg. samples / sec: 65913.45
Iteration:   4160, Loss function: 3.371, Average Loss: 3.665, avg. samples / sec: 65973.34
Iteration:   4160, Loss function: 2.942, Average Loss: 3.686, avg. samples / sec: 65869.14
Iteration:   4160, Loss function: 3.026, Average Loss: 3.670, avg. samples / sec: 65863.02
Iteration:   4160, Loss function: 4.098, Average Loss: 3.685, avg. samples / sec: 65874.25
Iteration:   4160, Loss function: 3.089, Average Loss: 3.663, avg. samples / sec: 66037.30
Iteration:   4160, Loss function: 3.446, Average Loss: 3.663, avg. samples / sec: 65879.34
Iteration:   4160, Loss function: 2.490, Average Loss: 3.687, avg. samples / sec: 65811.72
Iteration:   4160, Loss function: 2.707, Average Loss: 3.669, avg. samples / sec: 66078.88
Iteration:   4160, Loss function: 3.592, Average Loss: 3.701, avg. samples / sec: 65913.48
Iteration:   4160, Loss function: 2.159, Average Loss: 3.658, avg. samples / sec: 65922.08
Iteration:   4160, Loss function: 3.250, Average Loss: 3.678, avg. samples / sec: 65814.97
Iteration:   4160, Loss function: 4.048, Average Loss: 3.667, avg. samples / sec: 65868.37
Iteration:   4160, Loss function: 3.298, Average Loss: 3.666, avg. samples / sec: 65963.89
Iteration:   4160, Loss function: 2.960, Average Loss: 3.690, avg. samples / sec: 65870.19
Iteration:   4160, Loss function: 2.988, Average Loss: 3.676, avg. samples / sec: 65887.31
Iteration:   4160, Loss function: 3.674, Average Loss: 3.685, avg. samples / sec: 65967.19
Iteration:   4160, Loss function: 3.190, Average Loss: 3.673, avg. samples / sec: 65773.26
Iteration:   4160, Loss function: 3.089, Average Loss: 3.696, avg. samples / sec: 65752.98
Iteration:   4160, Loss function: 3.630, Average Loss: 3.686, avg. samples / sec: 65842.55
Iteration:   4160, Loss function: 3.783, Average Loss: 3.674, avg. samples / sec: 65790.18
Iteration:   4160, Loss function: 2.909, Average Loss: 3.653, avg. samples / sec: 65885.62
Iteration:   4160, Loss function: 4.032, Average Loss: 3.671, avg. samples / sec: 65824.75
Iteration:   4160, Loss function: 3.244, Average Loss: 3.659, avg. samples / sec: 65951.73
Iteration:   4160, Loss function: 4.231, Average Loss: 3.670, avg. samples / sec: 65743.93
Iteration:   4160, Loss function: 3.428, Average Loss: 3.658, avg. samples / sec: 65725.93
Iteration:   4180, Loss function: 2.786, Average Loss: 3.657, avg. samples / sec: 65970.22
Iteration:   4180, Loss function: 4.480, Average Loss: 3.682, avg. samples / sec: 66008.10
Iteration:   4180, Loss function: 2.832, Average Loss: 3.651, avg. samples / sec: 66012.86
Iteration:   4180, Loss function: 3.472, Average Loss: 3.669, avg. samples / sec: 65995.98
Iteration:   4180, Loss function: 3.737, Average Loss: 3.708, avg. samples / sec: 65815.93
Iteration:   4180, Loss function: 2.162, Average Loss: 3.684, avg. samples / sec: 65989.00
Iteration:   4180, Loss function: 2.421, Average Loss: 3.678, avg. samples / sec: 65873.73
Iteration:   4180, Loss function: 3.907, Average Loss: 3.651, avg. samples / sec: 65966.20
Iteration:   4180, Loss function: 3.722, Average Loss: 3.675, avg. samples / sec: 65797.73
Iteration:   4180, Loss function: 3.641, Average Loss: 3.687, avg. samples / sec: 65996.76
Iteration:   4180, Loss function: 3.788, Average Loss: 3.660, avg. samples / sec: 66059.09
Iteration:   4180, Loss function: 2.051, Average Loss: 3.662, avg. samples / sec: 66019.26
Iteration:   4180, Loss function: 2.275, Average Loss: 3.672, avg. samples / sec: 65973.31
Iteration:   4180, Loss function: 3.583, Average Loss: 3.663, avg. samples / sec: 65935.06
Iteration:   4180, Loss function: 2.947, Average Loss: 3.679, avg. samples / sec: 65875.46
Iteration:   4180, Loss function: 3.247, Average Loss: 3.664, avg. samples / sec: 65902.75
Iteration:   4180, Loss function: 3.429, Average Loss: 3.669, avg. samples / sec: 65962.56
Iteration:   4180, Loss function: 3.358, Average Loss: 3.651, avg. samples / sec: 66004.55
Iteration:   4180, Loss function: 3.328, Average Loss: 3.670, avg. samples / sec: 65966.98
Iteration:   4180, Loss function: 4.030, Average Loss: 3.671, avg. samples / sec: 65724.98
Iteration:   4180, Loss function: 3.240, Average Loss: 3.655, avg. samples / sec: 65772.95
Iteration:   4180, Loss function: 2.988, Average Loss: 3.680, avg. samples / sec: 65812.91
Iteration:   4180, Loss function: 3.305, Average Loss: 3.654, avg. samples / sec: 65942.47
Iteration:   4180, Loss function: 3.286, Average Loss: 3.694, avg. samples / sec: 65843.79
Iteration:   4180, Loss function: 3.303, Average Loss: 3.662, avg. samples / sec: 65839.76
Iteration:   4180, Loss function: 3.811, Average Loss: 3.675, avg. samples / sec: 65888.61
Iteration:   4180, Loss function: 2.858, Average Loss: 3.652, avg. samples / sec: 65995.58
Iteration:   4180, Loss function: 2.956, Average Loss: 3.673, avg. samples / sec: 65809.32
Iteration:   4180, Loss function: 3.203, Average Loss: 3.672, avg. samples / sec: 65807.29
Iteration:   4180, Loss function: 4.533, Average Loss: 3.659, avg. samples / sec: 65700.10
:::MLL 1558651813.255 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558651813.255 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558651813.305 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=2.54s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23039
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39060
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05865
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24224
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37807
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22318
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32446
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34123
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09891
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37147
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53503
Current AP: 0.23039 AP goal: 0.23000
:::MLL 1558651817.051 eval_accuracy: {"value": 0.23039206238596105, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558651817.061 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558651817.068 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558651817.702 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 10:50:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
ENDING TIMING RUN AT 2019-05-23 10:50:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,164,nvidia,2019-05-23 10:47:40 PM
